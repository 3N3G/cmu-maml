{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vBTJxs8IYd3",
        "outputId": "e8f53f50-67c3-4706-e78b-52686b260cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HowToTrainYourMAMLPytorch'...\n",
            "remote: Enumerating objects: 36634, done.\u001b[K\n",
            "remote: Counting objects: 100% (261/261), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 36634 (delta 159), reused 210 (delta 129), pack-reused 36373 (from 1)\u001b[K\n",
            "Receiving objects: 100% (36634/36634), 18.95 MiB | 9.11 MiB/s, done.\n",
            "Resolving deltas: 100% (2204/2204), done.\n",
            "Updating files: 100% (32570/32570), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AntreasAntoniou/HowToTrainYourMAMLPytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JqpuygWUiM_i"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# from meta_neural_network_architectures import VGGReLUNormNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KzOo4o8Tiwhg"
      },
      "outputs": [],
      "source": [
        "def set_torch_seed(seed):\n",
        "    \"\"\"\n",
        "    Sets the pytorch seeds for current experiment run\n",
        "    :param seed: The seed (int)\n",
        "    :return: A random number generator to use\n",
        "    \"\"\"\n",
        "    rng = np.random.RandomState(seed=seed)\n",
        "    torch_seed = rng.randint(0, 999999)\n",
        "    torch.manual_seed(seed=torch_seed)\n",
        "\n",
        "    return rng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqgfzU5ElCLi"
      },
      "source": [
        "# MAML Classifier Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oanV_B5TD5Zj"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class GradientDescentLearningRule(nn.Module):\n",
        "    \"\"\"Simple (stochastic) gradient descent learning rule.\n",
        "    For a scalar error function `E(p[0], p_[1] ... )` of some set of\n",
        "    potentially multidimensional parameters this attempts to find a local\n",
        "    minimum of the loss function by applying updates to each parameter of the\n",
        "    form\n",
        "        p[i] := p[i] - learning_rate * dE/dp[i]\n",
        "    With `learning_rate` a positive scaling parameter.\n",
        "    The error function used in successive applications of these updates may be\n",
        "    a stochastic estimator of the true error function (e.g. when the error with\n",
        "    respect to only a subset of data-points is calculated) in which case this\n",
        "    will correspond to a stochastic gradient descent learning rule.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, device, learning_rate=1e-3):\n",
        "        \"\"\"Creates a new learning rule object.\n",
        "        Args:\n",
        "            learning_rate: A postive scalar to scale gradient updates to the\n",
        "                parameters by. This needs to be carefully set - if too large\n",
        "                the learning dynamic will be unstable and may diverge, while\n",
        "                if set too small learning will proceed very slowly.\n",
        "        \"\"\"\n",
        "        super(GradientDescentLearningRule, self).__init__()\n",
        "        assert learning_rate > 0., 'learning_rate should be positive.'\n",
        "        self.learning_rate = torch.ones(1) * learning_rate\n",
        "        self.learning_rate.to(device)\n",
        "\n",
        "    def update_params(self, names_weights_dict, names_grads_wrt_params_dict, num_step, tau=0.9):\n",
        "        \"\"\"Applies a single gradient descent update to all parameters.\n",
        "        All parameter updates are performed using in-place operations and so\n",
        "        nothing is returned.\n",
        "        Args:\n",
        "            grads_wrt_params: A list of gradients of the scalar loss function\n",
        "                with respect to each of the parameters passed to `initialise`\n",
        "                previously, with this list expected to be in the same order.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            key: names_weights_dict[key]\n",
        "            - self.learning_rate * names_grads_wrt_params_dict[key]\n",
        "            for key in names_weights_dict.keys()\n",
        "        }\n",
        "\n",
        "\n",
        "class LSLRGradientDescentLearningRule(nn.Module):\n",
        "    \"\"\"Simple (stochastic) gradient descent learning rule.\n",
        "    For a scalar error function `E(p[0], p_[1] ... )` of some set of\n",
        "    potentially multidimensional parameters this attempts to find a local\n",
        "    minimum of the loss function by applying updates to each parameter of the\n",
        "    form\n",
        "        p[i] := p[i] - learning_rate * dE/dp[i]\n",
        "    With `learning_rate` a positive scaling parameter.\n",
        "    The error function used in successive applications of these updates may be\n",
        "    a stochastic estimator of the true error function (e.g. when the error with\n",
        "    respect to only a subset of data-points is calculated) in which case this\n",
        "    will correspond to a stochastic gradient descent learning rule.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, device, total_num_inner_loop_steps, use_learnable_learning_rates, init_learning_rate=1e-3):\n",
        "        \"\"\"Creates a new learning rule object.\n",
        "        Args:\n",
        "            init_learning_rate: A postive scalar to scale gradient updates to the\n",
        "                parameters by. This needs to be carefully set - if too large\n",
        "                the learning dynamic will be unstable and may diverge, while\n",
        "                if set too small learning will proceed very slowly.\n",
        "        \"\"\"\n",
        "        super(LSLRGradientDescentLearningRule, self).__init__()\n",
        "        print(init_learning_rate)\n",
        "        assert init_learning_rate > 0., 'learning_rate should be positive.'\n",
        "\n",
        "        self.init_learning_rate = torch.ones(1) * init_learning_rate\n",
        "        self.init_learning_rate.to(device)\n",
        "        self.total_num_inner_loop_steps = total_num_inner_loop_steps\n",
        "        self.use_learnable_learning_rates = use_learnable_learning_rates\n",
        "\n",
        "    def initialise(self, names_weights_dict):\n",
        "        self.names_learning_rates_dict = nn.ParameterDict()\n",
        "        for idx, (key, param) in enumerate(names_weights_dict.items()):\n",
        "            self.names_learning_rates_dict[key.replace(\".\", \"-\")] = nn.Parameter(\n",
        "                data=torch.ones(self.total_num_inner_loop_steps + 1) * self.init_learning_rate,\n",
        "                requires_grad=self.use_learnable_learning_rates)\n",
        "\n",
        "    def reset(self):\n",
        "\n",
        "        # for key, param in self.names_learning_rates_dict.items():\n",
        "        #     param.fill_(self.init_learning_rate)\n",
        "        pass\n",
        "\n",
        "    def update_params(self, names_weights_dict, names_grads_wrt_params_dict, num_step, tau=0.1):\n",
        "        \"\"\"Applies a single gradient descent update to all parameters.\n",
        "        All parameter updates are performed using in-place operations and so\n",
        "        nothing is returned.\n",
        "        Args:\n",
        "            grads_wrt_params: A list of gradients of the scalar loss function\n",
        "                with respect to each of the parameters passed to `initialise`\n",
        "                previously, with this list expected to be in the same order.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            key: names_weights_dict[key]\n",
        "            - self.names_learning_rates_dict[key.replace(\".\", \"-\")][num_step]\n",
        "            * names_grads_wrt_params_dict[key]\n",
        "            for key in names_grads_wrt_params_dict.keys()\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9t22ksVdiybq"
      },
      "outputs": [],
      "source": [
        "class MAMLFewShotClassifier(nn.Module):\n",
        "    def __init__(self, im_shape, device, args):\n",
        "        \"\"\"\n",
        "        Initializes a MAML few shot learning system\n",
        "        :param im_shape: The images input size, in batch, c, h, w shape\n",
        "        :param device: The device to use to use the model on.\n",
        "        :param args: A namedtuple of arguments specifying various hyperparameters.\n",
        "        \"\"\"\n",
        "        super(MAMLFewShotClassifier, self).__init__()\n",
        "        self.args = args\n",
        "        self.device = device\n",
        "        self.batch_size = args.batch_size\n",
        "        self.use_cuda = args.use_cuda\n",
        "        self.im_shape = im_shape\n",
        "        self.current_epoch = 0\n",
        "\n",
        "        self.rng = set_torch_seed(seed=args.seed)\n",
        "        self.classifier = VGGReLUNormNetwork(im_shape=self.im_shape, num_output_classes=self.args.\n",
        "                                             num_classes_per_set,\n",
        "                                             args=args, device=device, meta_classifier=True).to(device=self.device)\n",
        "        self.task_learning_rate = args.task_learning_rate\n",
        "\n",
        "        self.inner_loop_optimizer = LSLRGradientDescentLearningRule(device=device,\n",
        "                                                                    init_learning_rate=self.task_learning_rate,\n",
        "                                                                    total_num_inner_loop_steps=self.args.number_of_training_steps_per_iter,\n",
        "                                                                    use_learnable_learning_rates=self.args.learnable_per_layer_per_step_inner_loop_learning_rate)\n",
        "        self.inner_loop_optimizer.initialise(\n",
        "            names_weights_dict=self.get_inner_loop_parameter_dict(params=self.classifier.named_parameters()))\n",
        "\n",
        "        print(\"Inner Loop parameters\")\n",
        "        for key, value in self.inner_loop_optimizer.named_parameters():\n",
        "            print(key, value.shape)\n",
        "\n",
        "        self._noise_size = 0.1\n",
        "\n",
        "        self.use_cuda = args.use_cuda\n",
        "        self.device = device\n",
        "        self.args = args\n",
        "        self.to(device)\n",
        "        print(\"Outer Loop parameters\")\n",
        "        for name, param in self.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                print(name, param.shape, param.device, param.requires_grad)\n",
        "\n",
        "\n",
        "        self.optimizer = optim.Adam(self.trainable_parameters(), lr=args.meta_learning_rate, amsgrad=False)\n",
        "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer=self.optimizer, T_max=self.args.total_epochs,\n",
        "                                                              eta_min=self.args.min_learning_rate)\n",
        "\n",
        "        self.device = torch.device('cpu')\n",
        "        if torch.cuda.is_available():\n",
        "            if torch.cuda.device_count() > 1:\n",
        "                self.to(torch.cuda.current_device())\n",
        "                self.classifier = nn.DataParallel(module=self.classifier)\n",
        "            else:\n",
        "                self.to(torch.cuda.current_device())\n",
        "\n",
        "            self.device = torch.cuda.current_device()\n",
        "\n",
        "    def get_per_step_loss_importance_vector(self):\n",
        "        \"\"\"\n",
        "        Generates a tensor of dimensionality (num_inner_loop_steps) indicating the importance of each step's target\n",
        "        loss towards the optimization loss.\n",
        "        :return: A tensor to be used to compute the weighted average of the loss, useful for\n",
        "        the MSL (Multi Step Loss) mechanism.\n",
        "        \"\"\"\n",
        "        loss_weights = np.ones(shape=(self.args.number_of_training_steps_per_iter)) * (\n",
        "                1.0 / self.args.number_of_training_steps_per_iter)\n",
        "        decay_rate = 1.0 / self.args.number_of_training_steps_per_iter / self.args.multi_step_loss_num_epochs\n",
        "        min_value_for_non_final_losses = 0.03 / self.args.number_of_training_steps_per_iter\n",
        "        for i in range(len(loss_weights) - 1):\n",
        "            curr_value = np.maximum(loss_weights[i] - (self.current_epoch * decay_rate), min_value_for_non_final_losses)\n",
        "            loss_weights[i] = curr_value\n",
        "\n",
        "        curr_value = np.minimum(\n",
        "            loss_weights[-1] + (self.current_epoch * (self.args.number_of_training_steps_per_iter - 1) * decay_rate),\n",
        "            1.0 - ((self.args.number_of_training_steps_per_iter - 1) * min_value_for_non_final_losses))\n",
        "        loss_weights[-1] = curr_value\n",
        "        loss_weights = torch.Tensor(loss_weights).to(device=self.device)\n",
        "        return loss_weights\n",
        "\n",
        "    def get_inner_loop_parameter_dict(self, params):\n",
        "        \"\"\"\n",
        "        Returns a dictionary with the parameters to use for inner loop updates.\n",
        "        :param params: A dictionary of the network's parameters.\n",
        "        :return: A dictionary of the parameters to use for the inner loop optimization process.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            name: param.to(device=self.device)\n",
        "            for name, param in params\n",
        "            if param.requires_grad\n",
        "            and (\n",
        "                not self.args.enable_inner_loop_optimizable_bn_params\n",
        "                and \"norm_layer\" not in name\n",
        "                or self.args.enable_inner_loop_optimizable_bn_params\n",
        "            )\n",
        "        }\n",
        "\n",
        "    def apply_inner_loop_update(self, loss, names_weights_copy, use_second_order, current_step_idx):\n",
        "        \"\"\"\n",
        "        Applies an inner loop update given current step's loss, the weights to update, a flag indicating whether to use\n",
        "        second order derivatives and the current step's index.\n",
        "        :param loss: Current step's loss with respect to the support set.\n",
        "        :param names_weights_copy: A dictionary with names to parameters to update.\n",
        "        :param use_second_order: A boolean flag of whether to use second order derivatives.\n",
        "        :param current_step_idx: Current step's index.\n",
        "        :return: A dictionary with the updated weights (name, param)\n",
        "        \"\"\"\n",
        "        num_gpus = torch.cuda.device_count()\n",
        "        if num_gpus > 1:\n",
        "            self.classifier.module.zero_grad(params=names_weights_copy)\n",
        "        else:\n",
        "            self.classifier.zero_grad(params=names_weights_copy)\n",
        "\n",
        "        grads = torch.autograd.grad(loss, names_weights_copy.values(),\n",
        "                                    create_graph=use_second_order, allow_unused=True)\n",
        "        names_grads_copy = dict(zip(names_weights_copy.keys(), grads))\n",
        "\n",
        "        names_weights_copy = {key: value[0] for key, value in names_weights_copy.items()}\n",
        "\n",
        "        for key, grad in names_grads_copy.items():\n",
        "            if grad is None:\n",
        "                print('Grads not found for inner loop parameter', key)\n",
        "            names_grads_copy[key] = names_grads_copy[key].sum(dim=0)\n",
        "\n",
        "\n",
        "        names_weights_copy = self.inner_loop_optimizer.update_params(names_weights_dict=names_weights_copy,\n",
        "                                                                     names_grads_wrt_params_dict=names_grads_copy,\n",
        "                                                                     num_step=current_step_idx)\n",
        "\n",
        "        num_devices = torch.cuda.device_count() if torch.cuda.is_available() else 1\n",
        "        names_weights_copy = {\n",
        "            name.replace('module.', ''): value.unsqueeze(0).repeat(\n",
        "                [num_devices] + [1 for i in range(len(value.shape))]) for\n",
        "            name, value in names_weights_copy.items()}\n",
        "\n",
        "\n",
        "        return names_weights_copy\n",
        "\n",
        "    def get_across_task_loss_metrics(self, total_losses, total_accuracies):\n",
        "        losses = {'loss': torch.mean(torch.stack(total_losses))}\n",
        "\n",
        "        losses['accuracy'] = np.mean(total_accuracies)\n",
        "\n",
        "        return losses\n",
        "\n",
        "    def forward(self, data_batch, epoch, use_second_order, use_multi_step_loss_optimization, num_steps, training_phase):\n",
        "        \"\"\"\n",
        "        Runs a forward outer loop pass on the batch of tasks using the MAML/++ framework.\n",
        "        :param data_batch: A data batch containing the support and target sets.\n",
        "        :param epoch: Current epoch's index\n",
        "        :param use_second_order: A boolean saying whether to use second order derivatives.\n",
        "        :param use_multi_step_loss_optimization: Whether to optimize on the outer loop using just the last step's\n",
        "        target loss (True) or whether to use multi step loss which improves the stability of the system (False)\n",
        "        :param num_steps: Number of inner loop steps.\n",
        "        :param training_phase: Whether this is a training phase (True) or an evaluation phase (False)\n",
        "        :return: A dictionary with the collected losses of the current outer forward propagation.\n",
        "        \"\"\"\n",
        "        x_support_set, x_target_set, y_support_set, y_target_set = data_batch\n",
        "\n",
        "        [b, ncs, spc] = y_support_set.shape\n",
        "\n",
        "        self.num_classes_per_set = ncs\n",
        "\n",
        "        total_losses = []\n",
        "        total_accuracies = []\n",
        "        per_task_target_preds = [[] for i in range(len(x_target_set))]\n",
        "        self.classifier.zero_grad()\n",
        "        task_accuracies = []\n",
        "        for task_id, (x_support_set_task, y_support_set_task, x_target_set_task, y_target_set_task) in enumerate(zip(x_support_set,\n",
        "                              y_support_set,\n",
        "                              x_target_set,\n",
        "                              y_target_set)):\n",
        "            task_losses = []\n",
        "            per_step_loss_importance_vectors = self.get_per_step_loss_importance_vector()\n",
        "            names_weights_copy = self.get_inner_loop_parameter_dict(self.classifier.named_parameters())\n",
        "\n",
        "            num_devices = torch.cuda.device_count() if torch.cuda.is_available() else 1\n",
        "\n",
        "            names_weights_copy = {\n",
        "                name.replace('module.', ''): value.unsqueeze(0).repeat(\n",
        "                    [num_devices] + [1 for i in range(len(value.shape))]) for\n",
        "                name, value in names_weights_copy.items()}\n",
        "\n",
        "            n, s, c, h, w = x_target_set_task.shape\n",
        "\n",
        "            x_support_set_task = x_support_set_task.view(-1, c, h, w)\n",
        "            y_support_set_task = y_support_set_task.view(-1)\n",
        "            x_target_set_task = x_target_set_task.view(-1, c, h, w)\n",
        "            y_target_set_task = y_target_set_task.view(-1)\n",
        "\n",
        "            for num_step in range(num_steps):\n",
        "\n",
        "                support_loss, support_preds = self.net_forward(\n",
        "                    x=x_support_set_task,\n",
        "                    y=y_support_set_task,\n",
        "                    weights=names_weights_copy,\n",
        "                    backup_running_statistics=num_step == 0,\n",
        "                    training=True,\n",
        "                    num_step=num_step,\n",
        "                )\n",
        "\n",
        "\n",
        "                names_weights_copy = self.apply_inner_loop_update(loss=support_loss,\n",
        "                                                                  names_weights_copy=names_weights_copy,\n",
        "                                                                  use_second_order=use_second_order,\n",
        "                                                                  current_step_idx=num_step)\n",
        "\n",
        "                if use_multi_step_loss_optimization and training_phase and epoch < self.args.multi_step_loss_num_epochs:\n",
        "                    target_loss, target_preds = self.net_forward(x=x_target_set_task,\n",
        "                                                                 y=y_target_set_task, weights=names_weights_copy,\n",
        "                                                                 backup_running_statistics=False, training=True,\n",
        "                                                                 num_step=num_step)\n",
        "\n",
        "                    task_losses.append(per_step_loss_importance_vectors[num_step] * target_loss)\n",
        "                elif num_step == (self.args.number_of_training_steps_per_iter - 1):\n",
        "                    target_loss, target_preds = self.net_forward(x=x_target_set_task,\n",
        "                                                                 y=y_target_set_task, weights=names_weights_copy,\n",
        "                                                                 backup_running_statistics=False, training=True,\n",
        "                                                                 num_step=num_step)\n",
        "                    task_losses.append(target_loss)\n",
        "\n",
        "            per_task_target_preds[task_id] = target_preds.detach().cpu().numpy()\n",
        "            _, predicted = torch.max(target_preds.data, 1)\n",
        "\n",
        "            accuracy = predicted.float().eq(y_target_set_task.data.float()).cpu().float()\n",
        "            task_losses = torch.sum(torch.stack(task_losses))\n",
        "            total_losses.append(task_losses)\n",
        "            total_accuracies.extend(accuracy)\n",
        "\n",
        "            if not training_phase:\n",
        "                self.classifier.restore_backup_stats()\n",
        "\n",
        "        losses = self.get_across_task_loss_metrics(total_losses=total_losses,\n",
        "                                                   total_accuracies=total_accuracies)\n",
        "\n",
        "        for idx, item in enumerate(per_step_loss_importance_vectors):\n",
        "            losses['loss_importance_vector_{}'.format(idx)] = item.detach().cpu().numpy()\n",
        "\n",
        "        return losses, per_task_target_preds\n",
        "\n",
        "    def net_forward(self, x, y, weights, backup_running_statistics, training, num_step):\n",
        "        \"\"\"\n",
        "        A base model forward pass on some data points x. Using the parameters in the weights dictionary. Also requires\n",
        "        boolean flags indicating whether to reset the running statistics at the end of the run (if at evaluation phase).\n",
        "        A flag indicating whether this is the training session and an int indicating the current step's number in the\n",
        "        inner loop.\n",
        "        :param x: A data batch of shape b, c, h, w\n",
        "        :param y: A data targets batch of shape b, n_classes\n",
        "        :param weights: A dictionary containing the weights to pass to the network.\n",
        "        :param backup_running_statistics: A flag indicating whether to reset the batch norm running statistics to their\n",
        "         previous values after the run (only for evaluation)\n",
        "        :param training: A flag indicating whether the current process phase is a training or evaluation.\n",
        "        :param num_step: An integer indicating the number of the step in the inner loop.\n",
        "        :return: the crossentropy losses with respect to the given y, the predictions of the base model.\n",
        "        \"\"\"\n",
        "        preds = self.classifier.forward(x=x, params=weights,\n",
        "                                        training=training,\n",
        "                                        backup_running_statistics=backup_running_statistics, num_step=num_step)\n",
        "\n",
        "        loss = F.cross_entropy(input=preds, target=y)\n",
        "\n",
        "        return loss, preds\n",
        "\n",
        "    def trainable_parameters(self):\n",
        "        \"\"\"\n",
        "        Returns an iterator over the trainable parameters of the model.\n",
        "        \"\"\"\n",
        "        for param in self.parameters():\n",
        "            if param.requires_grad:\n",
        "                noise = torch.randn_like(param) * self._noise_size  # TODO EXPERIMENT WITH THIS\n",
        "                print(f\"the grinch added {noise} amount of noise :)\")\n",
        "                param.data.add_(noise)\n",
        "                yield param\n",
        "\n",
        "    def train_forward_prop(self, data_batch, epoch):\n",
        "        \"\"\"\n",
        "        Runs an outer loop forward prop using the meta-model and base-model.\n",
        "        :param data_batch: A data batch containing the support set and the target set input, output pairs.\n",
        "        :param epoch: The index of the currrent epoch.\n",
        "        :return: A dictionary of losses for the current step.\n",
        "        \"\"\"\n",
        "        losses, per_task_target_preds = self.forward(data_batch=data_batch, epoch=epoch,\n",
        "                                                     use_second_order=self.args.second_order and\n",
        "                                                                      epoch > self.args.first_order_to_second_order_epoch,\n",
        "                                                     use_multi_step_loss_optimization=self.args.use_multi_step_loss_optimization,\n",
        "                                                     num_steps=self.args.number_of_training_steps_per_iter,\n",
        "                                                     training_phase=True)\n",
        "        return losses, per_task_target_preds\n",
        "\n",
        "    def evaluation_forward_prop(self, data_batch, epoch):\n",
        "        \"\"\"\n",
        "        Runs an outer loop evaluation forward prop using the meta-model and base-model.\n",
        "        :param data_batch: A data batch containing the support set and the target set input, output pairs.\n",
        "        :param epoch: The index of the currrent epoch.\n",
        "        :return: A dictionary of losses for the current step.\n",
        "        \"\"\"\n",
        "        losses, per_task_target_preds = self.forward(data_batch=data_batch, epoch=epoch, use_second_order=False,\n",
        "                                                     use_multi_step_loss_optimization=True,\n",
        "                                                     num_steps=self.args.number_of_evaluation_steps_per_iter,\n",
        "                                                     training_phase=False)\n",
        "\n",
        "        return losses, per_task_target_preds\n",
        "\n",
        "    def meta_update(self, loss):\n",
        "        \"\"\"\n",
        "        Applies an outer loop update on the meta-parameters of the model.\n",
        "        :param loss: The current crossentropy loss.\n",
        "        \"\"\"\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        if 'imagenet' in self.args.dataset_name:\n",
        "            for name, param in self.classifier.named_parameters():\n",
        "                if param.requires_grad:\n",
        "                    param.grad.data.clamp_(-10, 10)  # not sure if this is necessary, more experiments are needed\n",
        "        self._noise_size *= 0.95\n",
        "        print(f\"noise size: {self._noise_size}\")\n",
        "        self.optimizer.step()\n",
        "\n",
        "    def run_train_iter(self, data_batch, epoch):\n",
        "        \"\"\"\n",
        "        Runs an outer loop update step on the meta-model's parameters.\n",
        "        :param data_batch: input data batch containing the support set and target set input, output pairs\n",
        "        :param epoch: the index of the current epoch\n",
        "        :return: The losses of the ran iteration.\n",
        "        \"\"\"\n",
        "        epoch = int(epoch)\n",
        "        if epoch > 1:\n",
        "          self.scheduler.step(epoch=epoch)\n",
        "        if self.current_epoch != epoch:\n",
        "            self.current_epoch = epoch\n",
        "\n",
        "        if not self.training:\n",
        "            self.train()\n",
        "\n",
        "        x_support_set, x_target_set, y_support_set, y_target_set = data_batch\n",
        "\n",
        "        x_support_set = torch.Tensor(x_support_set).float().to(device=self.device)\n",
        "        x_target_set = torch.Tensor(x_target_set).float().to(device=self.device)\n",
        "        y_support_set = torch.Tensor(y_support_set).long().to(device=self.device)\n",
        "        y_target_set = torch.Tensor(y_target_set).long().to(device=self.device)\n",
        "\n",
        "        data_batch = (x_support_set, x_target_set, y_support_set, y_target_set)\n",
        "\n",
        "        losses, per_task_target_preds = self.train_forward_prop(data_batch=data_batch, epoch=epoch)\n",
        "\n",
        "        self.meta_update(loss=losses['loss'])\n",
        "        losses['learning_rate'] = self.scheduler.get_last_lr()[0]\n",
        "        self.optimizer.zero_grad()\n",
        "        self.zero_grad()\n",
        "\n",
        "        return losses, per_task_target_preds\n",
        "\n",
        "    def run_validation_iter(self, data_batch):\n",
        "        \"\"\"\n",
        "        Runs an outer loop evaluation step on the meta-model's parameters.\n",
        "        :param data_batch: input data batch containing the support set and target set input, output pairs\n",
        "        :param epoch: the index of the current epoch\n",
        "        :return: The losses of the ran iteration.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.training:\n",
        "            self.eval()\n",
        "\n",
        "        x_support_set, x_target_set, y_support_set, y_target_set = data_batch\n",
        "\n",
        "        x_support_set = torch.Tensor(x_support_set).float().to(device=self.device)\n",
        "        x_target_set = torch.Tensor(x_target_set).float().to(device=self.device)\n",
        "        y_support_set = torch.Tensor(y_support_set).long().to(device=self.device)\n",
        "        y_target_set = torch.Tensor(y_target_set).long().to(device=self.device)\n",
        "\n",
        "        data_batch = (x_support_set, x_target_set, y_support_set, y_target_set)\n",
        "\n",
        "        losses, per_task_target_preds = self.evaluation_forward_prop(data_batch=data_batch, epoch=self.current_epoch)\n",
        "\n",
        "        # losses['loss'].backward() # uncomment if you get the weird memory error\n",
        "        # self.zero_grad()\n",
        "        # self.optimizer.zero_grad()\n",
        "\n",
        "        return losses, per_task_target_preds\n",
        "\n",
        "    def save_model(self, model_save_dir, state):\n",
        "        \"\"\"\n",
        "        Save the network parameter state and experiment state dictionary.\n",
        "        :param model_save_dir: The directory to store the state at.\n",
        "        :param state: The state containing the experiment state and the network. It's in the form of a dictionary\n",
        "        object.\n",
        "        \"\"\"\n",
        "        state['network'] = self.state_dict()\n",
        "        state['optimizer'] = self.optimizer.state_dict()\n",
        "        torch.save(state, f=model_save_dir)\n",
        "\n",
        "    def load_model(self, model_save_dir, model_name, model_idx):\n",
        "        \"\"\"\n",
        "        Load checkpoint and return the state dictionary containing the network state params and experiment state.\n",
        "        :param model_save_dir: The directory from which to load the files.\n",
        "        :param model_name: The model_name to be loaded from the direcotry.\n",
        "        :param model_idx: The index of the model (i.e. epoch number or 'latest' for the latest saved model of the current\n",
        "        experiment)\n",
        "        :return: A dictionary containing the experiment state and the saved model parameters.\n",
        "        \"\"\"\n",
        "        filepath = os.path.join(model_save_dir, \"{}_{}\".format(model_name, model_idx))\n",
        "        state = torch.load(filepath)\n",
        "        state_dict_loaded = state['network']\n",
        "        self.optimizer.load_state_dict(state['optimizer'])\n",
        "        self.load_state_dict(state_dict=state_dict_loaded)\n",
        "        return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTJUQiySnDQi"
      },
      "source": [
        "# Layer Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "w0JKoFtCnWZZ"
      },
      "outputs": [],
      "source": [
        "import numbers\n",
        "from copy import copy\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_ZTbS3zjnOD5"
      },
      "outputs": [],
      "source": [
        "def extract_top_level_dict(current_dict):\n",
        "    \"\"\"\n",
        "    Builds a graph dictionary from the passed depth_keys, value pair. Useful for dynamically passing external params\n",
        "    :param depth_keys: A list of strings making up the name of a variable. Used to make a graph for that params tree.\n",
        "    :param value: Param value\n",
        "    :param key_exists: If none then assume new dict, else load existing dict and add new key->value pairs to it.\n",
        "    :return: A dictionary graph of the params already added to the graph.\n",
        "    \"\"\"\n",
        "    output_dict = {}\n",
        "    for key in current_dict.keys():\n",
        "        name = key.replace(\"layer_dict.\", \"\")\n",
        "        name = name.replace(\"layer_dict.\", \"\")\n",
        "        name = name.replace(\"block_dict.\", \"\")\n",
        "        name = name.replace(\"module-\", \"\")\n",
        "        top_level = name.split(\".\")[0]\n",
        "        sub_level = \".\".join(name.split(\".\")[1:])\n",
        "\n",
        "        if top_level in output_dict:\n",
        "            new_item = {key: value for key, value in output_dict[top_level].items()}\n",
        "            new_item[sub_level] = current_dict[key]\n",
        "            output_dict[top_level] = new_item\n",
        "\n",
        "        elif sub_level == \"\":\n",
        "            output_dict[top_level] = current_dict[key]\n",
        "        else:\n",
        "            output_dict[top_level] = {sub_level: current_dict[key]}\n",
        "    #print(current_dict.keys(), output_dict.keys())\n",
        "    return output_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y1N7ERJmnZpx"
      },
      "outputs": [],
      "source": [
        "class MetaConv2dLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, use_bias, groups=1, dilation_rate=1):\n",
        "        \"\"\"\n",
        "        A MetaConv2D layer. Applies the same functionality of a standard Conv2D layer with the added functionality of\n",
        "        being able to receive a parameter dictionary at the forward pass which allows the convolution to use external\n",
        "        weights instead of the internal ones stored in the conv layer. Useful for inner loop optimization in the meta\n",
        "        learning setting.\n",
        "        :param in_channels: Number of input channels\n",
        "        :param out_channels: Number of output channels\n",
        "        :param kernel_size: Convolutional kernel size\n",
        "        :param stride: Convolutional stride\n",
        "        :param padding: Convolution padding\n",
        "        :param use_bias: Boolean indicating whether to use a bias or not.\n",
        "        \"\"\"\n",
        "        super(MetaConv2dLayer, self).__init__()\n",
        "        num_filters = out_channels\n",
        "        self.stride = int(stride)\n",
        "        self.padding = int(padding)\n",
        "        self.dilation_rate = int(dilation_rate)\n",
        "        self.use_bias = use_bias\n",
        "        self.groups = int(groups)\n",
        "        self.weight = nn.Parameter(torch.empty(num_filters, in_channels, kernel_size, kernel_size))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = nn.Parameter(torch.zeros(num_filters))\n",
        "\n",
        "    def forward(self, x, params=None):\n",
        "        \"\"\"\n",
        "        Applies a conv2D forward pass. If params are not None will use the passed params as the conv weights and biases\n",
        "        :param x: Input image batch.\n",
        "        :param params: If none, then conv layer will use the stored self.weights and self.bias, if they are not none\n",
        "        then the conv layer will use the passed params as its parameters.\n",
        "        :return: The output of a convolutional function.\n",
        "        \"\"\"\n",
        "        if params is not None:\n",
        "            params = extract_top_level_dict(current_dict=params)\n",
        "            if self.use_bias:\n",
        "                (weight, bias) = params[\"weight\"], params[\"bias\"]\n",
        "            else:\n",
        "                (weight) = params[\"weight\"]\n",
        "                bias = None\n",
        "        elif self.use_bias:\n",
        "            weight, bias = self.weight, self.bias\n",
        "        else:\n",
        "            weight = self.weight\n",
        "            bias = None\n",
        "\n",
        "        return F.conv2d(\n",
        "            input=x,\n",
        "            weight=weight,\n",
        "            bias=bias,\n",
        "            stride=self.stride,\n",
        "            padding=self.padding,\n",
        "            dilation=self.dilation_rate,\n",
        "            groups=self.groups,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EvrE9o8Vnf6q"
      },
      "outputs": [],
      "source": [
        "class MetaLinearLayer(nn.Module):\n",
        "    def __init__(self, input_shape, num_filters, use_bias):\n",
        "        \"\"\"\n",
        "        A MetaLinear layer. Applies the same functionality of a standard linearlayer with the added functionality of\n",
        "        being able to receive a parameter dictionary at the forward pass which allows the convolution to use external\n",
        "        weights instead of the internal ones stored in the linear layer. Useful for inner loop optimization in the meta\n",
        "        learning setting.\n",
        "        :param input_shape: The shape of the input data, in the form (b, f)\n",
        "        :param num_filters: Number of output filters\n",
        "        :param use_bias: Whether to use biases or not.\n",
        "        \"\"\"\n",
        "        super(MetaLinearLayer, self).__init__()\n",
        "        b, c = input_shape\n",
        "\n",
        "        self.use_bias = use_bias\n",
        "        self.weights = nn.Parameter(torch.ones(num_filters, c))\n",
        "        # nn.init.xavier_uniform_(self.weights) TODO CHANGE BACK TEST GENE (it works kinda)\n",
        "        if self.use_bias:\n",
        "            self.bias = nn.Parameter(torch.zeros(num_filters))\n",
        "\n",
        "    def forward(self, x, params=None):\n",
        "        \"\"\"\n",
        "        Forward propagates by applying a linear function (Wx + b). If params are none then internal params are used.\n",
        "        Otherwise passed params will be used to execute the function.\n",
        "        :param x: Input data batch, in the form (b, f)\n",
        "        :param params: A dictionary containing 'weights' and 'bias'. If params are none then internal params are used.\n",
        "        Otherwise the external are used.\n",
        "        :return: The result of the linear function.\n",
        "        \"\"\"\n",
        "        if params is not None:\n",
        "            params = extract_top_level_dict(current_dict=params)\n",
        "            if self.use_bias:\n",
        "                (weight, bias) = params[\"weights\"], params[\"bias\"]\n",
        "            else:\n",
        "                (weight) = params[\"weights\"]\n",
        "                bias = None\n",
        "        elif self.use_bias:\n",
        "            weight, bias = self.weights, self.bias\n",
        "        else:\n",
        "            weight = self.weights\n",
        "            bias = None\n",
        "        return F.linear(input=x, weight=weight, bias=bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "b4UV1OiDnkU7"
      },
      "outputs": [],
      "source": [
        "class MetaBatchNormLayer(nn.Module):\n",
        "    def __init__(self, num_features, device, args, eps=1e-5, momentum=0.1, affine=True,\n",
        "                 track_running_stats=True, meta_batch_norm=True, no_learnable_params=False,\n",
        "                 use_per_step_bn_statistics=False):\n",
        "        \"\"\"\n",
        "        A MetaBatchNorm layer. Applies the same functionality of a standard BatchNorm layer with the added functionality of\n",
        "        being able to receive a parameter dictionary at the forward pass which allows the convolution to use external\n",
        "        weights instead of the internal ones stored in the conv layer. Useful for inner loop optimization in the meta\n",
        "        learning setting. Also has the additional functionality of being able to store per step running stats and per step beta and gamma.\n",
        "        :param num_features:\n",
        "        :param device:\n",
        "        :param args:\n",
        "        :param eps:\n",
        "        :param momentum:\n",
        "        :param affine:\n",
        "        :param track_running_stats:\n",
        "        :param meta_batch_norm:\n",
        "        :param no_learnable_params:\n",
        "        :param use_per_step_bn_statistics:\n",
        "        \"\"\"\n",
        "        super(MetaBatchNormLayer, self).__init__()\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "\n",
        "        self.affine = affine\n",
        "        self.track_running_stats = track_running_stats\n",
        "        self.meta_batch_norm = meta_batch_norm\n",
        "        self.num_features = num_features\n",
        "        self.device = device\n",
        "        self.use_per_step_bn_statistics = use_per_step_bn_statistics\n",
        "        self.args = args\n",
        "        self.learnable_gamma = self.args.learnable_bn_gamma\n",
        "        self.learnable_beta = self.args.learnable_bn_beta\n",
        "\n",
        "        if use_per_step_bn_statistics:\n",
        "            self.running_mean = nn.Parameter(torch.zeros(args.number_of_training_steps_per_iter, num_features),\n",
        "                                             requires_grad=False)\n",
        "            self.running_var = nn.Parameter(torch.ones(args.number_of_training_steps_per_iter, num_features),\n",
        "                                            requires_grad=False)\n",
        "            self.bias = nn.Parameter(torch.zeros(args.number_of_training_steps_per_iter, num_features),\n",
        "                                     requires_grad=self.learnable_beta)\n",
        "            self.weight = nn.Parameter(torch.ones(args.number_of_training_steps_per_iter, num_features),\n",
        "                                       requires_grad=self.learnable_gamma)\n",
        "        else:\n",
        "            self.running_mean = nn.Parameter(torch.zeros(num_features), requires_grad=False)\n",
        "            self.running_var = nn.Parameter(torch.zeros(num_features), requires_grad=False)\n",
        "            self.bias = nn.Parameter(torch.zeros(num_features),\n",
        "                                     requires_grad=self.learnable_beta)\n",
        "            self.weight = nn.Parameter(torch.ones(num_features),\n",
        "                                       requires_grad=self.learnable_gamma)\n",
        "\n",
        "        if self.args.enable_inner_loop_optimizable_bn_params:\n",
        "            self.bias = nn.Parameter(torch.zeros(num_features),\n",
        "                                     requires_grad=self.learnable_beta)\n",
        "            self.weight = nn.Parameter(torch.ones(num_features),\n",
        "                                       requires_grad=self.learnable_gamma)\n",
        "\n",
        "        self.backup_running_mean = torch.zeros(self.running_mean.shape)\n",
        "        self.backup_running_var = torch.ones(self.running_var.shape)\n",
        "\n",
        "        self.momentum = momentum\n",
        "\n",
        "    def forward(self, input, num_step, params=None, training=False, backup_running_statistics=False):\n",
        "        \"\"\"\n",
        "        Forward propagates by applying a bach norm function. If params are none then internal params are used.\n",
        "        Otherwise passed params will be used to execute the function.\n",
        "        :param input: input data batch, size either can be any.\n",
        "        :param num_step: The current inner loop step being taken. This is used when we are learning per step params and\n",
        "         collecting per step batch statistics. It indexes the correct object to use for the current time-step\n",
        "        :param params: A dictionary containing 'weight' and 'bias'.\n",
        "        :param training: Whether this is currently the training or evaluation phase.\n",
        "        :param backup_running_statistics: Whether to backup the running statistics. This is used\n",
        "        at evaluation time, when after the pass is complete we want to throw away the collected validation stats.\n",
        "        :return: The result of the batch norm operation.\n",
        "        \"\"\"\n",
        "        if params is not None:\n",
        "            params = extract_top_level_dict(current_dict=params)\n",
        "            (weight, bias) = params[\"weight\"], params[\"bias\"]\n",
        "            #print(num_step, params['weight'])\n",
        "        else:\n",
        "            #print(num_step, \"no params\")\n",
        "            weight, bias = self.weight, self.bias\n",
        "\n",
        "        if self.use_per_step_bn_statistics:\n",
        "            running_mean = self.running_mean[num_step]\n",
        "            running_var = self.running_var[num_step]\n",
        "            if (\n",
        "                params is None\n",
        "                and not self.args.enable_inner_loop_optimizable_bn_params\n",
        "            ):\n",
        "                bias = self.bias[num_step]\n",
        "                weight = self.weight[num_step]\n",
        "        else:\n",
        "            running_mean = None\n",
        "            running_var = None\n",
        "\n",
        "\n",
        "        if backup_running_statistics and self.use_per_step_bn_statistics:\n",
        "            self.backup_running_mean.data = copy(self.running_mean.data)\n",
        "            self.backup_running_var.data = copy(self.running_var.data)\n",
        "\n",
        "        momentum = self.momentum\n",
        "\n",
        "        return F.batch_norm(input, running_mean, running_var, weight, bias,\n",
        "                              training=True, momentum=momentum, eps=self.eps)\n",
        "\n",
        "    def restore_backup_stats(self):\n",
        "        \"\"\"\n",
        "        Resets batch statistics to their backup values which are collected after each forward pass.\n",
        "        \"\"\"\n",
        "        if self.use_per_step_bn_statistics:\n",
        "            self.running_mean = nn.Parameter(self.backup_running_mean.to(device=self.device), requires_grad=False)\n",
        "            self.running_var = nn.Parameter(self.backup_running_var.to(device=self.device), requires_grad=False)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return '{num_features}, eps={eps}, momentum={momentum}, affine={affine}, ' \\\n",
        "               'track_running_stats={track_running_stats}'.format(**self.__dict__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6nEWVSSLnna2"
      },
      "outputs": [],
      "source": [
        "class MetaLayerNormLayer(nn.Module):\n",
        "    def __init__(self, input_feature_shape, eps=1e-5, elementwise_affine=True):\n",
        "        \"\"\"\n",
        "        A MetaLayerNorm layer. A layer that applies the same functionality as a layer norm layer with the added\n",
        "        capability of being able to receive params at inference time to use instead of the internal ones. As well as\n",
        "        being able to use its own internal weights.\n",
        "        :param input_feature_shape: The input shape without the batch dimension, e.g. c, h, w\n",
        "        :param eps: Epsilon to use for protection against overflows\n",
        "        :param elementwise_affine: Whether to learn a multiplicative interaction parameter 'w' in addition to\n",
        "        the biases.\n",
        "        \"\"\"\n",
        "        super(MetaLayerNormLayer, self).__init__()\n",
        "        if isinstance(input_feature_shape, numbers.Integral):\n",
        "            input_feature_shape = (input_feature_shape,)\n",
        "        self.normalized_shape = torch.Size(input_feature_shape)\n",
        "        self.eps = eps\n",
        "        self.elementwise_affine = elementwise_affine\n",
        "        if self.elementwise_affine:\n",
        "            self.weight = nn.Parameter(torch.Tensor(*input_feature_shape), requires_grad=False)\n",
        "            self.bias = nn.Parameter(torch.Tensor(*input_feature_shape))\n",
        "        else:\n",
        "            self.register_parameter('weight', None)\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"\n",
        "        Reset parameters to their initialization values.\n",
        "        \"\"\"\n",
        "        if self.elementwise_affine:\n",
        "            self.weight.data.fill_(1)\n",
        "            self.bias.data.zero_()\n",
        "\n",
        "    def forward(self, input, num_step, params=None, training=False, backup_running_statistics=False):\n",
        "        \"\"\"\n",
        "            Forward propagates by applying a layer norm function. If params are none then internal params are used.\n",
        "            Otherwise passed params will be used to execute the function.\n",
        "            :param input: input data batch, size either can be any.\n",
        "            :param num_step: The current inner loop step being taken. This is used when we are learning per step params and\n",
        "             collecting per step batch statistics. It indexes the correct object to use for the current time-step\n",
        "            :param params: A dictionary containing 'weight' and 'bias'.\n",
        "            :param training: Whether this is currently the training or evaluation phase.\n",
        "            :param backup_running_statistics: Whether to backup the running statistics. This is used\n",
        "            at evaluation time, when after the pass is complete we want to throw away the collected validation stats.\n",
        "            :return: The result of the batch norm operation.\n",
        "        \"\"\"\n",
        "        if params is not None:\n",
        "            params = extract_top_level_dict(current_dict=params)\n",
        "            bias = params[\"bias\"]\n",
        "        else:\n",
        "            bias = self.bias\n",
        "            #print('no inner loop params', self)\n",
        "\n",
        "        return F.layer_norm(\n",
        "            input, self.normalized_shape, self.weight, bias, self.eps)\n",
        "\n",
        "    def restore_backup_stats(self):\n",
        "        pass\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return '{normalized_shape}, eps={eps}, ' \\\n",
        "               'elementwise_affine={elementwise_affine}'.format(**self.__dict__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "j1Jj9kodnrOV"
      },
      "outputs": [],
      "source": [
        "class MetaConvNormLayerReLU(nn.Module):\n",
        "    def __init__(self, input_shape, num_filters, kernel_size, stride, padding, use_bias, args, normalization=True,\n",
        "                 meta_layer=True, no_bn_learnable_params=False, device=None):\n",
        "        \"\"\"\n",
        "           Initializes a BatchNorm->Conv->ReLU layer which applies those operation in that order.\n",
        "           :param args: A named tuple containing the system's hyperparameters.\n",
        "           :param device: The device to run the layer on.\n",
        "           :param normalization: The type of normalization to use 'batch_norm' or 'layer_norm'\n",
        "           :param meta_layer: Whether this layer will require meta-layer capabilities such as meta-batch norm,\n",
        "           meta-conv etc.\n",
        "           :param input_shape: The image input shape in the form (b, c, h, w)\n",
        "           :param num_filters: number of filters for convolutional layer\n",
        "           :param kernel_size: the kernel size of the convolutional layer\n",
        "           :param stride: the stride of the convolutional layer\n",
        "           :param padding: the bias of the convolutional layer\n",
        "           :param use_bias: whether the convolutional layer utilizes a bias\n",
        "        \"\"\"\n",
        "        super(MetaConvNormLayerReLU, self).__init__()\n",
        "        self.normalization = normalization\n",
        "        self.use_per_step_bn_statistics = args.per_step_bn_statistics\n",
        "        self.input_shape = input_shape\n",
        "        self.args = args\n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.use_bias = use_bias\n",
        "        self.meta_layer = meta_layer\n",
        "        self.no_bn_learnable_params = no_bn_learnable_params\n",
        "        self.device = device\n",
        "        self.layer_dict = nn.ModuleDict()\n",
        "        self.build_block()\n",
        "\n",
        "    def build_block(self):\n",
        "\n",
        "        x = torch.zeros(self.input_shape)\n",
        "\n",
        "        out = x\n",
        "\n",
        "        self.conv = MetaConv2dLayer(in_channels=out.shape[1], out_channels=self.num_filters,\n",
        "                                    kernel_size=self.kernel_size,\n",
        "                                    stride=self.stride, padding=self.padding, use_bias=self.use_bias)\n",
        "\n",
        "\n",
        "\n",
        "        out = self.conv(out)\n",
        "\n",
        "        if self.normalization:\n",
        "            if self.args.norm_layer == \"batch_norm\":\n",
        "                self.norm_layer = MetaBatchNormLayer(out.shape[1], track_running_stats=True,\n",
        "                                                     meta_batch_norm=self.meta_layer,\n",
        "                                                     no_learnable_params=self.no_bn_learnable_params,\n",
        "                                                     device=self.device,\n",
        "                                                     use_per_step_bn_statistics=self.use_per_step_bn_statistics,\n",
        "                                                     args=self.args)\n",
        "            elif self.args.norm_layer == \"layer_norm\":\n",
        "                self.norm_layer = MetaLayerNormLayer(input_feature_shape=out.shape[1:])\n",
        "\n",
        "            out = self.norm_layer(out, num_step=0)\n",
        "\n",
        "        out = F.leaky_relu(out)\n",
        "\n",
        "        print(out.shape)\n",
        "\n",
        "    def forward(self, x, num_step, params=None, training=False, backup_running_statistics=False):\n",
        "        \"\"\"\n",
        "            Forward propagates by applying the function. If params are none then internal params are used.\n",
        "            Otherwise passed params will be used to execute the function.\n",
        "            :param input: input data batch, size either can be any.\n",
        "            :param num_step: The current inner loop step being taken. This is used when we are learning per step params and\n",
        "             collecting per step batch statistics. It indexes the correct object to use for the current time-step\n",
        "            :param params: A dictionary containing 'weight' and 'bias'.\n",
        "            :param training: Whether this is currently the training or evaluation phase.\n",
        "            :param backup_running_statistics: Whether to backup the running statistics. This is used\n",
        "            at evaluation time, when after the pass is complete we want to throw away the collected validation stats.\n",
        "            :return: The result of the batch norm operation.\n",
        "        \"\"\"\n",
        "        batch_norm_params = None\n",
        "        conv_params = None\n",
        "        activation_function_pre_params = None\n",
        "\n",
        "        if params is not None:\n",
        "            params = extract_top_level_dict(current_dict=params)\n",
        "\n",
        "            if self.normalization:\n",
        "                if 'norm_layer' in params:\n",
        "                    batch_norm_params = params['norm_layer']\n",
        "\n",
        "                if 'activation_function_pre' in params:\n",
        "                    activation_function_pre_params = params['activation_function_pre']\n",
        "\n",
        "            conv_params = params['conv']\n",
        "\n",
        "        out = x\n",
        "\n",
        "\n",
        "        out = self.conv(out, params=conv_params)\n",
        "\n",
        "        if self.normalization:\n",
        "            out = self.norm_layer.forward(out, num_step=num_step,\n",
        "                                          params=batch_norm_params, training=training,\n",
        "                                          backup_running_statistics=backup_running_statistics)\n",
        "\n",
        "        out = F.leaky_relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def restore_backup_stats(self):\n",
        "        \"\"\"\n",
        "        Restore stored statistics from the backup, replacing the current ones.\n",
        "        \"\"\"\n",
        "        if self.normalization:\n",
        "            self.norm_layer.restore_backup_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cl6609dBntk4"
      },
      "outputs": [],
      "source": [
        "class MetaNormLayerConvReLU(nn.Module):\n",
        "    def __init__(self, input_shape, num_filters, kernel_size, stride, padding, use_bias, args, normalization=True,\n",
        "                 meta_layer=True, no_bn_learnable_params=False, device=None):\n",
        "        \"\"\"\n",
        "           Initializes a BatchNorm->Conv->ReLU layer which applies those operation in that order.\n",
        "           :param args: A named tuple containing the system's hyperparameters.\n",
        "           :param device: The device to run the layer on.\n",
        "           :param normalization: The type of normalization to use 'batch_norm' or 'layer_norm'\n",
        "           :param meta_layer: Whether this layer will require meta-layer capabilities such as meta-batch norm,\n",
        "           meta-conv etc.\n",
        "           :param input_shape: The image input shape in the form (b, c, h, w)\n",
        "           :param num_filters: number of filters for convolutional layer\n",
        "           :param kernel_size: the kernel size of the convolutional layer\n",
        "           :param stride: the stride of the convolutional layer\n",
        "           :param padding: the bias of the convolutional layer\n",
        "           :param use_bias: whether the convolutional layer utilizes a bias\n",
        "        \"\"\"\n",
        "        super(MetaNormLayerConvReLU, self).__init__()\n",
        "        self.normalization = normalization\n",
        "        self.use_per_step_bn_statistics = args.per_step_bn_statistics\n",
        "        self.input_shape = input_shape\n",
        "        self.args = args\n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.use_bias = use_bias\n",
        "        self.meta_layer = meta_layer\n",
        "        self.no_bn_learnable_params = no_bn_learnable_params\n",
        "        self.device = device\n",
        "        self.layer_dict = nn.ModuleDict()\n",
        "        self.build_block()\n",
        "\n",
        "    def build_block(self):\n",
        "\n",
        "        x = torch.zeros(self.input_shape)\n",
        "\n",
        "        out = x\n",
        "        if self.normalization:\n",
        "            if self.args.norm_layer == \"batch_norm\":\n",
        "                self.norm_layer = MetaBatchNormLayer(self.input_shape[1], track_running_stats=True,\n",
        "                                                     meta_batch_norm=self.meta_layer,\n",
        "                                                     no_learnable_params=self.no_bn_learnable_params,\n",
        "                                                     device=self.device,\n",
        "                                                     use_per_step_bn_statistics=self.use_per_step_bn_statistics,\n",
        "                                                     args=self.args)\n",
        "            elif self.args.norm_layer == \"layer_norm\":\n",
        "                self.norm_layer = MetaLayerNormLayer(input_feature_shape=out.shape[1:])\n",
        "\n",
        "            out = self.norm_layer.forward(out, num_step=0)\n",
        "        self.conv = MetaConv2dLayer(in_channels=out.shape[1], out_channels=self.num_filters,\n",
        "                                    kernel_size=self.kernel_size,\n",
        "                                    stride=self.stride, padding=self.padding, use_bias=self.use_bias)\n",
        "\n",
        "\n",
        "        self.layer_dict['activation_function_pre'] = nn.LeakyReLU()\n",
        "\n",
        "\n",
        "        out = self.layer_dict['activation_function_pre'].forward(self.conv.forward(out))\n",
        "        print(out.shape)\n",
        "\n",
        "    def forward(self, x, num_step, params=None, training=False, backup_running_statistics=False):\n",
        "        \"\"\"\n",
        "            Forward propagates by applying the function. If params are none then internal params are used.\n",
        "            Otherwise passed params will be used to execute the function.\n",
        "            :param input: input data batch, size either can be any.\n",
        "            :param num_step: The current inner loop step being taken. This is used when we are learning per step params and\n",
        "             collecting per step batch statistics. It indexes the correct object to use for the current time-step\n",
        "            :param params: A dictionary containing 'weight' and 'bias'.\n",
        "            :param training: Whether this is currently the training or evaluation phase.\n",
        "            :param backup_running_statistics: Whether to backup the running statistics. This is used\n",
        "            at evaluation time, when after the pass is complete we want to throw away the collected validation stats.\n",
        "            :return: The result of the batch norm operation.\n",
        "        \"\"\"\n",
        "        batch_norm_params = None\n",
        "\n",
        "        if params is not None:\n",
        "            params = extract_top_level_dict(current_dict=params)\n",
        "\n",
        "            if self.normalization and 'norm_layer' in params:\n",
        "                batch_norm_params = params['norm_layer']\n",
        "\n",
        "            conv_params = params['conv']\n",
        "        else:\n",
        "            conv_params = None\n",
        "            #print('no inner loop params', self)\n",
        "\n",
        "        out = x\n",
        "\n",
        "        if self.normalization:\n",
        "            out = self.norm_layer.forward(out, num_step=num_step,\n",
        "                                          params=batch_norm_params, training=training,\n",
        "                                          backup_running_statistics=backup_running_statistics)\n",
        "\n",
        "        out = self.conv.forward(out, params=conv_params)\n",
        "        out = self.layer_dict['activation_function_pre'].forward(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def restore_backup_stats(self):\n",
        "        \"\"\"\n",
        "        Restore stored statistics from the backup, replacing the current ones.\n",
        "        \"\"\"\n",
        "        if self.normalization:\n",
        "            self.norm_layer.restore_backup_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LiAJAkvInHY-"
      },
      "outputs": [],
      "source": [
        "class VGGReLUNormNetwork(nn.Module):\n",
        "    def __init__(self, im_shape, num_output_classes, args, device, meta_classifier=True):\n",
        "        \"\"\"\n",
        "        Builds a multilayer convolutional network. It also provides functionality for passing external parameters to be\n",
        "        used at inference time. Enables inner loop optimization readily.\n",
        "        :param im_shape: The input image batch shape.\n",
        "        :param num_output_classes: The number of output classes of the network.\n",
        "        :param args: A named tuple containing the system's hyperparameters.\n",
        "        :param device: The device to run this on.\n",
        "        :param meta_classifier: A flag indicating whether the system's meta-learning (inner-loop) functionalities should\n",
        "        be enabled.\n",
        "        \"\"\"\n",
        "        super(VGGReLUNormNetwork, self).__init__()\n",
        "        b, c, self.h, self.w = im_shape\n",
        "        self.device = device\n",
        "        self.total_layers = 0\n",
        "        self.args = args\n",
        "        self.upscale_shapes = []\n",
        "        self.cnn_filters = args.cnn_num_filters\n",
        "        self.input_shape = list(im_shape)\n",
        "        self.num_stages = args.num_stages\n",
        "        self.num_output_classes = num_output_classes\n",
        "\n",
        "        if args.max_pooling:\n",
        "            print(\"Using max pooling\")\n",
        "            self.conv_stride = 1\n",
        "        else:\n",
        "            print(\"Using strided convolutions\")\n",
        "            self.conv_stride = 2\n",
        "        self.meta_classifier = meta_classifier\n",
        "\n",
        "        self.build_network()\n",
        "        print(\"meta network params\")\n",
        "        for name, param in self.named_parameters():\n",
        "            print(name, param.shape)\n",
        "\n",
        "    def build_network(self):\n",
        "        \"\"\"\n",
        "        Builds the network before inference is required by creating some dummy inputs with the same input as the\n",
        "        self.im_shape tuple. Then passes that through the network and dynamically computes input shapes and\n",
        "        sets output shapes for each layer.\n",
        "        \"\"\"\n",
        "        x = torch.zeros(self.input_shape)\n",
        "        out = x\n",
        "        self.layer_dict = nn.ModuleDict()\n",
        "        self.upscale_shapes.append(x.shape)\n",
        "\n",
        "        for i in range(self.num_stages):\n",
        "            self.layer_dict['conv{}'.format(i)] = MetaConvNormLayerReLU(input_shape=out.shape,\n",
        "                                                                        num_filters=self.cnn_filters,\n",
        "                                                                        kernel_size=3, stride=self.conv_stride,\n",
        "                                                                        padding=self.args.conv_padding,\n",
        "                                                                        use_bias=True, args=self.args,\n",
        "                                                                        normalization=True,\n",
        "                                                                        meta_layer=self.meta_classifier,\n",
        "                                                                        no_bn_learnable_params=False,\n",
        "                                                                        device=self.device)\n",
        "            out = self.layer_dict['conv{}'.format(i)](out, training=True, num_step=0)\n",
        "\n",
        "            if self.args.max_pooling:\n",
        "                out = F.max_pool2d(input=out, kernel_size=(2, 2), stride=2, padding=0)\n",
        "\n",
        "\n",
        "        if not self.args.max_pooling:\n",
        "            out = F.avg_pool2d(out, out.shape[2])\n",
        "\n",
        "        self.encoder_features_shape = list(out.shape)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "\n",
        "        self.layer_dict['linear'] = MetaLinearLayer(input_shape=(out.shape[0], np.prod(out.shape[1:])),\n",
        "                                                    num_filters=self.num_output_classes, use_bias=True)\n",
        "\n",
        "        out = self.layer_dict['linear'](out)\n",
        "        print(\"VGGNetwork build\", out.shape)\n",
        "\n",
        "    def forward(self, x, num_step, params=None, training=False, backup_running_statistics=False):\n",
        "        \"\"\"\n",
        "        Forward propages through the network. If any params are passed then they are used instead of stored params.\n",
        "        :param x: Input image batch.\n",
        "        :param num_step: The current inner loop step number\n",
        "        :param params: If params are None then internal parameters are used. If params are a dictionary with keys the\n",
        "         same as the layer names then they will be used instead.\n",
        "        :param training: Whether this is training (True) or eval time.\n",
        "        :param backup_running_statistics: Whether to backup the running statistics in their backup store. Which is\n",
        "        then used to reset the stats back to a previous state (usually after an eval loop, when we want to throw away stored statistics)\n",
        "        :return: Logits of shape b, num_output_classes.\n",
        "        \"\"\"\n",
        "        param_dict = {}\n",
        "\n",
        "        if params is not None:\n",
        "            params = {key: value[0] for key, value in params.items()}\n",
        "            param_dict = extract_top_level_dict(current_dict=params)\n",
        "\n",
        "        # print('top network', param_dict.keys())\n",
        "        for name, param in self.layer_dict.named_parameters():\n",
        "            path_bits = name.split(\".\")\n",
        "            layer_name = path_bits[0]\n",
        "            if layer_name not in param_dict:\n",
        "                param_dict[layer_name] = None\n",
        "\n",
        "        out = x\n",
        "\n",
        "        for i in range(self.num_stages):\n",
        "            out = self.layer_dict['conv{}'.format(i)](out, params=param_dict['conv{}'.format(i)], training=training,\n",
        "                                                      backup_running_statistics=backup_running_statistics,\n",
        "                                                      num_step=num_step)\n",
        "            if self.args.max_pooling:\n",
        "                out = F.max_pool2d(input=out, kernel_size=(2, 2), stride=2, padding=0)\n",
        "\n",
        "        if not self.args.max_pooling:\n",
        "            out = F.avg_pool2d(out, out.shape[2])\n",
        "\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.layer_dict['linear'](out, param_dict['linear'])\n",
        "\n",
        "        return out\n",
        "\n",
        "    def zero_grad(self, params=None):\n",
        "        if params is None:\n",
        "            for param in self.parameters():\n",
        "                if (\n",
        "                    param.requires_grad == True\n",
        "                    and param.grad is not None\n",
        "                    and torch.sum(param.grad) > 0\n",
        "                ):\n",
        "                    print(param.grad)\n",
        "                    param.grad.zero_()\n",
        "        else:\n",
        "            for name, param in params.items():\n",
        "                if (\n",
        "                    param.requires_grad == True\n",
        "                    and param.grad is not None\n",
        "                    and torch.sum(param.grad) > 0\n",
        "                ):\n",
        "                    print(param.grad)\n",
        "                    param.grad.zero_()\n",
        "                    params[name].grad = None\n",
        "\n",
        "    def restore_backup_stats(self):\n",
        "        \"\"\"\n",
        "        Reset stored batch statistics from the stored backup.\n",
        "        \"\"\"\n",
        "        for i in range(self.num_stages):\n",
        "            self.layer_dict['conv{}'.format(i)].restore_backup_stats()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-uTHDDT0YGl"
      },
      "source": [
        "TODO:\n",
        "\n",
        "add more functionalities specific to MAML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoajsklRk8Os"
      },
      "source": [
        "# Experiment Builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FmscGJS8cCUv"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import datetime\n",
        "import os\n",
        "import numpy as np\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "17o11EhPJ4NL"
      },
      "outputs": [],
      "source": [
        "def build_experiment_folder(experiment_name):\n",
        "    experiment_path = os.path.abspath(experiment_name)\n",
        "    saved_models_filepath = \"{}/{}\".format(experiment_path, \"saved_models\")\n",
        "    logs_filepath = \"{}/{}\".format(experiment_path, \"logs\")\n",
        "    samples_filepath = \"{}/{}\".format(experiment_path, \"visual_outputs\")\n",
        "\n",
        "    if not os.path.exists(experiment_path):\n",
        "        os.makedirs(experiment_path)\n",
        "    if not os.path.exists(logs_filepath):\n",
        "        os.makedirs(logs_filepath)\n",
        "    if not os.path.exists(samples_filepath):\n",
        "        os.makedirs(samples_filepath)\n",
        "    if not os.path.exists(saved_models_filepath):\n",
        "        os.makedirs(saved_models_filepath)\n",
        "\n",
        "    outputs = (saved_models_filepath, logs_filepath, samples_filepath)\n",
        "    outputs = (os.path.abspath(item) for item in outputs)\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3BMXNVZ6b9qk"
      },
      "outputs": [],
      "source": [
        "def save_statistics(experiment_name, line_to_add, filename=\"summary_statistics.csv\", create=False):\n",
        "    summary_filename = \"{}/{}\".format(experiment_name, filename)\n",
        "    if create:\n",
        "        with open(summary_filename, 'w') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(line_to_add)\n",
        "    else:\n",
        "        with open(summary_filename, 'a') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(line_to_add)\n",
        "\n",
        "    return summary_filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qIFIaiMXcIOc"
      },
      "outputs": [],
      "source": [
        "def save_to_json(filename, dict_to_store):\n",
        "    with open(os.path.abspath(filename), 'w') as f:\n",
        "        json.dump(dict_to_store, fp=f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nV0wkiZBk59X"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "import os\n",
        "import numpy as np\n",
        "import sys\n",
        "# from utils.storage import build_experiment_folder, save_statistics, save_to_json\n",
        "import time\n",
        "import torch\n",
        "\n",
        "\n",
        "class ExperimentBuilder(object):\n",
        "    def __init__(self, args, data, model, device):\n",
        "        \"\"\"\n",
        "        Initializes an experiment builder using a named tuple (args), a data provider (data), a meta learning system\n",
        "        (model) and a device (e.g. gpu/cpu/n)\n",
        "        :param args: A namedtuple containing all experiment hyperparameters\n",
        "        :param data: A data provider of instance MetaLearningSystemDataLoader\n",
        "        :param model: A meta learning system instance\n",
        "        :param device: Device/s to use for the experiment\n",
        "        \"\"\"\n",
        "        self.args, self.device = args, device\n",
        "\n",
        "        self.model = model\n",
        "        self.saved_models_filepath, self.logs_filepath, self.samples_filepath = build_experiment_folder(\n",
        "            experiment_name=self.args.experiment_name)\n",
        "\n",
        "        self.total_losses = {}\n",
        "        self.state = {'best_val_acc': 0.0, 'best_val_iter': 0, 'current_iter': 0}\n",
        "        self.start_epoch = 0\n",
        "        self.max_models_to_save = self.args.max_models_to_save\n",
        "        self.create_summary_csv = False\n",
        "\n",
        "        if self.args.continue_from_epoch == 'from_scratch':\n",
        "            self.create_summary_csv = True\n",
        "\n",
        "        elif self.args.continue_from_epoch == 'latest':\n",
        "            checkpoint = os.path.join(self.saved_models_filepath, \"train_model_latest\")\n",
        "            print(\"attempting to find existing checkpoint\", )\n",
        "            if os.path.exists(checkpoint):\n",
        "                self.state = \\\n",
        "                    self.model.load_model(model_save_dir=self.saved_models_filepath, model_name=\"train_model\",\n",
        "                                          model_idx='latest')\n",
        "                self.start_epoch = int(self.state['current_iter'] / self.args.total_iter_per_epoch)\n",
        "\n",
        "            else:\n",
        "                self.args.continue_from_epoch = 'from_scratch'\n",
        "                self.create_summary_csv = True\n",
        "        elif int(self.args.continue_from_epoch) >= 0:\n",
        "            self.state = \\\n",
        "                self.model.load_model(model_save_dir=self.saved_models_filepath, model_name=\"train_model\",\n",
        "                                      model_idx=self.args.continue_from_epoch)\n",
        "            self.start_epoch = int(self.state['current_iter'] / self.args.total_iter_per_epoch)\n",
        "\n",
        "        self.data = data(args=args, current_iter=self.state['current_iter'])\n",
        "\n",
        "        print(\"train_seed {}, val_seed: {}, at start time\".format(self.data.dataset.seed[\"train\"],\n",
        "                                                                  self.data.dataset.seed[\"val\"]))\n",
        "        self.total_epochs_before_pause = self.args.total_epochs_before_pause\n",
        "        self.state['best_epoch'] = int(self.state['best_val_iter'] / self.args.total_iter_per_epoch)\n",
        "        self.epoch = int(self.state['current_iter'] / self.args.total_iter_per_epoch)\n",
        "        self.augment_flag = 'omniglot' in self.args.dataset_name.lower()\n",
        "        self.start_time = time.time()\n",
        "        self.epochs_done_in_this_run = 0\n",
        "        print(self.state['current_iter'], int(self.args.total_iter_per_epoch * self.args.total_epochs))\n",
        "\n",
        "    def build_summary_dict(self, total_losses, phase, summary_losses=None):\n",
        "        \"\"\"\n",
        "        Builds/Updates a summary dict directly from the metric dict of the current iteration.\n",
        "        :param total_losses: Current dict with total losses (not aggregations) from experiment\n",
        "        :param phase: Current training phase\n",
        "        :param summary_losses: Current summarised (aggregated/summarised) losses stats means, stdv etc.\n",
        "        :return: A new summary dict with the updated summary statistics information.\n",
        "        \"\"\"\n",
        "        if summary_losses is None:\n",
        "            summary_losses = {}\n",
        "\n",
        "        for key in total_losses:\n",
        "            summary_losses[\"{}_{}_mean\".format(phase, key)] = np.mean(total_losses[key])\n",
        "            summary_losses[\"{}_{}_std\".format(phase, key)] = np.std(total_losses[key])\n",
        "\n",
        "        return summary_losses\n",
        "\n",
        "    def build_loss_summary_string(self, summary_losses):\n",
        "        \"\"\"\n",
        "        Builds a progress bar summary string given current summary losses dictionary\n",
        "        :param summary_losses: Current summary statistics\n",
        "        :return: A summary string ready to be shown to humans.\n",
        "        \"\"\"\n",
        "        output_update = \"\"\n",
        "        for key, value in zip(list(summary_losses.keys()), list(summary_losses.values())):\n",
        "            if \"loss\" in key or \"accuracy\" in key:\n",
        "                value = float(value)\n",
        "                output_update += \"{}: {:.4f}, \".format(key, value)\n",
        "\n",
        "        return output_update\n",
        "\n",
        "    def merge_two_dicts(self, first_dict, second_dict):\n",
        "        \"\"\"Given two dicts, merge them into a new dict as a shallow copy.\"\"\"\n",
        "        z = first_dict.copy()\n",
        "        z.update(second_dict)\n",
        "        return z\n",
        "\n",
        "    def train_iteration(self, train_sample, sample_idx, epoch_idx, total_losses, current_iter, pbar_train):\n",
        "        \"\"\"\n",
        "        Runs a training iteration, updates the progress bar and returns the total and current epoch train losses.\n",
        "        :param train_sample: A sample from the data provider\n",
        "        :param sample_idx: The index of the incoming sample, in relation to the current training run.\n",
        "        :param epoch_idx: The epoch index.\n",
        "        :param total_losses: The current total losses dictionary to be updated.\n",
        "        :param current_iter: The current training iteration in relation to the whole experiment.\n",
        "        :param pbar_train: The progress bar of the training.\n",
        "        :return: Updates total_losses, train_losses, current_iter\n",
        "        \"\"\"\n",
        "        x_support_set, x_target_set, y_support_set, y_target_set, seed = train_sample\n",
        "        data_batch = (x_support_set, x_target_set, y_support_set, y_target_set)\n",
        "\n",
        "        if sample_idx == 0:\n",
        "            print(\"shape of data\", x_support_set.shape, x_target_set.shape, y_support_set.shape,\n",
        "                  y_target_set.shape)\n",
        "\n",
        "        losses, _ = self.model.run_train_iter(data_batch=data_batch, epoch=epoch_idx)\n",
        "\n",
        "        for key, value in zip(list(losses.keys()), list(losses.values())):\n",
        "            if key not in total_losses:\n",
        "                total_losses[key] = [float(value)]\n",
        "            else:\n",
        "                total_losses[key].append(float(value))\n",
        "\n",
        "        train_losses = self.build_summary_dict(total_losses=total_losses, phase=\"train\")\n",
        "        train_output_update = self.build_loss_summary_string(losses)\n",
        "\n",
        "        pbar_train.update(1)\n",
        "        pbar_train.set_description(\"training phase {} -> {}\".format(self.epoch, train_output_update))\n",
        "\n",
        "        current_iter += 1\n",
        "\n",
        "        return train_losses, total_losses, current_iter\n",
        "\n",
        "    def evaluation_iteration(self, val_sample, total_losses, pbar_val, phase):\n",
        "        \"\"\"\n",
        "        Runs a validation iteration, updates the progress bar and returns the total and current epoch val losses.\n",
        "        :param val_sample: A sample from the data provider\n",
        "        :param total_losses: The current total losses dictionary to be updated.\n",
        "        :param pbar_val: The progress bar of the val stage.\n",
        "        :return: The updated val_losses, total_losses\n",
        "        \"\"\"\n",
        "        x_support_set, x_target_set, y_support_set, y_target_set, seed = val_sample\n",
        "        data_batch = (\n",
        "            x_support_set, x_target_set, y_support_set, y_target_set)\n",
        "\n",
        "        losses, _ = self.model.run_validation_iter(data_batch=data_batch)\n",
        "        for key, value in zip(list(losses.keys()), list(losses.values())):\n",
        "            if key not in total_losses:\n",
        "                total_losses[key] = [float(value)]\n",
        "            else:\n",
        "                total_losses[key].append(float(value))\n",
        "\n",
        "        val_losses = self.build_summary_dict(total_losses=total_losses, phase=phase)\n",
        "        val_output_update = self.build_loss_summary_string(losses)\n",
        "\n",
        "        pbar_val.update(1)\n",
        "        pbar_val.set_description(\n",
        "            \"val_phase {} -> {}\".format(self.epoch, val_output_update))\n",
        "\n",
        "        return val_losses, total_losses\n",
        "\n",
        "    def test_evaluation_iteration(self, val_sample, model_idx, sample_idx, per_model_per_batch_preds, pbar_test):\n",
        "        \"\"\"\n",
        "        Runs a validation iteration, updates the progress bar and returns the total and current epoch val losses.\n",
        "        :param val_sample: A sample from the data provider\n",
        "        :param total_losses: The current total losses dictionary to be updated.\n",
        "        :param pbar_test: The progress bar of the val stage.\n",
        "        :return: The updated val_losses, total_losses\n",
        "        \"\"\"\n",
        "        x_support_set, x_target_set, y_support_set, y_target_set, seed = val_sample\n",
        "        data_batch = (\n",
        "            x_support_set, x_target_set, y_support_set, y_target_set)\n",
        "\n",
        "        losses, per_task_preds = self.model.run_validation_iter(data_batch=data_batch)\n",
        "\n",
        "        per_model_per_batch_preds[model_idx].extend(list(per_task_preds))\n",
        "\n",
        "        test_output_update = self.build_loss_summary_string(losses)\n",
        "\n",
        "        pbar_test.update(1)\n",
        "        pbar_test.set_description(\n",
        "            \"test_phase {} -> {}\".format(self.epoch, test_output_update))\n",
        "\n",
        "        return per_model_per_batch_preds\n",
        "\n",
        "    def save_models(self, model, epoch, state):\n",
        "        \"\"\"\n",
        "        Saves two separate instances of the current model. One to be kept for history and reloading later and another\n",
        "        one marked as \"latest\" to be used by the system for the next epoch training. Useful when the training/val\n",
        "        process is interrupted or stopped. Leads to fault tolerant training and validation systems that can continue\n",
        "        from where they left off before.\n",
        "        :param model: Current meta learning model of any instance within the few_shot_learning_system.py\n",
        "        :param epoch: Current epoch\n",
        "        :param state: Current model and experiment state dict.\n",
        "        \"\"\"\n",
        "        model.save_model(model_save_dir=os.path.join(self.saved_models_filepath, \"train_model_{}\".format(int(epoch))),\n",
        "                         state=state)\n",
        "\n",
        "        model.save_model(model_save_dir=os.path.join(self.saved_models_filepath, \"train_model_latest\"),\n",
        "                         state=state)\n",
        "\n",
        "        print(\"saved models to\", self.saved_models_filepath)\n",
        "\n",
        "    def pack_and_save_metrics(self, start_time, create_summary_csv, train_losses, val_losses, state):\n",
        "        \"\"\"\n",
        "        Given current epochs start_time, train losses, val losses and whether to create a new stats csv file, pack stats\n",
        "        and save into a statistics csv file. Return a new start time for the new epoch.\n",
        "        :param start_time: The start time of the current epoch\n",
        "        :param create_summary_csv: A boolean variable indicating whether to create a new statistics file or\n",
        "        append results to existing one\n",
        "        :param train_losses: A dictionary with the current train losses\n",
        "        :param val_losses: A dictionary with the currrent val loss\n",
        "        :return: The current time, to be used for the next epoch.\n",
        "        \"\"\"\n",
        "        epoch_summary_losses = self.merge_two_dicts(first_dict=train_losses, second_dict=val_losses)\n",
        "\n",
        "        if 'per_epoch_statistics' not in state:\n",
        "            state['per_epoch_statistics'] = {}\n",
        "\n",
        "        for key, value in epoch_summary_losses.items():\n",
        "\n",
        "            if key not in state['per_epoch_statistics']:\n",
        "                state['per_epoch_statistics'][key] = [value]\n",
        "            else:\n",
        "                state['per_epoch_statistics'][key].append(value)\n",
        "\n",
        "        epoch_summary_string = self.build_loss_summary_string(epoch_summary_losses)\n",
        "        epoch_summary_losses[\"epoch\"] = self.epoch\n",
        "        epoch_summary_losses['epoch_run_time'] = time.time() - start_time\n",
        "\n",
        "        if create_summary_csv:\n",
        "            self.summary_statistics_filepath = save_statistics(self.logs_filepath, list(epoch_summary_losses.keys()),\n",
        "                                                               create=True)\n",
        "            self.create_summary_csv = False\n",
        "\n",
        "        start_time = time.time()\n",
        "        print(\"epoch {} -> {}\".format(epoch_summary_losses[\"epoch\"], epoch_summary_string))\n",
        "\n",
        "        self.summary_statistics_filepath = save_statistics(self.logs_filepath,\n",
        "                                                           list(epoch_summary_losses.values()))\n",
        "        return start_time, state\n",
        "\n",
        "    def evaluated_test_set_using_the_best_models(self, top_n_models):\n",
        "        per_epoch_statistics = self.state['per_epoch_statistics']\n",
        "        val_acc = np.copy(per_epoch_statistics['val_accuracy_mean'])\n",
        "        val_idx = np.array([i for i in range(len(val_acc))])\n",
        "        sorted_idx = np.argsort(val_acc, axis=0).astype(dtype=np.int32)[::-1][:top_n_models]\n",
        "\n",
        "        sorted_val_acc = val_acc[sorted_idx]\n",
        "        val_idx = val_idx[sorted_idx]\n",
        "        print(sorted_idx)\n",
        "        print(sorted_val_acc)\n",
        "\n",
        "        top_n_idx = val_idx[:top_n_models]\n",
        "        per_model_per_batch_preds = [[] for i in range(top_n_models)]\n",
        "        per_model_per_batch_targets = [[] for i in range(top_n_models)]\n",
        "        test_losses = [dict() for i in range(top_n_models)]\n",
        "        for idx, model_idx in enumerate(top_n_idx):\n",
        "            self.state = \\\n",
        "                self.model.load_model(model_save_dir=self.saved_models_filepath, model_name=\"train_model\",\n",
        "                                      model_idx=model_idx + 1)\n",
        "            with tqdm.tqdm(total=int(self.args.num_evaluation_tasks / self.args.batch_size)) as pbar_test:\n",
        "                for sample_idx, test_sample in enumerate(\n",
        "                        self.data.get_test_batches(total_batches=int(self.args.num_evaluation_tasks / self.args.batch_size),\n",
        "                                                   augment_images=False)):\n",
        "                    #print(test_sample[4])\n",
        "                    per_model_per_batch_targets[idx].extend(np.array(test_sample[3]))\n",
        "                    per_model_per_batch_preds = self.test_evaluation_iteration(val_sample=test_sample,\n",
        "                                                                               sample_idx=sample_idx,\n",
        "                                                                               model_idx=idx,\n",
        "                                                                               per_model_per_batch_preds=per_model_per_batch_preds,\n",
        "                                                                               pbar_test=pbar_test)\n",
        "        # for i in range(top_n_models):\n",
        "        #     print(\"test assertion\", 0)\n",
        "        #     print(per_model_per_batch_targets[0], per_model_per_batch_targets[i])\n",
        "        #     assert np.equal(np.array(per_model_per_batch_targets[0]), np.array(per_model_per_batch_targets[i]))\n",
        "\n",
        "        per_batch_preds = np.mean(per_model_per_batch_preds, axis=0)\n",
        "        #print(per_batch_preds.shape)\n",
        "        per_batch_max = np.argmax(per_batch_preds, axis=2)\n",
        "        per_batch_targets = np.array(per_model_per_batch_targets[0]).reshape(per_batch_max.shape)\n",
        "        #print(per_batch_max)\n",
        "        accuracy = np.mean(np.equal(per_batch_targets, per_batch_max))\n",
        "        accuracy_std = np.std(np.equal(per_batch_targets, per_batch_max))\n",
        "\n",
        "        test_losses = {\"test_accuracy_mean\": accuracy, \"test_accuracy_std\": accuracy_std}\n",
        "\n",
        "        _ = save_statistics(self.logs_filepath,\n",
        "                            list(test_losses.keys()),\n",
        "                            create=True, filename=\"test_summary.csv\")\n",
        "\n",
        "        summary_statistics_filepath = save_statistics(self.logs_filepath,\n",
        "                                                      list(test_losses.values()),\n",
        "                                                      create=False, filename=\"test_summary.csv\")\n",
        "        print(test_losses)\n",
        "        print(\"saved test performance at\", summary_statistics_filepath)\n",
        "\n",
        "    def run_experiment(self):\n",
        "        \"\"\"\n",
        "        Runs a full training experiment with evaluations of the model on the val set at every epoch. Furthermore,\n",
        "        will return the test set evaluation results on the best performing validation model.\n",
        "        \"\"\"\n",
        "        with tqdm.tqdm(initial=self.state['current_iter'],\n",
        "                           total=int(self.args.total_iter_per_epoch * self.args.total_epochs)) as pbar_train:\n",
        "\n",
        "            while (self.state['current_iter'] < (self.args.total_epochs * self.args.total_iter_per_epoch)) and (self.args.evaluate_on_test_set_only == False):\n",
        "\n",
        "                for train_sample_idx, train_sample in enumerate(\n",
        "                        self.data.get_train_batches(total_batches=int(self.args.total_iter_per_epoch *\n",
        "                                                                      self.args.total_epochs) - self.state[\n",
        "                                                                      'current_iter'],\n",
        "                                                    augment_images=self.augment_flag)):\n",
        "                    # print(self.state['current_iter'], (self.args.total_epochs * self.args.total_iter_per_epoch))\n",
        "                    train_losses, total_losses, self.state['current_iter'] = self.train_iteration(\n",
        "                        train_sample=train_sample,\n",
        "                        total_losses=self.total_losses,\n",
        "                        epoch_idx=(self.state['current_iter'] /\n",
        "                                   self.args.total_iter_per_epoch),\n",
        "                        pbar_train=pbar_train,\n",
        "                        current_iter=self.state['current_iter'],\n",
        "                        sample_idx=self.state['current_iter'])\n",
        "\n",
        "                    if self.state['current_iter'] % self.args.total_iter_per_epoch == 0:\n",
        "\n",
        "                        total_losses = {}\n",
        "                        val_losses = {}\n",
        "                        with tqdm.tqdm(total=int(self.args.num_evaluation_tasks / self.args.batch_size)) as pbar_val:\n",
        "                            for _, val_sample in enumerate(\n",
        "                                    self.data.get_val_batches(total_batches=int(self.args.num_evaluation_tasks / self.args.batch_size),\n",
        "                                                              augment_images=False)):\n",
        "                                val_losses, total_losses = self.evaluation_iteration(val_sample=val_sample,\n",
        "                                                                                     total_losses=total_losses,\n",
        "                                                                                     pbar_val=pbar_val, phase='val')\n",
        "\n",
        "                            if val_losses[\"val_accuracy_mean\"] > self.state['best_val_acc']:\n",
        "                                print(\"Best validation accuracy\", val_losses[\"val_accuracy_mean\"])\n",
        "                                self.state['best_val_acc'] = val_losses[\"val_accuracy_mean\"]\n",
        "                                self.state['best_val_iter'] = self.state['current_iter']\n",
        "                                self.state['best_epoch'] = int(\n",
        "                                    self.state['best_val_iter'] / self.args.total_iter_per_epoch)\n",
        "\n",
        "\n",
        "                        self.epoch += 1\n",
        "                        self.state = self.merge_two_dicts(first_dict=self.merge_two_dicts(first_dict=self.state,\n",
        "                                                                                          second_dict=train_losses),\n",
        "                                                          second_dict=val_losses)\n",
        "\n",
        "                        self.save_models(model=self.model, epoch=self.epoch, state=self.state)\n",
        "\n",
        "                        self.start_time, self.state = self.pack_and_save_metrics(start_time=self.start_time,\n",
        "                                                                                 create_summary_csv=self.create_summary_csv,\n",
        "                                                                                 train_losses=train_losses,\n",
        "                                                                                 val_losses=val_losses,\n",
        "                                                                                 state=self.state)\n",
        "\n",
        "                        self.total_losses = {}\n",
        "\n",
        "                        self.epochs_done_in_this_run += 1\n",
        "\n",
        "                        save_to_json(filename=os.path.join(self.logs_filepath, \"summary_statistics.json\"),\n",
        "                                     dict_to_store=self.state['per_epoch_statistics'])\n",
        "\n",
        "                        if self.epochs_done_in_this_run >= self.total_epochs_before_pause:\n",
        "                            print(\"train_seed {}, val_seed: {}, at pause time\".format(self.data.dataset.seed[\"train\"],\n",
        "                                                                                      self.data.dataset.seed[\"val\"]))\n",
        "                            sys.exit()\n",
        "            self.evaluated_test_set_using_the_best_models(top_n_models=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcgAQA_LvTZc"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6C_DqsYZvVpv"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tqdm\n",
        "import concurrent.futures\n",
        "import pickle\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# from utils.parser_utils import get_args\n",
        "\n",
        "\n",
        "class rotate_image(object):\n",
        "\n",
        "    def __init__(self, k, channels):\n",
        "        self.k = k\n",
        "        self.channels = channels\n",
        "\n",
        "    def __call__(self, image):\n",
        "        if self.channels == 1:\n",
        "            if len(image.shape) == 3:\n",
        "                image = image[:, :, 0]\n",
        "                image = np.expand_dims(image, axis=2)\n",
        "\n",
        "            elif len(image.shape) == 4:\n",
        "                image = image[:, :, :, 0]\n",
        "                image = np.expand_dims(image, axis=3)\n",
        "\n",
        "        image = np.rot90(image, k=self.k).copy()\n",
        "        return image\n",
        "\n",
        "\n",
        "class torch_rotate_image(object):\n",
        "\n",
        "    def __init__(self, k, channels):\n",
        "        self.k = k\n",
        "        self.channels = channels\n",
        "\n",
        "    def __call__(self, image):\n",
        "        rotate = transforms.RandomRotation(degrees=self.k * 90)\n",
        "        if image.shape[-1] == 1:\n",
        "            image = image[:, :, 0]\n",
        "        image = Image.fromarray(image)\n",
        "        image = rotate(image)\n",
        "        image = np.array(image)\n",
        "        if len(image.shape) == 2:\n",
        "            image = np.expand_dims(image, axis=2)\n",
        "        return image\n",
        "\n",
        "\n",
        "def augment_image(image, k, channels, augment_bool, args, dataset_name):\n",
        "    transform_train, transform_evaluation = get_transforms_for_dataset(dataset_name=dataset_name,\n",
        "                                                                       args=args, k=k)\n",
        "    if len(image.shape) > 3:\n",
        "        images = [item for item in image]\n",
        "        output_images = []\n",
        "        for image in images:\n",
        "            if augment_bool is True:\n",
        "                for transform_current in transform_train:\n",
        "                    image = transform_current(image)\n",
        "            else:\n",
        "                for transform_current in transform_evaluation:\n",
        "                    image = transform_current(image)\n",
        "            output_images.append(image)\n",
        "        image = torch.stack(output_images)\n",
        "    elif augment_bool is True:\n",
        "        # meanstd transformation\n",
        "        for transform_current in transform_train:\n",
        "            image = transform_current(image)\n",
        "    else:\n",
        "        for transform_current in transform_evaluation:\n",
        "            image = transform_current(image)\n",
        "    return image\n",
        "\n",
        "\n",
        "def get_transforms_for_dataset(dataset_name, args, k):\n",
        "    if \"cifar10\" in dataset_name or \"cifar100\" in dataset_name:\n",
        "        transform_train = [\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(args.classification_mean, args.classification_std)]\n",
        "\n",
        "        transform_evaluate = [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(args.classification_mean, args.classification_std)]\n",
        "\n",
        "    elif 'omniglot' in dataset_name:\n",
        "\n",
        "        transform_train = [rotate_image(k=k, channels=args.image_channels), transforms.ToTensor()]\n",
        "        transform_evaluate = [transforms.ToTensor()]\n",
        "\n",
        "\n",
        "    elif 'imagenet' in dataset_name:\n",
        "\n",
        "        transform_train = [transforms.Compose([\n",
        "\n",
        "            transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])]\n",
        "\n",
        "        transform_evaluate = [transforms.Compose([\n",
        "\n",
        "            transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])]\n",
        "\n",
        "    return transform_train, transform_evaluate\n",
        "\n",
        "\n",
        "class FewShotLearningDatasetParallel(Dataset):\n",
        "    def __init__(self, args):\n",
        "        \"\"\"\n",
        "        A data provider class inheriting from Pytorch's Dataset class. It takes care of creating task sets for\n",
        "        our few-shot learning model training and evaluation\n",
        "        :param args: Arguments in the form of a Bunch object. Includes all hyperparameters necessary for the\n",
        "        data-provider. For transparency and readability reasons to explicitly set as self.object_name all arguments\n",
        "        required for the data provider, such that the reader knows exactly what is necessary for the data provider/\n",
        "        \"\"\"\n",
        "        self.data_path = args.dataset_path\n",
        "        self.dataset_name = args.dataset_name\n",
        "        self.data_loaded_in_memory = False\n",
        "        self.image_height, self.image_width, self.image_channel = args.image_height, args.image_width, args.image_channels\n",
        "        self.args = args\n",
        "        self.indexes_of_folders_indicating_class = args.indexes_of_folders_indicating_class\n",
        "        self.reverse_channels = args.reverse_channels\n",
        "        self.labels_as_int = args.labels_as_int\n",
        "        self.train_val_test_split = args.train_val_test_split\n",
        "        self.current_set_name = \"train\"\n",
        "        self.num_target_samples = args.num_target_samples\n",
        "        self.reset_stored_filepaths = args.reset_stored_filepaths\n",
        "        val_rng = np.random.RandomState(seed=args.val_seed)\n",
        "        val_seed = val_rng.randint(1, 999999)\n",
        "        train_rng = np.random.RandomState(seed=args.train_seed)\n",
        "        train_seed = train_rng.randint(1, 999999)\n",
        "        test_rng = np.random.RandomState(seed=args.val_seed)\n",
        "        test_seed = test_rng.randint(1, 999999)\n",
        "        args.val_seed = val_seed\n",
        "        args.train_seed = train_seed\n",
        "        args.test_seed = test_seed\n",
        "        self.init_seed = {\"train\": args.train_seed, \"val\": args.val_seed, 'test': args.val_seed}\n",
        "        self.seed = {\"train\": args.train_seed, \"val\": args.val_seed, 'test': args.val_seed}\n",
        "        self.num_of_gpus = args.num_of_gpus\n",
        "        self.batch_size = args.batch_size\n",
        "\n",
        "        self.train_index = 0\n",
        "        self.val_index = 0\n",
        "        self.test_index = 0\n",
        "\n",
        "        self.augment_images = False\n",
        "        self.num_samples_per_class = args.num_samples_per_class\n",
        "        self.num_classes_per_set = args.num_classes_per_set\n",
        "\n",
        "        self.rng = np.random.RandomState(seed=self.seed['val'])\n",
        "        self.datasets = self.load_dataset()\n",
        "\n",
        "        self.indexes = {\"train\": 0, \"val\": 0, 'test': 0}\n",
        "        self.dataset_size_dict = {\n",
        "            \"train\": {key: len(self.datasets['train'][key]) for key in list(self.datasets['train'].keys())},\n",
        "            \"val\": {key: len(self.datasets['val'][key]) for key in list(self.datasets['val'].keys())},\n",
        "            'test': {key: len(self.datasets['test'][key]) for key in list(self.datasets['test'].keys())}}\n",
        "        self.label_set = self.get_label_set()\n",
        "        self.data_length = {name: np.sum([len(self.datasets[name][key])\n",
        "                                          for key in self.datasets[name]]) for name in self.datasets.keys()}\n",
        "\n",
        "        print(\"data\", self.data_length)\n",
        "        self.observed_seed_set = None\n",
        "\n",
        "    def load_dataset(self):\n",
        "        \"\"\"\n",
        "        Loads a dataset's dictionary files and splits the data according to the train_val_test_split variable stored\n",
        "        in the args object.\n",
        "        :return: Three sets, the training set, validation set and test sets (referred to as the meta-train,\n",
        "        meta-val and meta-test in the paper)\n",
        "        \"\"\"\n",
        "        rng = np.random.RandomState(seed=self.seed['val'])\n",
        "\n",
        "        if self.args.sets_are_pre_split == True:\n",
        "            print(\"Loading pre-split data\")\n",
        "            data_image_paths, index_to_label_name_dict_file, label_to_index = self.load_datapaths()\n",
        "            dataset_splits = {}\n",
        "            for key, value in data_image_paths.items():\n",
        "                key = self.get_label_from_index(index=key)\n",
        "                bits = key.split(\"/\")\n",
        "                set_name = bits[0]\n",
        "                class_label = bits[1]\n",
        "                if set_name not in dataset_splits:\n",
        "                    dataset_splits[set_name] = {class_label: value}\n",
        "                else:\n",
        "                    dataset_splits[set_name][class_label] = value\n",
        "        else:\n",
        "            data_image_paths, index_to_label_name_dict_file, label_to_index = self.load_datapaths()\n",
        "            total_label_types = len(data_image_paths)\n",
        "            num_classes_idx = np.arange(len(data_image_paths.keys()), dtype=np.int32)\n",
        "            rng.shuffle(num_classes_idx)\n",
        "            keys = list(data_image_paths.keys())\n",
        "            values = list(data_image_paths.values())\n",
        "            new_keys = [keys[idx] for idx in num_classes_idx]\n",
        "            new_values = [values[idx] for idx in num_classes_idx]\n",
        "            data_image_paths = dict(zip(new_keys, new_values))\n",
        "            # data_image_paths = self.shuffle(data_image_paths)\n",
        "            x_train_id, x_val_id, x_test_id = int(self.train_val_test_split[0] * total_label_types), \\\n",
        "                                              int(np.sum(self.train_val_test_split[:2]) * total_label_types), \\\n",
        "                                              int(total_label_types)\n",
        "            # print(x_train_id, x_val_id, x_test_id)\n",
        "            # print(\"DATA IMAGE PATH FIRST KEY\")\n",
        "            test_first_class_key = list(data_image_paths.keys())[0]\n",
        "            # print(test_first_class_key)\n",
        "            # print(data_image_paths[test_first_class_key])\n",
        "            x_train_classes = (class_key for class_key in list(data_image_paths.keys())[:x_train_id])\n",
        "            x_val_classes = (class_key for class_key in list(data_image_paths.keys())[x_train_id:x_val_id])\n",
        "            x_test_classes = (class_key for class_key in list(data_image_paths.keys())[x_val_id:x_test_id])\n",
        "            x_train, x_val, x_test = {class_key: data_image_paths[class_key] for class_key in x_train_classes}, \\\n",
        "                                     {class_key: data_image_paths[class_key] for class_key in x_val_classes}, \\\n",
        "                                     {class_key: data_image_paths[class_key] for class_key in x_test_classes},\n",
        "            dataset_splits = {\"train\": x_train, \"val\":x_val , \"test\": x_test}\n",
        "\n",
        "        if self.args.load_into_memory is True:\n",
        "\n",
        "            print(\"Loading data into RAM\")\n",
        "            x_loaded = {\"train\": [], \"val\": [], \"test\": []}\n",
        "\n",
        "            for set_key, set_value in dataset_splits.items():\n",
        "                print(\"Currently loading into memory the {} set\".format(set_key))\n",
        "                # print(\"Set value is {}\".format(set_value))\n",
        "                x_loaded[set_key] = {key: np.zeros(len(value), ) for key, value in set_value.items()}\n",
        "                # for class_key, class_value in set_value.items():\n",
        "                with tqdm.tqdm(total=len(set_value)) as pbar_memory_load:\n",
        "                    with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
        "                        # Process the list of files, but split the work across the process pool to use all CPUs!\n",
        "                        for (class_label, class_images_loaded) in executor.map(self.load_parallel_batch, (set_value.items())):\n",
        "                            x_loaded[set_key][class_label] = class_images_loaded\n",
        "                            pbar_memory_load.update(1)\n",
        "\n",
        "            dataset_splits = x_loaded\n",
        "            self.data_loaded_in_memory = True\n",
        "\n",
        "        return dataset_splits\n",
        "\n",
        "    def load_datapaths(self):\n",
        "        \"\"\"\n",
        "        If saved json dictionaries of the data are available, then this method loads the dictionaries such that the\n",
        "        data is ready to be read. If the json dictionaries do not exist, then this method calls get_data_paths()\n",
        "        which will build the json dictionary containing the class to filepath samples, and then store them.\n",
        "        :return: data_image_paths: dict containing class to filepath list pairs.\n",
        "                 index_to_label_name_dict_file: dict containing numerical indexes mapped to the human understandable\n",
        "                 string-names of the class\n",
        "                 label_to_index: dictionary containing human understandable string mapped to numerical indexes\n",
        "        \"\"\"\n",
        "        dataset_dir = config[\"dataset_path\"]\n",
        "        data_path_file = \"{}/{}.json\".format(dataset_dir, self.dataset_name)\n",
        "        self.index_to_label_name_dict_file = \"{}/map_to_label_name_{}.json\".format(dataset_dir, self.dataset_name)\n",
        "        # print(self.index_to_label_name_dict_file)\n",
        "        self.label_name_to_map_dict_file = \"{}/label_name_to_map_{}.json\".format(dataset_dir, self.dataset_name)\n",
        "        # print(self.label_name_to_map_dict_file)\n",
        "\n",
        "        if not os.path.exists(data_path_file):\n",
        "            self.reset_stored_filepaths = True\n",
        "\n",
        "        if self.reset_stored_filepaths == True:\n",
        "            if os.path.exists(data_path_file):\n",
        "                os.remove(data_path_file)\n",
        "            self.reset_stored_filepaths = False\n",
        "\n",
        "        try:\n",
        "            data_image_paths = self.load_from_json(filename=data_path_file)\n",
        "            #json name difference; takes in /content/datasets...\n",
        "            #changed to datasets/... which is appended to new path\n",
        "            label_to_index = self.load_from_json(filename=self.label_name_to_map_dict_file)\n",
        "            index_to_label_name_dict_file = self.load_from_json(filename=self.index_to_label_name_dict_file)\n",
        "\n",
        "\n",
        "            # print(data_image_paths)\n",
        "            # print(index_to_label_name_dict_file)\n",
        "            # print(label_to_index)\n",
        "            return data_image_paths, index_to_label_name_dict_file, label_to_index\n",
        "        except:\n",
        "            print(\"Mapped data paths can't be found, remapping paths..\")\n",
        "            data_image_paths, code_to_label_name, label_name_to_code = self.get_data_paths()\n",
        "            self.save_to_json(dict_to_store=data_image_paths, filename=data_path_file)\n",
        "            self.save_to_json(dict_to_store=code_to_label_name, filename=self.index_to_label_name_dict_file)\n",
        "            self.save_to_json(dict_to_store=label_name_to_code, filename=self.label_name_to_map_dict_file)\n",
        "            return self.load_datapaths()\n",
        "\n",
        "    def save_to_json(self, filename, dict_to_store):\n",
        "        with open(os.path.abspath(filename), 'w') as f:\n",
        "            json.dump(dict_to_store, fp=f)\n",
        "\n",
        "    def load_from_json(self, filename):\n",
        "        with open(filename, mode=\"r\") as f:\n",
        "            load_dict = json.load(fp=f)\n",
        "\n",
        "        return load_dict\n",
        "\n",
        "    def load_test_image(self, filepath):\n",
        "        \"\"\"\n",
        "        Tests whether a target filepath contains an uncorrupted image. If image is corrupted, attempt to fix.\n",
        "        :param filepath: Filepath of image to be tested\n",
        "        :return: Return filepath of image if image exists and is uncorrupted (or attempt to fix has succeeded),\n",
        "        else return None\n",
        "        \"\"\"\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(filepath)\n",
        "        except RuntimeWarning:\n",
        "            os.system(\"convert {} -strip {}\".format(filepath, filepath))\n",
        "            print(\"converting\")\n",
        "            image = Image.open(filepath)\n",
        "        except:\n",
        "            print(\"Broken image\")\n",
        "\n",
        "        if image is not None:\n",
        "            return filepath\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def get_data_paths(self):\n",
        "        \"\"\"\n",
        "        Method that scans the dataset directory and generates class to image-filepath list dictionaries.\n",
        "        :return: data_image_paths: dict containing class to filepath list pairs.\n",
        "                 index_to_label_name_dict_file: dict containing numerical indexes mapped to the human understandable\n",
        "                 string-names of the class\n",
        "                 label_to_index: dictionary containing human understandable string mapped to numerical indexes\n",
        "        \"\"\"\n",
        "        print(\"Get images from\", self.data_path)\n",
        "        data_image_path_list_raw = []\n",
        "        labels = set()\n",
        "        for subdir, dir, files in os.walk(self.data_path):\n",
        "            for file in files:\n",
        "                if (\".jpeg\") in file.lower() or (\".png\") in file.lower() or (\".jpg\") in file.lower():\n",
        "                    filepath = os.path.abspath(os.path.join(subdir, file))\n",
        "                    label = self.get_label_from_path(filepath)\n",
        "                    data_image_path_list_raw.append(filepath)\n",
        "                    labels.add(label)\n",
        "\n",
        "        labels = sorted(labels)\n",
        "        idx_to_label_name = {idx: label for idx, label in enumerate(labels)}\n",
        "        label_name_to_idx = {label: idx for idx, label in enumerate(labels)}\n",
        "        data_image_path_dict = {idx: [] for idx in list(idx_to_label_name.keys())}\n",
        "        with tqdm.tqdm(total=len(data_image_path_list_raw)) as pbar_error:\n",
        "            with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
        "                # Process the list of files, but split the work across the process pool to use all CPUs!\n",
        "                for image_file in executor.map(self.load_test_image, (data_image_path_list_raw)):\n",
        "                    pbar_error.update(1)\n",
        "                    if image_file is not None:\n",
        "                        label = self.get_label_from_path(image_file)\n",
        "                        data_image_path_dict[label_name_to_idx[label]].append(image_file)\n",
        "\n",
        "        return data_image_path_dict, idx_to_label_name, label_name_to_idx\n",
        "\n",
        "    def get_label_set(self):\n",
        "        \"\"\"\n",
        "        Generates a set containing all class numerical indexes\n",
        "        :return: A set containing all class numerical indexes\n",
        "        \"\"\"\n",
        "        index_to_label_name_dict_file = self.load_from_json(filename=self.index_to_label_name_dict_file)\n",
        "        return set(list(index_to_label_name_dict_file.keys()))\n",
        "\n",
        "    def get_index_from_label(self, label):\n",
        "        \"\"\"\n",
        "        Given a class's (human understandable) string, returns the numerical index of that class\n",
        "        :param label: A string of a human understandable class contained in the dataset\n",
        "        :return: An int containing the numerical index of the given class-string\n",
        "        \"\"\"\n",
        "        label_to_index = self.load_from_json(filename=self.label_name_to_map_dict_file)\n",
        "        return label_to_index[label]\n",
        "\n",
        "    def get_label_from_index(self, index):\n",
        "        \"\"\"\n",
        "        Given an index return the human understandable label mapping to it.\n",
        "        :param index: A numerical index (int)\n",
        "        :return: A human understandable label (str)\n",
        "        \"\"\"\n",
        "        index_to_label_name = self.load_from_json(filename=self.index_to_label_name_dict_file)\n",
        "        return index_to_label_name[index]\n",
        "\n",
        "    def get_label_from_path(self, filepath):\n",
        "        \"\"\"\n",
        "        Given a path of an image generate the human understandable label for that image.\n",
        "        :param filepath: The image's filepath\n",
        "        :return: A human understandable label.\n",
        "        \"\"\"\n",
        "        label_bits = filepath.split(\"/\")\n",
        "        label = \"/\".join([label_bits[idx] for idx in self.indexes_of_folders_indicating_class])\n",
        "        if self.labels_as_int:\n",
        "            label = int(label)\n",
        "        return label\n",
        "\n",
        "    def load_image(self, image_path, channels):\n",
        "        \"\"\"\n",
        "        Given an image filepath and the number of channels to keep, load an image and keep the specified channels\n",
        "        :param image_path: The image's filepath\n",
        "        :param channels: The number of channels to keep\n",
        "        :return: An image array of shape (h, w, channels), whose values range between 0.0 and 1.0.\n",
        "        \"\"\"\n",
        "        if not self.data_loaded_in_memory:\n",
        "            image = Image.open(image_path)\n",
        "            if 'omniglot' in self.dataset_name:\n",
        "                image = image.resize((self.image_height, self.image_width), resample=Image.LANCZOS)\n",
        "                image = np.array(image, np.float32)\n",
        "                if channels == 1:\n",
        "                    image = np.expand_dims(image, axis=2)\n",
        "            else:\n",
        "                image = image.resize((self.image_height, self.image_width)).convert('RGB')\n",
        "                image = np.array(image, np.float32)\n",
        "                image = image / 255.0\n",
        "        else:\n",
        "            image = image_path\n",
        "\n",
        "        return image\n",
        "\n",
        "    def load_batch(self, batch_image_paths):\n",
        "        \"\"\"\n",
        "        Load a batch of images, given a list of filepaths\n",
        "        :param batch_image_paths: A list of filepaths\n",
        "        :return: A numpy array of images of shape batch, height, width, channels\n",
        "        \"\"\"\n",
        "        image_batch = []\n",
        "\n",
        "        if self.data_loaded_in_memory:\n",
        "            for image_path in batch_image_paths:\n",
        "                image_batch.append(image_path)\n",
        "            image_batch = np.array(image_batch, dtype=np.float32)\n",
        "            #print(image_batch.shape)\n",
        "        else:\n",
        "            print(\"BATCH IMAGE PATH (no content?):\")\n",
        "            print(image_path)\n",
        "            image_batch = [self.load_image(image_path=image_path, channels=self.image_channel)\n",
        "                           for image_path in batch_image_paths]\n",
        "            image_batch = np.array(image_batch, dtype=np.float32)\n",
        "            image_batch = self.preprocess_data(image_batch)\n",
        "\n",
        "        return image_batch\n",
        "\n",
        "    def load_parallel_batch(self, inputs):\n",
        "        \"\"\"\n",
        "        Load a batch of images, given a list of filepaths\n",
        "        :param batch_image_paths: A list of filepaths\n",
        "        :return: A numpy array of images of shape batch, height, width, channels\n",
        "        \"\"\"\n",
        "        class_label, batch_image_paths = inputs\n",
        "        image_batch = []\n",
        "\n",
        "        if self.data_loaded_in_memory:\n",
        "            for image_path in batch_image_paths:\n",
        "                image_batch.append(np.copy(image_path))\n",
        "            image_batch = np.array(image_batch, dtype=np.float32)\n",
        "        else:\n",
        "            #with tqdm.tqdm(total=1) as load_pbar:\n",
        "            image_batch = [self.load_image(image_path=image_path, channels=self.image_channel)\n",
        "                           for image_path in batch_image_paths]\n",
        "                #load_pbar.update(1)\n",
        "\n",
        "            image_batch = np.array(image_batch, dtype=np.float32)\n",
        "            image_batch = self.preprocess_data(image_batch)\n",
        "\n",
        "        return class_label, image_batch\n",
        "\n",
        "    def preprocess_data(self, x):\n",
        "        \"\"\"\n",
        "        Preprocesses data such that their shapes match the specified structures\n",
        "        :param x: A data batch to preprocess\n",
        "        :return: A preprocessed data batch\n",
        "        \"\"\"\n",
        "        x_shape = x.shape\n",
        "        x = np.reshape(x, (-1, x_shape[-3], x_shape[-2], x_shape[-1]))\n",
        "        if self.reverse_channels is True:\n",
        "            reverse_photos = np.ones(shape=x.shape)\n",
        "            for channel in range(x.shape[-1]):\n",
        "                reverse_photos[:, :, :, x.shape[-1] - 1 - channel] = x[:, :, :, channel]\n",
        "            x = reverse_photos\n",
        "        x = x.reshape(x_shape)\n",
        "        return x\n",
        "\n",
        "    def reconstruct_original(self, x):\n",
        "        \"\"\"\n",
        "        Applies the reverse operations that preprocess_data() applies such that the data returns to their original form\n",
        "        :param x: A batch of data to reconstruct\n",
        "        :return: A reconstructed batch of data\n",
        "        \"\"\"\n",
        "        x = x * 255.0\n",
        "        return x\n",
        "\n",
        "    def shuffle(self, x, rng):\n",
        "        \"\"\"\n",
        "        Shuffles the data batch along it's first axis\n",
        "        :param x: A data batch\n",
        "        :return: A shuffled data batch\n",
        "        \"\"\"\n",
        "        indices = np.arange(len(x))\n",
        "        rng.shuffle(indices)\n",
        "        x = x[indices]\n",
        "        return x\n",
        "\n",
        "    def get_set(self, dataset_name, seed, augment_images=False):\n",
        "        \"\"\"\n",
        "        Generates a task-set to be used for training or evaluation\n",
        "        :param set_name: The name of the set to use, e.g. \"train\", \"val\" etc.\n",
        "        :return: A task-set containing an image and label support set, and an image and label target set.\n",
        "        \"\"\"\n",
        "        #seed = seed % self.args.total_unique_tasks\n",
        "        rng = np.random.RandomState(seed)\n",
        "\n",
        "        # print(self.dataset_size_dict)\n",
        "        selected_classes = rng.choice(list(self.dataset_size_dict[dataset_name].keys()),\n",
        "                                      size=self.num_classes_per_set, replace=False)\n",
        "        rng.shuffle(selected_classes)\n",
        "        k_list = rng.randint(0, 4, size=self.num_classes_per_set)\n",
        "        k_dict = {selected_class: k_item for (selected_class, k_item) in zip(selected_classes, k_list)}\n",
        "        episode_labels = [i for i in range(self.num_classes_per_set)]\n",
        "        class_to_episode_label = {selected_class: episode_label for (selected_class, episode_label) in\n",
        "                                  zip(selected_classes, episode_labels)}\n",
        "\n",
        "        x_images = []\n",
        "        y_labels = []\n",
        "\n",
        "        for class_entry in selected_classes:\n",
        "            choose_samples_list = rng.choice(self.dataset_size_dict[dataset_name][class_entry],\n",
        "                                             size=self.num_samples_per_class + self.num_target_samples, replace=False)\n",
        "            class_image_samples = []\n",
        "            class_labels = []\n",
        "            for sample in choose_samples_list:\n",
        "                choose_samples = self.datasets[dataset_name][class_entry][sample]\n",
        "                x_class_data = self.load_batch([choose_samples])[0]\n",
        "                k = k_dict[class_entry]\n",
        "                x_class_data = augment_image(image=x_class_data, k=k,\n",
        "                                             channels=self.image_channel, augment_bool=augment_images,\n",
        "                                             dataset_name=self.dataset_name, args=self.args)\n",
        "                class_image_samples.append(x_class_data)\n",
        "                class_labels.append(int(class_to_episode_label[class_entry]))\n",
        "            class_image_samples = torch.stack(class_image_samples)\n",
        "            x_images.append(class_image_samples)\n",
        "            y_labels.append(class_labels)\n",
        "\n",
        "        x_images = torch.stack(x_images)\n",
        "        y_labels = np.array(y_labels, dtype=np.float32)\n",
        "\n",
        "        support_set_images = x_images[:, :self.num_samples_per_class]\n",
        "        support_set_labels = y_labels[:, :self.num_samples_per_class]\n",
        "        target_set_images = x_images[:, self.num_samples_per_class:]\n",
        "        target_set_labels = y_labels[:, self.num_samples_per_class:]\n",
        "\n",
        "        return support_set_images, target_set_images, support_set_labels, target_set_labels, seed\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_length[self.current_set_name]\n",
        "\n",
        "    def length(self, set_name):\n",
        "        self.switch_set(set_name=set_name)\n",
        "        return len(self)\n",
        "\n",
        "    def set_augmentation(self, augment_images):\n",
        "        self.augment_images = augment_images\n",
        "\n",
        "    def switch_set(self, set_name, current_iter=None):\n",
        "        self.current_set_name = set_name\n",
        "        if set_name == \"train\":\n",
        "            self.update_seed(dataset_name=set_name, seed=self.init_seed[set_name] + current_iter)\n",
        "\n",
        "    def update_seed(self, dataset_name, seed=100):\n",
        "        self.seed[dataset_name] = seed\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        support_set_images, target_set_image, support_set_labels, target_set_label, seed = \\\n",
        "            self.get_set(self.current_set_name, seed=self.seed[self.current_set_name] + idx,\n",
        "                         augment_images=self.augment_images)\n",
        "\n",
        "        return support_set_images, target_set_image, support_set_labels, target_set_label, seed\n",
        "\n",
        "    def reset_seed(self):\n",
        "        self.seed = self.init_seed\n",
        "\n",
        "\n",
        "class MetaLearningSystemDataLoader(object):\n",
        "    def __init__(self, args, current_iter=0):\n",
        "        \"\"\"\n",
        "        Initializes a meta learning system dataloader. The data loader uses the Pytorch DataLoader class to parallelize\n",
        "        batch sampling and preprocessing.\n",
        "        :param args: An arguments NamedTuple containing all the required arguments.\n",
        "        :param current_iter: Current iter of experiment. Is used to make sure the data loader continues where it left\n",
        "        of previously.\n",
        "        \"\"\"\n",
        "        self.num_of_gpus = args.num_of_gpus\n",
        "        self.batch_size = args.batch_size\n",
        "        self.samples_per_iter = args.samples_per_iter\n",
        "        self.num_workers = args.num_dataprovider_workers\n",
        "        self.total_train_iters_produced = 0\n",
        "        self.dataset = FewShotLearningDatasetParallel(args=args)\n",
        "        self.batches_per_iter = args.samples_per_iter\n",
        "        self.full_data_length = self.dataset.data_length\n",
        "        self.continue_from_iter(current_iter=current_iter)\n",
        "        self.args = args\n",
        "\n",
        "    def get_dataloader(self):\n",
        "        \"\"\"\n",
        "        Returns a data loader with the correct set (train, val or test), continuing from the current iter.\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return DataLoader(self.dataset, batch_size=(self.num_of_gpus * self.batch_size * self.samples_per_iter),\n",
        "                          shuffle=False, num_workers=self.num_workers, drop_last=True)\n",
        "\n",
        "    def continue_from_iter(self, current_iter):\n",
        "        \"\"\"\n",
        "        Makes sure the data provider is aware of where we are in terms of training iterations in the experiment.\n",
        "        :param current_iter:\n",
        "        \"\"\"\n",
        "        self.total_train_iters_produced += (current_iter * (self.num_of_gpus * self.batch_size * self.samples_per_iter))\n",
        "\n",
        "    def get_train_batches(self, total_batches=-1, augment_images=False):\n",
        "        \"\"\"\n",
        "        Returns a training batches data_loader\n",
        "        :param total_batches: The number of batches we want the data loader to sample\n",
        "        :param augment_images: Whether we want the images to be augmented.\n",
        "        \"\"\"\n",
        "        if total_batches == -1:\n",
        "            self.dataset.data_length = self.full_data_length\n",
        "        else:\n",
        "            self.dataset.data_length[\"train\"] = total_batches * self.dataset.batch_size\n",
        "        self.dataset.switch_set(set_name=\"train\", current_iter=self.total_train_iters_produced)\n",
        "        self.dataset.set_augmentation(augment_images=augment_images)\n",
        "        self.total_train_iters_produced += (self.num_of_gpus * self.batch_size * self.samples_per_iter)\n",
        "        for sample_id, sample_batched in enumerate(self.get_dataloader()):\n",
        "            yield sample_batched\n",
        "\n",
        "\n",
        "    def get_val_batches(self, total_batches=-1, augment_images=False):\n",
        "        \"\"\"\n",
        "        Returns a validation batches data_loader\n",
        "        :param total_batches: The number of batches we want the data loader to sample\n",
        "        :param augment_images: Whether we want the images to be augmented.\n",
        "        \"\"\"\n",
        "        if total_batches == -1:\n",
        "            self.dataset.data_length = self.full_data_length\n",
        "        else:\n",
        "            self.dataset.data_length['val'] = total_batches * self.dataset.batch_size\n",
        "        self.dataset.switch_set(set_name=\"val\")\n",
        "        self.dataset.set_augmentation(augment_images=augment_images)\n",
        "        for sample_id, sample_batched in enumerate(self.get_dataloader()):\n",
        "            yield sample_batched\n",
        "\n",
        "\n",
        "    def get_test_batches(self, total_batches=-1, augment_images=False):\n",
        "        \"\"\"\n",
        "        Returns a testing batches data_loader\n",
        "        :param total_batches: The number of batches we want the data loader to sample\n",
        "        :param augment_images: Whether we want the images to be augmented.\n",
        "        \"\"\"\n",
        "        if total_batches == -1:\n",
        "            self.dataset.data_length = self.full_data_length\n",
        "        else:\n",
        "            self.dataset.data_length['test'] = total_batches * self.dataset.batch_size\n",
        "        self.dataset.switch_set(set_name='test')\n",
        "        self.dataset.set_augmentation(augment_images=augment_images)\n",
        "        for sample_id, sample_batched in enumerate(self.get_dataloader()):\n",
        "            yield sample_batched"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27S6f3VZp0jo"
      },
      "source": [
        "# Train MAML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wXc8OJUvwZp2"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "config = {\n",
        "  \"batch_size\":8,\n",
        "  \"image_height\":28,\n",
        "  \"image_width\":28,\n",
        "  \"image_channels\":1,\n",
        "  \"gpu_to_use\":0,\n",
        "  \"num_dataprovider_workers\":4,\n",
        "  \"max_models_to_save\":5,\n",
        "  \"dataset_name\":\"omniglot_dataset\",\n",
        "  \"dataset_path\":\"/content/HowToTrainYourMAMLPytorch/datasets\",\n",
        "  \"reset_stored_paths\":False,\n",
        "  \"experiment_name\":\"omniglot_5_8_0.1_64_20_2\",\n",
        "  \"train_seed\": 2, \"val_seed\": 0,\n",
        "  \"train_val_test_split\": [0.70918052988, 0.03080714725, 0.2606284658],\n",
        "  \"indexes_of_folders_indicating_class\": [-3, -2],\n",
        "  \"load_from_npz_files\": False,\n",
        "  \"sets_are_pre_split\": False,\n",
        "  \"load_into_memory\": True,\n",
        "  \"init_inner_loop_learning_rate\": 0.1,\n",
        "  \"train_in_stages\": False,\n",
        "  \"multi_step_loss_num_epochs\": 10,\n",
        "  \"minimum_per_task_contribution\": 0.01,\n",
        "  \"num_evaluation_tasks\":600,\n",
        "  \"learnable_per_layer_per_step_inner_loop_learning_rate\": True,\n",
        "  \"enable_inner_loop_optimizable_bn_params\": False,\n",
        "\n",
        "  \"total_epochs\": 150,\n",
        "  \"total_iter_per_epoch\":500, \"continue_from_epoch\": -2,\n",
        "  \"evaluate_on_test_set_only\": False,\n",
        "  \"max_pooling\": True,\n",
        "  \"per_step_bn_statistics\": True,\n",
        "  \"learnable_batch_norm_momentum\": False,\n",
        "  \"evalute_on_test_set_only\": False,\n",
        "  \"learnable_bn_gamma\": True,\n",
        "  \"learnable_bn_beta\": True,\n",
        "\n",
        "  \"weight_decay\": 0.0,\n",
        "  \"dropout_rate_value\":0.0,\n",
        "  \"min_learning_rate\":0.00001,\n",
        "  \"meta_learning_rate\":0.001,   \"total_epochs_before_pause\": 150,\n",
        "  \"first_order_to_second_order_epoch\":-1,\n",
        "\n",
        "  \"norm_layer\":\"batch_norm\",\n",
        "  \"cnn_num_filters\":64,\n",
        "  \"num_stages\":4,\n",
        "  \"conv_padding\": True,\n",
        "  \"number_of_training_steps_per_iter\":5,\n",
        "  \"number_of_evaluation_steps_per_iter\":5,\n",
        "  \"cnn_blocks_per_stage\":1,\n",
        "  \"num_classes_per_set\":5,\n",
        "  \"num_samples_per_class\":5,\n",
        "  \"num_target_samples\": 1,\n",
        "\n",
        "  \"second_order\": True,\n",
        "  \"use_multi_step_loss_optimization\":True,\n",
        "\n",
        "\n",
        "  # \"seed\": 2,\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "with open(\"omniglot_maml++-omniglot_5_8_0.1_64_20_2.json\", \"w\") as outfile:\n",
        "    json.dump(config, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "D0LK35JzzHRM"
      },
      "outputs": [],
      "source": [
        "# from torch import cuda\n",
        "\n",
        "\n",
        "# def get_args():\n",
        "#     import argparse\n",
        "#     import os\n",
        "#     import torch\n",
        "#     import json\n",
        "#     parser = argparse.ArgumentParser(description='Welcome to the MAML++ training and inference system')\n",
        "\n",
        "#     parser.add_argument('--batch_size', nargs=\"?\", type=int, default=32, help='Batch_size for experiment')\n",
        "#     parser.add_argument('--image_height', nargs=\"?\", type=int, default=28)\n",
        "#     parser.add_argument('--image_width', nargs=\"?\", type=int, default=28)\n",
        "#     parser.add_argument('--image_channels', nargs=\"?\", type=int, default=1)\n",
        "#     parser.add_argument('--reset_stored_filepaths', type=str, default=\"False\")\n",
        "#     parser.add_argument('--reverse_channels', type=str, default=\"False\")\n",
        "#     parser.add_argument('--num_of_gpus', type=int, default=1)\n",
        "#     parser.add_argument('--indexes_of_folders_indicating_class', nargs='+', default=[-2, -3])\n",
        "#     parser.add_argument('--train_val_test_split', nargs='+', default=[0.73982737361, 0.26, 0.13008631319])\n",
        "#     parser.add_argument('--samples_per_iter', nargs=\"?\", type=int, default=1)\n",
        "#     parser.add_argument('--labels_as_int', type=str, default=\"False\")\n",
        "#     parser.add_argument('--seed', type=int, default=104)\n",
        "\n",
        "#     parser.add_argument('--gpu_to_use', type=int)\n",
        "#     parser.add_argument('--num_dataprovider_workers', nargs=\"?\", type=int, default=4)\n",
        "#     parser.add_argument('--max_models_to_save', nargs=\"?\", type=int, default=5)\n",
        "#     parser.add_argument('--dataset_name', type=str, default=\"omniglot_dataset\")\n",
        "#     parser.add_argument('--dataset_path', type=str, default=\"datasets/omniglot_dataset\")\n",
        "#     parser.add_argument('--reset_stored_paths', type=str, default=\"False\")\n",
        "#     parser.add_argument('--experiment_name', nargs=\"?\", type=str, )\n",
        "#     parser.add_argument('--architecture_name', nargs=\"?\", type=str)\n",
        "#     parser.add_argument('--continue_from_epoch', nargs=\"?\", type=str, default='latest', help='Continue from checkpoint of epoch')\n",
        "#     parser.add_argument('--dropout_rate_value', type=float, default=0.3, help='Dropout_rate_value')\n",
        "#     parser.add_argument('--num_target_samples', type=int, default=15, help='Dropout_rate_value')\n",
        "#     parser.add_argument('--second_order', type=str, default=\"False\", help='Dropout_rate_value')\n",
        "#     parser.add_argument('--total_epochs', type=int, default=200, help='Number of epochs per experiment')\n",
        "#     parser.add_argument('--total_iter_per_epoch', type=int, default=500, help='Number of iters per epoch')\n",
        "#     parser.add_argument('--min_learning_rate', type=float, default=0.00001, help='Min learning rate')\n",
        "#     parser.add_argument('--meta_learning_rate', type=float, default=0.001, help='Learning rate of overall MAML system')\n",
        "#     parser.add_argument('--meta_opt_bn', type=str, default=\"False\")\n",
        "#     parser.add_argument('--task_learning_rate', type=float, default=0.1, help='Learning rate per task gradient step')\n",
        "\n",
        "#     parser.add_argument('--norm_layer', type=str, default=\"batch_norm\")\n",
        "#     parser.add_argument('--max_pooling', type=str, default=\"False\")\n",
        "#     parser.add_argument('--per_step_bn_statistics', type=str, default=\"False\")\n",
        "#     parser.add_argument('--num_classes_per_set', type=int, default=20, help='Number of classes to sample per set')\n",
        "#     parser.add_argument('--cnn_num_blocks', type=int, default=4, help='Number of classes to sample per set')\n",
        "#     parser.add_argument('--number_of_training_steps_per_iter', type=int, default=1, help='Number of classes to sample per set')\n",
        "#     parser.add_argument('--number_of_evaluation_steps_per_iter', type=int, default=1, help='Number of classes to sample per set')\n",
        "#     parser.add_argument('--cnn_num_filters', type=int, default=64, help='Number of classes to sample per set')\n",
        "#     parser.add_argument('--cnn_blocks_per_stage', type=int, default=1,\n",
        "#                         help='Number of classes to sample per set')\n",
        "#     parser.add_argument('--num_samples_per_class', type=int, default=1, help='Number of samples per set to sample')\n",
        "#     parser.add_argument('--name_of_args_json_file', type=str, default=\"None\")\n",
        "\n",
        "#     args = parser.parse_args()\n",
        "#     args_dict = vars(args)\n",
        "#     if args.name_of_args_json_file is not \"None\":\n",
        "#         args_dict = extract_args_from_json(args.name_of_args_json_file, args_dict)\n",
        "\n",
        "#     for key in list(args_dict.keys()):\n",
        "\n",
        "#         if str(args_dict[key]).lower() == \"true\":\n",
        "#             args_dict[key] = True\n",
        "#         elif str(args_dict[key]).lower() == \"false\":\n",
        "#             args_dict[key] = False\n",
        "#         if key == \"dataset_path\":\n",
        "#             args_dict[key] = os.path.join(os.environ['DATASET_DIR'], args_dict[key])\n",
        "#             print(key, os.path.join(os.environ['DATASET_DIR'], args_dict[key]))\n",
        "\n",
        "#         print(key, args_dict[key], type(args_dict[key]))\n",
        "\n",
        "#     args = Bunch(args_dict)\n",
        "\n",
        "\n",
        "#     args.use_cuda = torch.cuda.is_available()\n",
        "#     if torch.cuda.is_available():  # checks whether a cuda gpu is available and whether the gpu flag is True\n",
        "#         device = torch.cuda.current_device()\n",
        "\n",
        "#         print(\"use GPU\", device)\n",
        "#         print(\"GPU ID {}\".format(torch.cuda.current_device()))\n",
        "\n",
        "#     else:\n",
        "#         print(\"use CPU\")\n",
        "#         device = torch.device('cpu')  # sets the device to be CPU\n",
        "\n",
        "\n",
        "#     return args, device\n",
        "\n",
        "\n",
        "\n",
        "# class Bunch(object):\n",
        "#   def __init__(self, adict):\n",
        "#     self.__dict__.update(adict)\n",
        "\n",
        "# def extract_args_from_json(json_file_path, args_dict):\n",
        "#     import json\n",
        "#     summary_filename = json_file_path\n",
        "#     with open(summary_filename) as f:\n",
        "#         summary_dict = json.load(fp=f)\n",
        "\n",
        "#     for key in summary_dict.keys():\n",
        "#         if \"continue_from\" not in key and \"gpu_to_use\" not in key:\n",
        "#             args_dict[key] = summary_dict[key]\n",
        "\n",
        "#     return args_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RcsmAhVaCUNP"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import json\n",
        "\n",
        "class Bunch(object):\n",
        "    def __init__(self, adict):\n",
        "        self.__dict__.update(adict)\n",
        "\n",
        "def load_args_from_json(json_file_path):\n",
        "    def extract_args_from_json(json_file_path, args_dict):\n",
        "        with open(json_file_path) as f:\n",
        "            summary_dict = json.load(fp=f)\n",
        "        for key, value in summary_dict.items():\n",
        "            if \"continue_from\" not in key and \"gpu_to_use\" not in key:\n",
        "                args_dict[key] = value\n",
        "        return args_dict\n",
        "\n",
        "    parser = argparse.ArgumentParser(description='Welcome to the MAML++ training and inference system')\n",
        "\n",
        "    parser.add_argument('--batch_size', type=int, default=32, help='Batch_size for experiment')\n",
        "    parser.add_argument('--image_height', type=int, default=28)\n",
        "    parser.add_argument('--image_width', type=int, default=28)\n",
        "    parser.add_argument('--image_channels', type=int, default=1)\n",
        "    parser.add_argument('--reset_stored_filepaths', type=str, default=\"False\")\n",
        "    parser.add_argument('--reverse_channels', type=str, default=\"False\")\n",
        "    parser.add_argument('--num_of_gpus', type=int, default=1)\n",
        "    parser.add_argument('--indexes_of_folders_indicating_class', nargs='+', default=[-2, -3])\n",
        "    parser.add_argument('--train_val_test_split', nargs='+', default=[0.73982737361, 0.26, 0.13008631319])\n",
        "    parser.add_argument('--samples_per_iter', type=int, default=1)\n",
        "    parser.add_argument('--labels_as_int', type=str, default=\"False\")\n",
        "    parser.add_argument('--seed', type=int, default=104)\n",
        "\n",
        "    parser.add_argument('--gpu_to_use', type=int)\n",
        "    parser.add_argument('--num_dataprovider_workers', type=int, default=4)\n",
        "    parser.add_argument('--max_models_to_save', type=int, default=5)\n",
        "    parser.add_argument('--dataset_name', type=str, default=\"omniglot_dataset\")\n",
        "    parser.add_argument('--dataset_path', type=str, default=\"datasets/omniglot_dataset\")\n",
        "    parser.add_argument('--reset_stored_paths', type=str, default=\"False\")\n",
        "    parser.add_argument('--experiment_name', type=str)\n",
        "    parser.add_argument('--architecture_name', type=str)\n",
        "    parser.add_argument('--continue_from_epoch', type=str, default='latest', help='Continue from checkpoint of epoch')\n",
        "    parser.add_argument('--dropout_rate_value', type=float, default=0.3, help='Dropout_rate_value')\n",
        "    parser.add_argument('--num_target_samples', type=int, default=15, help='Dropout_rate_value')\n",
        "    parser.add_argument('--second_order', type=str, default=\"False\", help='Dropout_rate_value')\n",
        "    parser.add_argument('--total_epochs', type=int, default=200, help='Number of epochs per experiment')\n",
        "    parser.add_argument('--total_iter_per_epoch', type=int, default=500, help='Number of iters per epoch')\n",
        "    parser.add_argument('--min_learning_rate', type=float, default=0.00001, help='Min learning rate')\n",
        "    parser.add_argument('--meta_learning_rate', type=float, default=0.001, help='Learning rate of overall MAML system')\n",
        "    parser.add_argument('--meta_opt_bn', type=str, default=\"False\")\n",
        "    parser.add_argument('--task_learning_rate', type=float, default=0.1, help='Learning rate per task gradient step')\n",
        "\n",
        "    parser.add_argument('--norm_layer', type=str, default=\"batch_norm\")\n",
        "    parser.add_argument('--max_pooling', type=str, default=\"False\")\n",
        "    parser.add_argument('--per_step_bn_statistics', type=str, default=\"False\")\n",
        "    parser.add_argument('--num_classes_per_set', type=int, default=20, help='Number of classes to sample per set')\n",
        "    parser.add_argument('--cnn_num_blocks', type=int, default=4, help='Number of classes to sample per set')\n",
        "    parser.add_argument('--number_of_training_steps_per_iter', type=int, default=1, help='Number of classes to sample per set')\n",
        "    parser.add_argument('--number_of_evaluation_steps_per_iter', type=int, default=1, help='Number of classes to sample per set')\n",
        "    parser.add_argument('--cnn_num_filters', type=int, default=64, help='Number of classes to sample per set')\n",
        "    parser.add_argument('--cnn_blocks_per_stage', type=int, default=1, help='Number of classes to sample per set')\n",
        "    parser.add_argument('--num_samples_per_class', type=int, default=1, help='Number of samples per set to sample')\n",
        "    parser.add_argument('--name_of_args_json_file', type=str, default=\"None\")\n",
        "\n",
        "    args = parser.parse_args([])\n",
        "    args_dict = vars(args)\n",
        "\n",
        "    # Override args with JSON file values\n",
        "    if json_file_path:\n",
        "        args_dict = extract_args_from_json(json_file_path, args_dict)\n",
        "\n",
        "    # Convert string-based booleans to actual booleans\n",
        "    for key in args_dict:\n",
        "        if isinstance(args_dict[key], str) and args_dict[key].lower() == \"true\":\n",
        "            args_dict[key] = True\n",
        "        elif isinstance(args_dict[key], str) and args_dict[key].lower() == \"false\":\n",
        "            args_dict[key] = False\n",
        "\n",
        "    # Resolve dataset path if environment variable is set\n",
        "    if \"dataset_path\" in args_dict and config[\"dataset_path\"]:\n",
        "        args_dict[\"dataset_path\"] = os.path.join(config[\"dataset_path\"], args_dict[\"dataset_path\"])\n",
        "\n",
        "    args = Bunch(args_dict)\n",
        "\n",
        "    # Check if CUDA is available\n",
        "    args.use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device('cuda' if args.use_cuda else 'cpu')\n",
        "\n",
        "    return args, device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Hb1S5Yh6zf6J"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "def maybe_unzip_dataset(args):\n",
        "\n",
        "    datasets = [args.dataset_name]\n",
        "    dataset_paths = [args.dataset_path]\n",
        "    done = False\n",
        "\n",
        "    for dataset_idx, dataset_path in enumerate(dataset_paths):\n",
        "        if dataset_path.endswith('/'):\n",
        "            dataset_path = dataset_path[:-1]\n",
        "        # print(dataset_path)\n",
        "        if not os.path.exists(dataset_path):\n",
        "            print(\"Not found dataset folder structure.. searching for .tar.bz2 file\")\n",
        "            zip_directory = \"{}.tar.bz2\".format(os.path.join(config[\"dataset_path\"], datasets[dataset_idx]))\n",
        "\n",
        "            assert os.path.exists(os.path.abspath(zip_directory)), \"{} dataset zip file not found\" \\\n",
        "                                                  \"place dataset in datasets folder as explained in README\".format(os.path.abspath(zip_directory))\n",
        "            print(\"Found zip file, unpacking\")\n",
        "\n",
        "            unzip_file(filepath_pack=os.path.join(config[\"dataset_path\"], \"{}.tar.bz2\".format(datasets[dataset_idx])),\n",
        "                       filepath_to_store=config[\"dataset_path\"])\n",
        "\n",
        "\n",
        "\n",
        "            args.reset_stored_filepaths = True\n",
        "\n",
        "        total_files = 0\n",
        "        for subdir, dir, files in os.walk(dataset_path):\n",
        "            for file in files:\n",
        "                if file.lower().endswith(\".jpeg\") or file.lower().endswith(\".jpg\") or file.lower().endswith(\n",
        "                        \".png\") or file.lower().endswith(\".pkl\"):\n",
        "                    total_files += 1\n",
        "        print(\"count stuff________________________________________\", total_files)\n",
        "        if (total_files == 1623 * 20 and datasets[dataset_idx] == 'omniglot_dataset') or (\n",
        "                total_files == 100 * 600 and 'mini_imagenet' in datasets[dataset_idx]) or (\n",
        "                total_files == 3 and 'mini_imagenet_pkl' in datasets[dataset_idx]):\n",
        "            print(\"file count is correct\")\n",
        "            done = True\n",
        "        elif datasets[dataset_idx] not in [\n",
        "            'omniglot_dataset',\n",
        "            'mini_imagenet',\n",
        "            'mini_imagenet_pkl',\n",
        "        ]:\n",
        "            done = True\n",
        "            print(\"using new dataset\")\n",
        "\n",
        "        if not done:\n",
        "            shutil.rmtree(dataset_path, ignore_errors=True)\n",
        "            maybe_unzip_dataset(args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UKVzZ6KPXvzN"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/HowToTrainYourMAMLPytorch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuRv8nXqp2zr",
        "outputId": "30d4cf06-d06d-49df-def8-956885771d67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using max pooling\n",
            "torch.Size([2, 64, 28, 28])\n",
            "torch.Size([2, 64, 14, 14])\n",
            "torch.Size([2, 64, 7, 7])\n",
            "torch.Size([2, 64, 3, 3])\n",
            "VGGNetwork build torch.Size([2, 5])\n",
            "meta network params\n",
            "layer_dict.conv0.conv.weight torch.Size([64, 1, 3, 3])\n",
            "layer_dict.conv0.conv.bias torch.Size([64])\n",
            "layer_dict.conv0.norm_layer.running_mean torch.Size([5, 64])\n",
            "layer_dict.conv0.norm_layer.running_var torch.Size([5, 64])\n",
            "layer_dict.conv0.norm_layer.bias torch.Size([5, 64])\n",
            "layer_dict.conv0.norm_layer.weight torch.Size([5, 64])\n",
            "layer_dict.conv1.conv.weight torch.Size([64, 64, 3, 3])\n",
            "layer_dict.conv1.conv.bias torch.Size([64])\n",
            "layer_dict.conv1.norm_layer.running_mean torch.Size([5, 64])\n",
            "layer_dict.conv1.norm_layer.running_var torch.Size([5, 64])\n",
            "layer_dict.conv1.norm_layer.bias torch.Size([5, 64])\n",
            "layer_dict.conv1.norm_layer.weight torch.Size([5, 64])\n",
            "layer_dict.conv2.conv.weight torch.Size([64, 64, 3, 3])\n",
            "layer_dict.conv2.conv.bias torch.Size([64])\n",
            "layer_dict.conv2.norm_layer.running_mean torch.Size([5, 64])\n",
            "layer_dict.conv2.norm_layer.running_var torch.Size([5, 64])\n",
            "layer_dict.conv2.norm_layer.bias torch.Size([5, 64])\n",
            "layer_dict.conv2.norm_layer.weight torch.Size([5, 64])\n",
            "layer_dict.conv3.conv.weight torch.Size([64, 64, 3, 3])\n",
            "layer_dict.conv3.conv.bias torch.Size([64])\n",
            "layer_dict.conv3.norm_layer.running_mean torch.Size([5, 64])\n",
            "layer_dict.conv3.norm_layer.running_var torch.Size([5, 64])\n",
            "layer_dict.conv3.norm_layer.bias torch.Size([5, 64])\n",
            "layer_dict.conv3.norm_layer.weight torch.Size([5, 64])\n",
            "layer_dict.linear.weights torch.Size([5, 64])\n",
            "layer_dict.linear.bias torch.Size([5])\n",
            "0.1\n",
            "Inner Loop parameters\n",
            "names_learning_rates_dict.layer_dict-conv0-conv-weight torch.Size([6])\n",
            "names_learning_rates_dict.layer_dict-conv0-conv-bias torch.Size([6])\n",
            "names_learning_rates_dict.layer_dict-conv1-conv-weight torch.Size([6])\n",
            "names_learning_rates_dict.layer_dict-conv1-conv-bias torch.Size([6])\n",
            "names_learning_rates_dict.layer_dict-conv2-conv-weight torch.Size([6])\n",
            "names_learning_rates_dict.layer_dict-conv2-conv-bias torch.Size([6])\n",
            "names_learning_rates_dict.layer_dict-conv3-conv-weight torch.Size([6])\n",
            "names_learning_rates_dict.layer_dict-conv3-conv-bias torch.Size([6])\n",
            "names_learning_rates_dict.layer_dict-linear-weights torch.Size([6])\n",
            "names_learning_rates_dict.layer_dict-linear-bias torch.Size([6])\n",
            "Outer Loop parameters\n",
            "classifier.layer_dict.conv0.conv.weight torch.Size([64, 1, 3, 3]) cuda:0 True\n",
            "classifier.layer_dict.conv0.conv.bias torch.Size([64]) cuda:0 True\n",
            "classifier.layer_dict.conv0.norm_layer.bias torch.Size([5, 64]) cuda:0 True\n",
            "classifier.layer_dict.conv0.norm_layer.weight torch.Size([5, 64]) cuda:0 True\n",
            "classifier.layer_dict.conv1.conv.weight torch.Size([64, 64, 3, 3]) cuda:0 True\n",
            "classifier.layer_dict.conv1.conv.bias torch.Size([64]) cuda:0 True\n",
            "classifier.layer_dict.conv1.norm_layer.bias torch.Size([5, 64]) cuda:0 True\n",
            "classifier.layer_dict.conv1.norm_layer.weight torch.Size([5, 64]) cuda:0 True\n",
            "classifier.layer_dict.conv2.conv.weight torch.Size([64, 64, 3, 3]) cuda:0 True\n",
            "classifier.layer_dict.conv2.conv.bias torch.Size([64]) cuda:0 True\n",
            "classifier.layer_dict.conv2.norm_layer.bias torch.Size([5, 64]) cuda:0 True\n",
            "classifier.layer_dict.conv2.norm_layer.weight torch.Size([5, 64]) cuda:0 True\n",
            "classifier.layer_dict.conv3.conv.weight torch.Size([64, 64, 3, 3]) cuda:0 True\n",
            "classifier.layer_dict.conv3.conv.bias torch.Size([64]) cuda:0 True\n",
            "classifier.layer_dict.conv3.norm_layer.bias torch.Size([5, 64]) cuda:0 True\n",
            "classifier.layer_dict.conv3.norm_layer.weight torch.Size([5, 64]) cuda:0 True\n",
            "classifier.layer_dict.linear.weights torch.Size([5, 64]) cuda:0 True\n",
            "classifier.layer_dict.linear.bias torch.Size([5]) cuda:0 True\n",
            "inner_loop_optimizer.names_learning_rates_dict.layer_dict-conv0-conv-weight torch.Size([6]) cuda:0 True\n",
            "inner_loop_optimizer.names_learning_rates_dict.layer_dict-conv0-conv-bias torch.Size([6]) cuda:0 True\n",
            "inner_loop_optimizer.names_learning_rates_dict.layer_dict-conv1-conv-weight torch.Size([6]) cuda:0 True\n",
            "inner_loop_optimizer.names_learning_rates_dict.layer_dict-conv1-conv-bias torch.Size([6]) cuda:0 True\n",
            "inner_loop_optimizer.names_learning_rates_dict.layer_dict-conv2-conv-weight torch.Size([6]) cuda:0 True\n",
            "inner_loop_optimizer.names_learning_rates_dict.layer_dict-conv2-conv-bias torch.Size([6]) cuda:0 True\n",
            "inner_loop_optimizer.names_learning_rates_dict.layer_dict-conv3-conv-weight torch.Size([6]) cuda:0 True\n",
            "inner_loop_optimizer.names_learning_rates_dict.layer_dict-conv3-conv-bias torch.Size([6]) cuda:0 True\n",
            "inner_loop_optimizer.names_learning_rates_dict.layer_dict-linear-weights torch.Size([6]) cuda:0 True\n",
            "inner_loop_optimizer.names_learning_rates_dict.layer_dict-linear-bias torch.Size([6]) cuda:0 True\n",
            "the grinch added tensor([[[[ 3.6613e-02, -1.3564e-02,  6.0923e-02],\n",
            "          [-1.5399e-01, -1.2500e-01,  1.6804e-02],\n",
            "          [ 1.6092e-01, -5.2949e-02,  9.8219e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.4195e-02,  8.0810e-02, -1.3344e-01],\n",
            "          [-5.6334e-02, -3.1194e-02,  8.9222e-02],\n",
            "          [ 1.7641e-02,  5.6131e-02, -3.2981e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.4586e-01, -1.1758e-01, -2.4927e-01],\n",
            "          [-5.9980e-02, -6.2057e-02, -1.3694e-01],\n",
            "          [ 1.9233e-01,  1.7691e-02,  4.4033e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7600e-01,  8.7354e-02, -1.0963e-01],\n",
            "          [-3.5854e-03,  1.4937e-01,  1.4427e-01],\n",
            "          [-6.9371e-02,  3.4147e-02, -1.4251e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6535e-01, -2.6468e-02,  1.5328e-02],\n",
            "          [ 1.2706e-01, -4.1075e-02,  8.5480e-02],\n",
            "          [ 1.9021e-01, -8.1587e-02,  7.2995e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1271e-01,  5.7736e-02, -3.9494e-02],\n",
            "          [ 1.4842e-01, -2.8651e-02,  3.9554e-02],\n",
            "          [ 1.3322e-01,  2.5119e-02,  1.9731e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.1832e-01,  5.7183e-03, -1.9212e-02],\n",
            "          [ 1.2790e-01,  2.6381e-01,  1.1459e-01],\n",
            "          [-5.4064e-02,  1.2854e-02, -1.6295e-01]]],\n",
            "\n",
            "\n",
            "        [[[-7.1023e-02,  4.7939e-02, -1.5326e-01],\n",
            "          [ 4.4203e-02, -5.5543e-03,  2.8752e-01],\n",
            "          [ 1.2404e-01, -1.0005e-01, -1.7286e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5179e-02,  2.1320e-01, -8.1590e-02],\n",
            "          [-2.0492e-02,  1.7359e-01,  6.1650e-02],\n",
            "          [-8.8859e-02,  2.5722e-02, -1.0426e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1212e-02,  1.1736e-01,  1.4546e-01],\n",
            "          [-2.7084e-02, -1.3664e-01, -4.5408e-02],\n",
            "          [-5.2491e-02, -7.7820e-02,  3.2247e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.2995e-02, -2.2769e-02, -9.6601e-02],\n",
            "          [ 9.4605e-02, -7.3303e-03,  2.2016e-03],\n",
            "          [ 3.6141e-02,  7.9885e-02,  6.3303e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.5787e-02, -5.3410e-02,  1.1617e-02],\n",
            "          [ 8.8367e-03, -2.3024e-02,  5.1687e-02],\n",
            "          [-1.2823e-01,  1.3673e-01, -1.0574e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 6.2732e-02, -3.1628e-03,  1.0340e-01],\n",
            "          [-2.5044e-02,  3.0414e-03,  5.5050e-03],\n",
            "          [-2.7730e-02, -5.5528e-02,  3.5187e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.1949e-01,  2.6179e-02, -3.3700e-02],\n",
            "          [ 1.0205e-01,  5.6640e-02,  2.3503e-01],\n",
            "          [-6.1160e-02,  9.5413e-02,  1.2373e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.2107e-01,  1.7033e-01, -2.9930e-02],\n",
            "          [ 1.6888e-01,  2.5238e-02, -2.2385e-02],\n",
            "          [ 4.2591e-02,  8.6339e-02,  1.6119e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.6045e-02, -1.5415e-01,  7.2127e-03],\n",
            "          [ 1.1687e-01,  1.1366e-02,  5.4530e-02],\n",
            "          [ 4.9916e-02,  1.1303e-01, -8.1069e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.1243e-02, -2.7012e-01, -7.3845e-02],\n",
            "          [-3.2209e-01, -3.3287e-02, -3.7108e-02],\n",
            "          [-3.7525e-02,  8.1539e-02, -5.9733e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 5.5110e-02,  2.0256e-02,  1.7512e-02],\n",
            "          [ 1.0115e-01,  6.2845e-02,  1.6308e-01],\n",
            "          [-5.2674e-03, -7.5277e-02, -3.9158e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4136e-01,  6.4186e-02, -1.1665e-01],\n",
            "          [ 3.0595e-02, -1.0450e-01, -5.8576e-02],\n",
            "          [ 5.4824e-02, -1.1623e-01,  3.4045e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.2981e-01,  1.4445e-01,  1.7435e-01],\n",
            "          [-8.7336e-02,  1.5707e-01, -8.2706e-02],\n",
            "          [-2.1726e-02, -1.3799e-01,  2.7326e-04]]],\n",
            "\n",
            "\n",
            "        [[[-3.4700e-02,  9.2680e-02,  1.6796e-01],\n",
            "          [ 6.3827e-02, -3.9939e-02, -4.6858e-02],\n",
            "          [-7.0750e-02,  9.6774e-02,  5.3703e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 9.2191e-02,  1.4123e-02,  1.0951e-01],\n",
            "          [ 4.9822e-02,  1.4374e-01,  2.8866e-02],\n",
            "          [ 7.6484e-02, -2.6668e-02, -4.7380e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.3430e-01, -1.2409e-01, -9.0428e-02],\n",
            "          [ 1.5036e-01, -4.3843e-02, -1.2610e-01],\n",
            "          [ 5.8490e-02,  1.3380e-03,  2.3739e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3742e-02,  1.0804e-01, -1.2230e-01],\n",
            "          [ 1.3519e-02,  1.7345e-01,  3.9802e-02],\n",
            "          [-2.2710e-01, -2.2236e-02, -6.6438e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.9089e-02, -2.5652e-02, -6.1433e-02],\n",
            "          [ 5.5485e-02, -1.7807e-02,  1.9649e-01],\n",
            "          [ 5.7338e-02, -1.5038e-02,  4.4148e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8924e-01,  9.0648e-02,  1.8976e-03],\n",
            "          [ 1.4985e-02, -7.8990e-02, -5.1714e-02],\n",
            "          [-8.4451e-02,  1.3014e-01, -8.7942e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.6519e-02,  1.7445e-01, -3.5903e-02],\n",
            "          [ 1.3550e-01, -2.5391e-02,  5.0799e-02],\n",
            "          [-4.7196e-02,  7.1391e-02,  1.0581e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4420e-02,  6.9151e-02,  3.0252e-01],\n",
            "          [ 5.5398e-02, -1.4082e-02, -4.7829e-02],\n",
            "          [ 2.3716e-02,  2.4098e-01,  1.2321e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.5003e-02,  5.6408e-02, -2.0709e-01],\n",
            "          [ 1.9640e-01,  9.4596e-02, -5.1295e-02],\n",
            "          [-1.4477e-02,  1.4134e-01, -2.1266e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.3529e-03,  1.5086e-02, -2.2838e-02],\n",
            "          [ 1.0028e-01, -1.3439e-01, -4.2723e-02],\n",
            "          [ 4.1214e-02, -5.3564e-02,  1.1009e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4925e-01, -8.1006e-02, -7.0538e-02],\n",
            "          [-7.3890e-02, -7.9324e-02,  1.1637e-01],\n",
            "          [-1.3826e-02, -8.9133e-03, -1.6975e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.5759e-01,  1.7602e-01, -8.2699e-02],\n",
            "          [-6.3623e-02,  1.0873e-01,  5.2519e-02],\n",
            "          [-1.9506e-02,  5.4716e-02,  8.2796e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4120e-02, -2.1383e-02, -1.4293e-01],\n",
            "          [-4.3504e-02, -9.3792e-03,  6.9162e-03],\n",
            "          [-2.1352e-02, -6.9061e-02,  1.7956e-01]]],\n",
            "\n",
            "\n",
            "        [[[-5.8873e-02, -9.2074e-02,  2.0152e-01],\n",
            "          [-2.0837e-01, -1.8994e-02, -2.4735e-01],\n",
            "          [-5.4990e-02, -1.2853e-01,  1.8984e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 8.8037e-02, -1.1509e-01,  2.8865e-01],\n",
            "          [-1.1462e-01, -5.9653e-02, -8.9700e-02],\n",
            "          [-1.1926e-02, -7.2435e-02, -1.7531e-02]]],\n",
            "\n",
            "\n",
            "        [[[-5.6932e-02,  2.5704e-02, -1.0707e-01],\n",
            "          [-1.7409e-01,  2.8439e-03, -3.7063e-02],\n",
            "          [-8.6065e-02,  1.1817e-02,  2.3390e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9284e-01, -9.8121e-02, -3.9436e-02],\n",
            "          [-4.9021e-02, -1.0933e-01,  6.9417e-02],\n",
            "          [-1.4149e-01, -6.4160e-02, -1.9730e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.0391e-02, -4.6133e-02,  7.4471e-02],\n",
            "          [-4.2391e-02, -1.7183e-01, -6.4390e-02],\n",
            "          [-5.7122e-02,  1.2502e-01,  8.5091e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.2802e-02, -1.1910e-01,  4.8112e-02],\n",
            "          [-2.9376e-03, -4.9039e-02, -6.3347e-02],\n",
            "          [-4.0848e-02,  4.7793e-02, -7.4990e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.6878e-01, -1.1662e-01, -1.7424e-01],\n",
            "          [ 6.4284e-02, -1.0498e-01,  1.3592e-01],\n",
            "          [ 1.2330e-01, -2.5569e-02, -8.9189e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 8.6538e-02, -1.2296e-01,  4.0869e-02],\n",
            "          [ 1.3000e-02, -8.2859e-02, -1.4074e-01],\n",
            "          [-9.9739e-02, -1.1523e-02, -8.3628e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.7100e-02, -1.1176e-01,  1.3123e-02],\n",
            "          [ 7.5381e-02,  2.6033e-02,  1.1322e-01],\n",
            "          [ 8.0056e-02,  8.5361e-02,  1.1630e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9709e-02, -5.8017e-03,  1.4027e-01],\n",
            "          [-6.5377e-02, -1.7139e-01,  8.2416e-02],\n",
            "          [-2.6548e-02, -2.1047e-01, -2.6282e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1035e-01, -4.8260e-04, -4.6277e-02],\n",
            "          [ 1.4407e-01, -1.8855e-01, -9.6527e-02],\n",
            "          [-4.1263e-02,  1.2100e-01,  2.5087e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0787e-02, -3.8617e-02, -2.8761e-03],\n",
            "          [-1.6833e-01, -3.3241e-02,  5.0740e-02],\n",
            "          [-4.4293e-03, -3.8393e-02, -5.5417e-02]]],\n",
            "\n",
            "\n",
            "        [[[-9.1846e-03,  3.4538e-02,  8.1111e-02],\n",
            "          [ 8.9106e-02,  5.4754e-02, -2.0988e-01],\n",
            "          [-9.1796e-02,  9.0491e-02,  8.1908e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.1496e-02,  1.1037e-01,  1.8134e-01],\n",
            "          [ 1.1731e-02, -1.0938e-01,  1.4127e-01],\n",
            "          [-4.9461e-02,  1.3053e-01, -1.1124e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.4202e-01,  2.1285e-02,  2.8794e-02],\n",
            "          [ 2.9206e-02,  1.2061e-01, -1.6685e-02],\n",
            "          [-2.4199e-01, -1.1349e-02,  2.3988e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1771e-01, -8.3229e-02, -1.3214e-01],\n",
            "          [-2.6510e-03, -2.1221e-01, -9.7036e-02],\n",
            "          [-2.4797e-02,  9.5378e-02,  1.5009e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.3665e-01, -2.2876e-01, -1.6234e-02],\n",
            "          [ 1.2869e-01, -2.0264e-01, -5.0017e-02],\n",
            "          [-3.7108e-03,  1.7306e-02,  1.0003e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8323e-01,  6.5736e-02, -2.6375e-02],\n",
            "          [-5.8991e-02,  1.0246e-01, -9.6323e-02],\n",
            "          [-9.2865e-02, -1.2344e-01, -1.2774e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3105e-01,  1.1833e-01,  6.4975e-02],\n",
            "          [ 5.1848e-02, -6.2853e-02, -9.9458e-02],\n",
            "          [-6.2559e-02,  5.6851e-02, -6.2553e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.8315e-02,  5.9719e-02,  3.1572e-02],\n",
            "          [-1.5213e-01,  9.3762e-02, -8.3298e-02],\n",
            "          [ 1.1410e-01,  5.2366e-02,  2.3108e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1786e-02, -2.1536e-02, -9.0887e-03],\n",
            "          [ 4.1792e-02, -4.9347e-03, -7.2147e-02],\n",
            "          [-8.5074e-02, -3.0495e-02, -2.2748e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4001e-01, -1.5526e-02, -1.4991e-01],\n",
            "          [-1.2049e-01, -5.2235e-02, -7.5521e-03],\n",
            "          [-8.7283e-02, -1.6892e-01,  1.1699e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.5862e-02, -1.9578e-01,  8.4118e-02],\n",
            "          [-8.0783e-02, -4.4006e-02, -5.9521e-02],\n",
            "          [-1.0322e-01,  1.5583e-02,  2.2355e-01]]],\n",
            "\n",
            "\n",
            "        [[[-8.4692e-02, -7.5535e-02, -1.6198e-02],\n",
            "          [ 1.4337e-02, -6.5023e-02, -3.9280e-02],\n",
            "          [ 1.0736e-01, -7.6757e-03, -2.3273e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.1001e-02, -3.0772e-02,  1.2197e-02],\n",
            "          [ 3.0248e-02, -1.0877e-01, -2.2554e-02],\n",
            "          [ 7.2522e-02,  3.4657e-02, -1.2077e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 6.6929e-02, -7.6666e-02,  2.0686e-02],\n",
            "          [ 7.1964e-02,  1.1210e-01,  8.0040e-03],\n",
            "          [ 6.0670e-02,  2.3997e-01,  9.2542e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.2070e-02,  1.2853e-01, -1.7153e-01],\n",
            "          [-3.2592e-02, -1.2860e-02, -8.0543e-02],\n",
            "          [ 4.3678e-02, -4.1013e-02,  1.1671e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 7.1370e-02,  9.3073e-03, -5.4271e-02],\n",
            "          [ 2.9160e-02, -6.5728e-02,  2.1610e-02],\n",
            "          [-1.1214e-01,  5.3849e-02,  8.9917e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3933e-01,  4.9287e-02, -2.7123e-01],\n",
            "          [-1.7753e-01,  7.8940e-03, -8.0561e-02],\n",
            "          [ 2.0000e-01, -5.7215e-03, -5.6407e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2082e-01,  1.3247e-01, -3.8369e-02],\n",
            "          [-2.0008e-01,  4.8900e-02, -6.4718e-02],\n",
            "          [-6.8011e-02,  1.3387e-02, -9.8281e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0902e-02, -1.9627e-02, -9.0776e-02],\n",
            "          [ 1.0026e-01,  6.1887e-02,  9.2364e-02],\n",
            "          [ 9.0067e-02, -1.3658e-02,  9.0099e-02]]]], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([-0.0329, -0.1129, -0.0698,  0.0165, -0.0255, -0.0011,  0.0008,  0.1762,\n",
            "        -0.1926, -0.1850,  0.0173, -0.0748, -0.0418,  0.0461, -0.0176,  0.0081,\n",
            "         0.0341, -0.1659,  0.1051, -0.1049, -0.0008,  0.0026, -0.0767, -0.1087,\n",
            "         0.1760, -0.1560,  0.0080,  0.2486,  0.0475, -0.2210,  0.0139,  0.0203,\n",
            "         0.0108, -0.0943, -0.0394,  0.1519,  0.0041, -0.1591, -0.0849,  0.0076,\n",
            "         0.0263,  0.1186, -0.0979, -0.0605,  0.0592, -0.0535,  0.0010, -0.1637,\n",
            "        -0.1438,  0.0222,  0.0592,  0.0176, -0.1200, -0.0564,  0.0675, -0.0172,\n",
            "         0.0950, -0.0419, -0.2211,  0.1231,  0.0255, -0.0433,  0.0746,  0.0642],\n",
            "       device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([[ 3.7180e-02,  6.2472e-02,  7.9275e-02,  2.2362e-01,  1.3501e-01,\n",
            "         -4.2056e-02,  7.6042e-02,  5.8889e-02,  1.8096e-01, -6.3512e-02,\n",
            "          1.3052e-01, -1.2000e-02, -1.2475e-02, -4.9394e-02,  2.0063e-02,\n",
            "          1.8136e-02,  4.3669e-02, -9.4203e-02,  6.0531e-02, -7.6137e-02,\n",
            "          2.4204e-02,  7.9669e-02,  2.0765e-03, -1.2347e-01, -8.1067e-02,\n",
            "         -2.7022e-02, -1.2428e-03, -1.5044e-01, -4.0208e-02, -1.2774e-01,\n",
            "          4.8504e-02,  2.0418e-02,  2.2444e-02,  1.6849e-01, -6.8270e-02,\n",
            "          6.8006e-02,  3.9416e-03, -8.9345e-02,  4.3386e-02,  9.4794e-02,\n",
            "          1.4644e-01, -1.0986e-01, -4.8059e-03, -1.4768e-01,  4.7953e-02,\n",
            "         -8.2935e-02, -6.7297e-02,  8.9825e-02, -7.0267e-02,  1.3876e-01,\n",
            "         -1.2532e-01, -1.0717e-01,  4.8036e-02, -1.9017e-01, -8.2584e-02,\n",
            "         -6.3544e-02,  7.2996e-02, -9.2871e-02, -1.4883e-01,  1.4367e-01,\n",
            "          1.6129e-01,  8.7999e-02,  1.2850e-02, -3.8407e-02],\n",
            "        [ 1.6356e-01, -3.7712e-02, -6.5327e-02,  8.8089e-02, -3.1550e-02,\n",
            "         -1.2123e-01, -5.0105e-02, -1.3002e-02, -3.4253e-02, -8.2850e-02,\n",
            "         -9.8646e-02, -3.8362e-02,  9.8417e-02, -4.3977e-02,  2.0346e-02,\n",
            "         -1.7787e-01, -5.0068e-02, -1.1617e-01,  6.0188e-02,  7.2818e-03,\n",
            "         -8.7272e-02, -1.5902e-01,  2.6152e-02, -3.0838e-02,  1.3111e-01,\n",
            "          4.1489e-03, -2.5636e-01, -2.2688e-01,  2.4187e-02,  1.2483e-01,\n",
            "          4.9336e-03, -1.1846e-01,  8.9995e-02,  9.1830e-02, -4.6226e-03,\n",
            "          5.4647e-02, -4.3764e-02, -1.7092e-01,  1.5603e-01,  8.7969e-02,\n",
            "          2.4171e-02,  7.3101e-02, -3.8795e-02,  1.6081e-01,  2.4910e-01,\n",
            "          7.1790e-02,  3.3119e-02,  7.7333e-02, -1.0430e-01,  1.9044e-02,\n",
            "          1.2697e-01,  2.4317e-01, -9.1379e-02, -3.6836e-03,  3.9565e-02,\n",
            "          1.5913e-01,  3.4774e-02, -2.1475e-02, -1.8883e-02,  1.7346e-02,\n",
            "          1.6455e-01, -1.3387e-01, -1.1892e-01,  1.0757e-01],\n",
            "        [-8.7354e-02,  1.1371e-02, -1.2408e-01, -1.4019e-01, -6.2066e-02,\n",
            "         -6.7967e-02,  9.6435e-02,  1.5019e-01, -8.5705e-02, -9.4630e-02,\n",
            "          1.0286e-01, -4.8589e-02, -2.0318e-02,  1.3786e-01,  9.6059e-02,\n",
            "         -8.6803e-02, -1.5655e-02, -7.0537e-02, -9.1429e-03,  6.6965e-02,\n",
            "         -1.1969e-01,  6.1911e-02,  7.1336e-02, -1.1044e-01,  3.9743e-02,\n",
            "         -3.4038e-02,  1.1344e-01,  8.0599e-02, -8.0878e-02, -5.4776e-02,\n",
            "         -7.9786e-02, -1.5321e-02,  1.2332e-01,  4.6264e-02,  9.5713e-02,\n",
            "          1.2089e-01, -3.1538e-02, -5.5854e-02,  3.6655e-02, -1.3421e-01,\n",
            "          1.8249e-03,  3.6031e-03, -1.8267e-02,  7.9242e-02, -1.3886e-02,\n",
            "          6.0055e-03, -4.1960e-02, -7.2346e-02,  6.3188e-02,  1.2111e-01,\n",
            "         -9.5764e-02, -5.2670e-02, -4.4112e-02, -5.6687e-02,  5.9178e-02,\n",
            "          3.7174e-02,  2.2149e-01,  1.5181e-01, -6.2694e-02,  2.3092e-02,\n",
            "          1.2453e-01, -9.3370e-02, -6.9155e-02, -1.7339e-02],\n",
            "        [-1.2525e-02, -1.7579e-02,  1.1126e-01,  2.2295e-02,  2.6561e-02,\n",
            "          3.7306e-02,  2.0370e-02, -7.8709e-02, -3.7493e-02,  1.0517e-01,\n",
            "          1.6909e-01,  5.1784e-02,  4.2377e-03, -8.1281e-02,  1.3313e-01,\n",
            "          2.3179e-02, -7.9419e-02,  9.3225e-02, -1.2626e-01,  2.5429e-01,\n",
            "         -7.2574e-03, -1.6142e-01, -1.9377e-01,  3.6210e-02,  1.0618e-01,\n",
            "         -1.3523e-01,  4.4247e-02, -9.0626e-02,  5.0371e-02, -3.9013e-02,\n",
            "          5.5932e-02,  5.7709e-02,  1.2547e-01,  5.6481e-02, -1.7325e-01,\n",
            "          3.7506e-04, -4.2417e-02, -5.6947e-02, -5.2692e-02, -6.1723e-02,\n",
            "         -7.4881e-02, -2.4069e-02, -5.2344e-02, -2.1867e-02, -7.6435e-02,\n",
            "          7.0718e-03,  1.4068e-01,  1.7055e-04, -1.4688e-01, -8.7549e-02,\n",
            "         -4.6476e-02,  7.0813e-02,  5.0569e-02, -7.8929e-02, -8.5884e-02,\n",
            "          7.1082e-02,  2.2872e-01,  7.1396e-02,  4.5043e-02,  6.2185e-02,\n",
            "          1.1858e-02,  1.6022e-02,  4.7799e-03, -5.3696e-02],\n",
            "        [-6.3162e-02,  5.0439e-02,  4.7648e-02,  7.3941e-02,  1.6911e-01,\n",
            "          1.7798e-01, -1.0955e-01, -3.3679e-02, -2.1076e-02, -6.8633e-02,\n",
            "         -6.9969e-02,  1.5132e-02, -7.8739e-02,  1.6726e-01,  8.6442e-02,\n",
            "         -7.6011e-02,  1.1046e-01, -5.2727e-03,  7.5265e-02,  1.8942e-02,\n",
            "          2.7447e-02, -9.1540e-02, -1.4359e-02, -5.2746e-02, -2.8455e-01,\n",
            "         -1.1168e-01, -6.0316e-02, -6.7642e-02,  7.3929e-02, -2.3155e-02,\n",
            "          9.9041e-02, -4.2640e-03, -3.5012e-02,  3.2132e-02, -2.4777e-02,\n",
            "          1.9781e-01,  3.0032e-02, -1.2392e-01, -1.0271e-01, -1.6663e-01,\n",
            "         -1.4747e-01, -6.8946e-02, -4.3310e-02, -6.1812e-02, -1.6499e-01,\n",
            "          8.4112e-04,  7.8297e-03, -2.7367e-01, -1.2315e-01,  2.1212e-01,\n",
            "          1.2569e-01,  5.6122e-02,  1.0700e-01,  1.8586e-02, -1.0668e-01,\n",
            "         -1.1024e-01,  5.7702e-02, -3.6113e-02, -3.9137e-02, -1.2339e-01,\n",
            "         -1.7409e-01,  6.0027e-03, -9.1744e-02, -9.6532e-04]], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([[-8.7494e-02, -2.0637e-02, -4.4899e-03, -4.8741e-02,  1.6676e-01,\n",
            "         -8.4286e-02, -2.2599e-03,  1.5552e-01,  8.0627e-02,  2.0512e-02,\n",
            "          2.3096e-02, -1.2449e-01,  8.9230e-02, -8.0234e-02,  1.8384e-01,\n",
            "         -1.5322e-02, -1.9527e-01,  1.0610e-01, -5.2042e-02, -3.7085e-02,\n",
            "         -7.0506e-03,  1.9769e-03,  1.3130e-01, -1.9989e-01,  8.8067e-02,\n",
            "         -8.2662e-02, -2.0283e-01, -3.1105e-02,  2.2347e-01,  2.4947e-02,\n",
            "          1.5081e-02, -8.8467e-02, -1.6488e-01, -9.5514e-02,  4.8927e-02,\n",
            "          1.4175e-02,  1.7904e-01,  6.6340e-02,  1.7543e-01,  2.6605e-01,\n",
            "          1.2046e-01,  9.5850e-02, -8.7452e-02, -8.1311e-02, -7.9778e-02,\n",
            "          1.5461e-01, -7.6793e-02,  1.9515e-03,  4.7396e-02, -8.8603e-02,\n",
            "         -3.3250e-02,  1.9239e-04,  3.1990e-02, -2.1646e-02, -3.3637e-02,\n",
            "         -1.9025e-01,  1.9692e-02,  6.1355e-02, -8.3333e-02, -7.2804e-02,\n",
            "          7.3740e-03,  3.0397e-03,  1.3464e-01, -1.8901e-01],\n",
            "        [-1.3546e-01,  1.7179e-01,  1.2771e-01, -5.6367e-02, -1.7893e-01,\n",
            "          7.0364e-02,  6.2526e-02,  7.8897e-02,  2.7154e-02, -7.9279e-02,\n",
            "         -1.1234e-01,  2.1846e-01,  4.9088e-02, -1.9869e-01, -1.0779e-02,\n",
            "         -2.7903e-02,  1.0076e-01, -1.0002e-01,  1.8162e-01,  2.4187e-02,\n",
            "         -3.7152e-03,  6.1989e-02,  1.3901e-01,  4.8507e-04,  9.8674e-02,\n",
            "         -4.4368e-02, -4.0059e-02, -5.0676e-02, -3.5736e-02,  3.3393e-02,\n",
            "          9.2080e-03, -1.0839e-03, -2.8780e-02, -1.0923e-01, -1.2057e-01,\n",
            "         -1.4996e-01, -7.9963e-02,  3.7442e-02, -8.5170e-02, -1.0523e-01,\n",
            "         -1.3555e-01,  1.3402e-01, -9.7721e-04,  2.2256e-02, -1.8845e-02,\n",
            "         -2.5045e-02,  2.1161e-02,  1.4021e-01, -8.1560e-02, -8.4254e-02,\n",
            "          8.8461e-03, -3.7614e-02, -8.4182e-02, -6.1632e-02, -1.9448e-01,\n",
            "         -4.6537e-02, -2.4877e-02, -3.5444e-02, -6.4592e-02, -1.7037e-02,\n",
            "         -5.8762e-02, -4.9061e-02,  6.1189e-02, -1.3159e-02],\n",
            "        [ 1.7265e-01,  6.5419e-02,  8.1347e-02,  2.4320e-01,  4.8994e-02,\n",
            "          3.7469e-03, -6.4463e-02,  6.4616e-02, -6.7563e-03, -1.2413e-01,\n",
            "         -6.8978e-02, -3.3764e-02, -1.7137e-02, -8.2019e-02,  4.4240e-03,\n",
            "         -5.5150e-02, -1.6263e-02,  1.2450e-01,  6.3608e-02,  8.4387e-03,\n",
            "          4.6497e-03,  4.1836e-02,  3.9319e-02,  4.2876e-02,  5.3406e-02,\n",
            "          1.8542e-01,  7.7980e-02, -7.6645e-02, -3.8197e-02,  6.3520e-03,\n",
            "          2.2031e-02, -9.7075e-02,  1.5850e-01, -1.3038e-02, -1.1305e-03,\n",
            "          8.5594e-02,  6.8732e-02, -8.2545e-02, -9.3282e-02,  6.3332e-02,\n",
            "         -7.4911e-02,  1.0573e-01,  9.8219e-02,  2.7497e-02, -6.6704e-02,\n",
            "         -4.8227e-04, -6.1173e-02, -1.4382e-01, -1.9742e-03,  1.0600e-01,\n",
            "         -1.1194e-01, -1.1457e-01, -1.9570e-01,  1.1940e-02, -4.1474e-02,\n",
            "         -8.1186e-02,  4.7412e-02,  8.4195e-02,  1.6238e-01,  1.0852e-01,\n",
            "         -2.2425e-01, -4.6980e-02,  4.6475e-02, -1.3551e-01],\n",
            "        [ 4.3573e-02, -7.8043e-02, -5.6239e-02, -2.1019e-01,  1.3714e-01,\n",
            "          1.1261e-01,  7.8170e-03, -8.8846e-02, -1.6708e-01, -2.1583e-02,\n",
            "          1.6745e-01,  6.6755e-04,  1.3611e-01, -1.2790e-01, -1.8655e-01,\n",
            "          3.5698e-02, -7.4861e-02, -1.7534e-02, -2.4207e-03,  2.2243e-01,\n",
            "          5.3036e-02, -1.0047e-01,  9.1334e-02,  1.1790e-01,  5.2742e-02,\n",
            "         -1.2201e-01,  6.1377e-02,  8.7714e-02,  2.0077e-02, -4.2411e-03,\n",
            "         -6.5421e-02,  1.8531e-02,  8.4937e-02, -1.1914e-01, -8.7909e-02,\n",
            "          7.7397e-02,  4.9868e-02, -9.5203e-02, -6.0212e-02, -4.3796e-02,\n",
            "         -9.7685e-03,  8.4496e-02, -2.8881e-02,  9.8502e-02, -1.5556e-01,\n",
            "         -1.6190e-02, -8.7906e-02, -6.4810e-02,  4.1955e-02, -2.1432e-01,\n",
            "          2.4894e-02, -1.4733e-01,  1.2992e-03, -1.8214e-01, -1.2240e-02,\n",
            "          9.4616e-02,  7.5425e-02,  4.5402e-02,  3.2487e-02,  1.0931e-01,\n",
            "         -1.5305e-02,  1.5305e-01,  1.9054e-03, -1.3891e-01],\n",
            "        [-4.9443e-02,  2.9309e-01, -2.2542e-02, -1.2623e-01, -9.2119e-02,\n",
            "         -1.6724e-01, -8.6962e-02,  1.1346e-02,  1.9109e-01, -1.6625e-01,\n",
            "         -8.5022e-02,  4.7556e-03, -1.2265e-01, -7.4601e-02, -1.5396e-01,\n",
            "         -7.5827e-02,  4.7320e-04, -1.4266e-01,  6.8136e-02, -1.0872e-01,\n",
            "         -1.3494e-01,  2.0135e-02, -5.6003e-02,  3.6143e-02, -5.4914e-02,\n",
            "         -4.8410e-02,  1.5856e-01, -1.9499e-03,  1.3100e-02, -1.3295e-01,\n",
            "          1.4357e-01, -1.1470e-01,  8.5950e-02, -3.1119e-02,  5.9160e-02,\n",
            "          6.1119e-02,  5.7418e-03,  7.4776e-02, -4.7495e-02, -1.3243e-01,\n",
            "         -3.6678e-02, -1.0546e-01, -7.9479e-02,  3.0919e-02, -8.2517e-03,\n",
            "          1.0269e-01, -9.2155e-02, -9.0149e-02,  6.4739e-02, -9.0593e-02,\n",
            "         -7.8693e-02,  3.5958e-02, -8.9822e-03, -5.0510e-02,  4.9980e-03,\n",
            "         -1.4235e-01,  1.8199e-01,  1.0957e-02, -1.7305e-02,  2.2472e-01,\n",
            "         -7.8897e-02, -5.6365e-02, -2.5678e-02,  1.4167e-01]], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([[[[-1.0059e-01,  8.7010e-02, -1.2423e-01],\n",
            "          [ 1.8662e-01, -9.1798e-02, -1.6137e-01],\n",
            "          [ 5.5440e-02,  3.6042e-02, -4.0254e-02]],\n",
            "\n",
            "         [[ 1.5059e-01, -1.4529e-01,  8.6454e-02],\n",
            "          [-7.7549e-02,  1.6340e-01,  1.5315e-01],\n",
            "          [-1.4696e-01, -1.1221e-01, -7.6392e-02]],\n",
            "\n",
            "         [[ 2.8374e-02,  2.2632e-01,  1.4016e-01],\n",
            "          [-2.2195e-02, -2.3882e-02, -4.9647e-02],\n",
            "          [-9.9920e-02, -7.1984e-03, -4.7322e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.3041e-02,  7.5735e-02,  7.9336e-03],\n",
            "          [-2.1516e-01,  2.0890e-01,  5.9399e-02],\n",
            "          [ 2.6055e-01,  2.6272e-02,  5.5031e-02]],\n",
            "\n",
            "         [[-4.6203e-02, -7.3284e-03,  7.5504e-02],\n",
            "          [ 4.2724e-03,  4.2967e-03, -2.1030e-01],\n",
            "          [-1.0553e-01, -3.2784e-02, -6.4046e-02]],\n",
            "\n",
            "         [[-1.9497e-01,  5.7459e-02,  1.0110e-03],\n",
            "          [-2.1762e-01, -6.3764e-02, -8.7480e-02],\n",
            "          [-1.0702e-01, -4.0481e-03, -4.6368e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3431e-01, -1.2497e-01,  9.7891e-02],\n",
            "          [ 1.4194e-02, -1.0065e-01, -2.3288e-04],\n",
            "          [-1.4615e-01, -1.2817e-01, -2.6221e-02]],\n",
            "\n",
            "         [[-2.7714e-03,  1.4270e-01, -9.1893e-02],\n",
            "          [ 5.2533e-02,  3.9559e-02,  6.1359e-02],\n",
            "          [-5.9803e-03,  3.8195e-02, -2.1242e-02]],\n",
            "\n",
            "         [[ 2.0836e-02,  1.2322e-02, -9.5813e-02],\n",
            "          [-6.1444e-02,  1.6881e-01, -2.5226e-02],\n",
            "          [ 2.9662e-03,  9.6070e-02, -7.9149e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5942e-01,  5.7040e-02,  6.1195e-02],\n",
            "          [ 6.2294e-02,  1.0694e-01,  1.0030e-01],\n",
            "          [ 6.6961e-02,  1.0596e-01, -1.7257e-01]],\n",
            "\n",
            "         [[-4.7969e-02, -1.3849e-02,  5.3796e-02],\n",
            "          [-5.7201e-02, -8.3361e-02,  1.2899e-02],\n",
            "          [-6.5684e-02,  6.2934e-02, -4.5370e-02]],\n",
            "\n",
            "         [[ 5.8592e-02,  7.4964e-02, -6.5394e-02],\n",
            "          [ 9.7341e-03, -3.0967e-02,  5.5261e-02],\n",
            "          [-1.4389e-02,  1.1983e-01, -1.4316e-01]]],\n",
            "\n",
            "\n",
            "        [[[-7.0295e-02, -3.7285e-02,  3.2048e-02],\n",
            "          [-7.9761e-02, -1.0249e-01,  1.4549e-02],\n",
            "          [-1.8360e-01,  1.3306e-01, -3.5380e-03]],\n",
            "\n",
            "         [[-1.3490e-01, -1.9787e-01,  2.9473e-02],\n",
            "          [ 1.1065e-01, -6.0241e-03, -3.6693e-02],\n",
            "          [ 1.3421e-01, -2.2442e-02, -9.0404e-02]],\n",
            "\n",
            "         [[-1.0042e-02, -1.2212e-01, -8.2505e-02],\n",
            "          [ 7.1112e-02,  7.7172e-02, -7.7867e-02],\n",
            "          [ 1.6256e-01, -1.2818e-01,  2.3141e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.9341e-03,  1.1994e-02,  1.3206e-01],\n",
            "          [-5.4282e-02, -2.0786e-01,  1.8907e-01],\n",
            "          [-9.1974e-02,  2.8056e-02, -2.6841e-02]],\n",
            "\n",
            "         [[-1.6304e-01,  3.1568e-03, -2.2652e-03],\n",
            "          [ 4.1875e-03,  2.6563e-02, -1.3520e-01],\n",
            "          [-4.2786e-02, -1.0616e-01,  6.9648e-02]],\n",
            "\n",
            "         [[-9.4843e-02, -1.5011e-02, -5.9965e-02],\n",
            "          [-1.3353e-02, -6.6252e-03, -4.1476e-02],\n",
            "          [ 2.1580e-01, -8.8936e-02,  6.5430e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-8.1694e-02,  1.1509e-02,  5.5114e-02],\n",
            "          [-3.1445e-02, -1.0982e-01, -4.3274e-02],\n",
            "          [-7.2594e-02,  2.1751e-02, -7.3138e-02]],\n",
            "\n",
            "         [[-8.3141e-02,  1.0625e-01, -2.5913e-01],\n",
            "          [ 1.6758e-02,  8.0595e-02, -5.0297e-02],\n",
            "          [-2.3470e-01, -3.1096e-02,  7.8664e-02]],\n",
            "\n",
            "         [[-2.9120e-01,  5.1571e-02, -7.6065e-02],\n",
            "          [ 1.8813e-02, -1.8050e-02, -3.1812e-02],\n",
            "          [ 1.6669e-01, -1.2945e-01,  9.7576e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.5367e-01, -1.9622e-01, -1.1126e-01],\n",
            "          [-1.6081e-01, -5.5354e-02,  2.3323e-01],\n",
            "          [ 5.4926e-02,  8.9498e-02,  3.0763e-02]],\n",
            "\n",
            "         [[-1.1694e-01,  1.9718e-01,  1.3124e-01],\n",
            "          [ 1.1862e-01,  9.5792e-03,  9.8848e-02],\n",
            "          [-8.0156e-02, -4.8527e-02,  1.9440e-01]],\n",
            "\n",
            "         [[-4.2495e-02,  8.3383e-02,  1.2501e-01],\n",
            "          [ 3.8887e-02,  9.6153e-02,  2.6204e-02],\n",
            "          [ 6.3162e-02,  6.5927e-03,  2.1231e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.0602e-01, -1.6746e-01,  7.4207e-02],\n",
            "          [-1.9724e-01,  4.8414e-02,  2.6935e-02],\n",
            "          [ 7.1694e-02,  1.5884e-01, -8.9387e-02]],\n",
            "\n",
            "         [[ 4.5453e-02,  4.1771e-02,  2.1542e-01],\n",
            "          [-2.0789e-01,  1.0176e-01,  1.1915e-01],\n",
            "          [ 7.6377e-02, -1.3054e-02,  6.9071e-03]],\n",
            "\n",
            "         [[-1.4272e-01, -2.5587e-01, -3.6489e-02],\n",
            "          [ 1.6283e-01,  1.1273e-01,  2.4665e-01],\n",
            "          [ 2.6276e-01, -1.6602e-01,  6.9293e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4918e-02,  3.3884e-02, -5.1847e-02],\n",
            "          [-4.2716e-02, -1.0282e-01, -5.0267e-03],\n",
            "          [ 2.3259e-01, -1.2828e-01, -5.7695e-02]],\n",
            "\n",
            "         [[ 8.9106e-02,  1.1447e-01, -9.8288e-02],\n",
            "          [ 2.0774e-01, -2.3596e-02, -2.6069e-01],\n",
            "          [-5.0676e-02,  2.7701e-01,  1.3853e-01]],\n",
            "\n",
            "         [[-9.9007e-02, -1.3591e-01, -9.3319e-02],\n",
            "          [ 1.5788e-01, -6.3632e-02,  6.3655e-02],\n",
            "          [ 9.5862e-03,  1.6826e-01, -3.3462e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4699e-01, -2.3381e-02,  6.7656e-02],\n",
            "          [-3.7288e-02, -1.5025e-01,  2.3391e-01],\n",
            "          [ 1.4124e-01, -1.4360e-01,  9.3291e-02]],\n",
            "\n",
            "         [[ 9.9046e-02,  5.1371e-02,  2.0248e-01],\n",
            "          [ 2.8805e-02,  6.2069e-02, -1.1777e-01],\n",
            "          [ 2.9448e-02, -1.6599e-01, -3.3593e-02]],\n",
            "\n",
            "         [[ 1.3219e-01,  1.8839e-01, -3.6512e-02],\n",
            "          [-1.8276e-01,  6.7946e-02,  2.6399e-02],\n",
            "          [-1.2460e-01, -1.5857e-01,  1.0265e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.5359e-02,  1.1944e-01, -2.2413e-02],\n",
            "          [ 1.2890e-01, -8.9753e-02,  3.9729e-02],\n",
            "          [-1.1157e-01,  3.2748e-02,  2.1886e-02]],\n",
            "\n",
            "         [[-2.9806e-02, -4.1481e-02, -7.7610e-02],\n",
            "          [-3.5926e-02,  2.7952e-02,  7.7041e-03],\n",
            "          [-3.1950e-02,  1.2102e-01,  1.5273e-02]],\n",
            "\n",
            "         [[-2.7404e-02,  3.7798e-02, -2.5047e-02],\n",
            "          [ 8.1239e-02,  1.2700e-01, -5.4946e-02],\n",
            "          [-2.4290e-02,  1.0771e-01,  1.9301e-01]]]], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([-0.1709, -0.1132, -0.1258,  0.0394, -0.0004, -0.0501,  0.0603, -0.0890,\n",
            "         0.0814,  0.0656, -0.0830, -0.0328, -0.1131, -0.0462, -0.0244,  0.1048,\n",
            "         0.0418, -0.0435,  0.0468,  0.0402, -0.0374,  0.0421,  0.1161, -0.0230,\n",
            "        -0.0187,  0.1099,  0.1576,  0.0957,  0.0331,  0.0708,  0.0436, -0.1325,\n",
            "        -0.2541,  0.0776,  0.0646, -0.0565, -0.0325,  0.1837, -0.0953,  0.1936,\n",
            "         0.0791, -0.0628, -0.0592,  0.1693, -0.0212, -0.0536, -0.0520,  0.0441,\n",
            "        -0.0918,  0.0938, -0.1529,  0.1656,  0.1527, -0.1752, -0.0670, -0.0062,\n",
            "        -0.0834,  0.0565, -0.3089, -0.0880,  0.0392,  0.1196, -0.1322,  0.0863],\n",
            "       device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([[ 3.0304e-02,  2.9118e-03,  1.0751e-02,  7.5644e-03, -1.8848e-01,\n",
            "          1.0196e-01, -6.8463e-02,  3.6689e-03, -1.0691e-01,  6.2915e-02,\n",
            "          3.3592e-02,  3.2944e-03, -7.0095e-02,  6.6980e-02,  7.5333e-02,\n",
            "          1.4490e-01,  7.8801e-02,  1.5452e-01,  1.2693e-02,  1.6641e-01,\n",
            "          1.1632e-01,  9.5886e-02,  5.3658e-03, -1.9156e-01, -1.7923e-02,\n",
            "         -2.1751e-01, -9.6325e-03,  9.2521e-03,  4.9209e-03, -1.0099e-01,\n",
            "         -7.1668e-02,  1.1149e-01,  1.8170e-01, -3.3223e-02, -8.0576e-02,\n",
            "         -9.3900e-02, -7.2689e-02, -1.4858e-01, -9.0430e-02,  9.1038e-02,\n",
            "          2.7095e-02,  5.6517e-02,  1.4079e-01, -1.3102e-01,  1.6406e-01,\n",
            "          9.8383e-02, -2.3490e-02,  2.0435e-01,  1.0166e-01, -4.1933e-02,\n",
            "          1.0434e-01, -5.9291e-02, -2.9863e-02, -8.0517e-02,  1.3675e-01,\n",
            "         -6.0932e-02,  8.5338e-02, -7.3927e-02, -7.8971e-03, -2.1636e-02,\n",
            "          3.8541e-02,  2.5544e-02, -6.2273e-02, -1.0913e-01],\n",
            "        [-4.9334e-02, -7.9423e-02, -1.0288e-01, -1.0777e-02,  1.0470e-01,\n",
            "          4.2127e-03,  6.5743e-02, -5.4776e-02,  4.7957e-02,  2.0724e-01,\n",
            "          3.9398e-02,  4.0040e-02, -1.5870e-01,  1.8502e-01, -1.2568e-02,\n",
            "          2.0840e-01, -1.2834e-01,  1.8038e-01,  8.8422e-03, -7.7405e-03,\n",
            "          6.4027e-02, -4.1990e-02, -5.1127e-03, -3.0449e-02,  4.9720e-02,\n",
            "          4.9633e-02,  2.5308e-02, -9.8387e-02,  3.5035e-02,  6.0074e-02,\n",
            "          1.6565e-01,  1.7917e-02, -8.9137e-03, -7.2711e-02, -2.2894e-01,\n",
            "         -5.5245e-02,  2.2160e-01, -1.6838e-01,  4.3594e-02, -2.6534e-01,\n",
            "         -4.1228e-02,  4.1105e-02, -5.0905e-02,  1.6281e-01, -4.1351e-02,\n",
            "         -2.1010e-01, -7.9109e-02,  7.1205e-02,  1.8865e-02,  6.3825e-02,\n",
            "         -1.3224e-01, -7.6874e-02,  8.2245e-02,  5.2595e-02, -1.5097e-01,\n",
            "          6.7883e-02,  7.0615e-02, -7.3829e-02,  1.7626e-02,  1.3823e-01,\n",
            "         -1.0425e-01, -2.9474e-02,  2.0366e-01, -7.2091e-02],\n",
            "        [-3.2825e-02,  1.1886e-01, -6.7654e-02,  4.8415e-02,  1.9917e-02,\n",
            "          2.0153e-02, -2.2627e-02,  2.1064e-02, -9.4899e-02,  5.8763e-02,\n",
            "         -1.4063e-01,  1.0419e-01, -9.4999e-02,  2.0559e-01, -6.3086e-02,\n",
            "         -1.5336e-02, -5.2378e-02,  1.0423e-01, -2.0079e-01,  1.4087e-02,\n",
            "         -3.8244e-02,  1.4390e-01,  5.8587e-02, -1.3478e-01,  9.0397e-02,\n",
            "         -2.8107e-02,  7.1619e-02,  6.2770e-02, -8.0400e-03,  1.2006e-01,\n",
            "          2.4948e-02,  6.2235e-02,  1.1729e-02,  1.6115e-01, -1.3156e-01,\n",
            "          3.8489e-02,  6.6062e-03, -4.7262e-03,  4.4516e-02,  3.0894e-02,\n",
            "          7.9363e-02,  8.9242e-02,  1.5102e-02, -1.7523e-02, -9.3804e-02,\n",
            "         -7.1092e-03,  1.4000e-01, -9.6914e-02,  5.0309e-02, -1.2269e-02,\n",
            "          2.1009e-01, -5.6265e-02, -2.4630e-01,  4.4222e-03, -3.6669e-02,\n",
            "         -1.5491e-02,  5.2435e-02,  3.3603e-02,  7.2721e-02, -9.3002e-03,\n",
            "         -5.4442e-02, -9.9285e-02, -2.9680e-02, -9.2632e-02],\n",
            "        [-7.2641e-03, -6.0896e-02, -7.0025e-02, -2.7330e-02,  1.8357e-01,\n",
            "          1.8684e-02, -6.7809e-04,  9.9163e-02,  2.1819e-02, -8.1835e-02,\n",
            "         -4.1554e-02, -1.3128e-01,  1.3240e-01, -5.3613e-02, -2.7411e-02,\n",
            "         -8.7063e-02, -3.5259e-03, -1.1493e-02, -6.4067e-02,  1.1833e-01,\n",
            "         -1.0457e-02,  5.1661e-02, -1.9633e-01,  6.6882e-02, -1.2606e-01,\n",
            "          6.1715e-02,  2.3821e-01, -5.5469e-02, -5.7141e-02, -6.9782e-02,\n",
            "         -1.3675e-04, -7.1760e-03, -4.7530e-02,  2.8778e-02,  1.6538e-01,\n",
            "          1.7685e-01, -2.0683e-02,  3.4081e-02,  4.7245e-02, -4.8962e-02,\n",
            "          8.8744e-02, -8.7724e-02, -2.6202e-02, -1.7547e-01, -1.5802e-02,\n",
            "          9.0995e-02, -9.0772e-02,  1.8841e-02, -1.6091e-02, -1.3677e-02,\n",
            "         -1.8817e-01, -6.8228e-02,  4.3013e-04,  8.0759e-02,  6.9218e-02,\n",
            "          7.8961e-03, -3.2519e-02,  4.7866e-02, -5.5780e-02, -9.7814e-02,\n",
            "          5.8979e-02, -5.6149e-02,  1.6505e-01, -3.5708e-02],\n",
            "        [-6.2155e-02, -4.4314e-02,  1.4855e-01, -3.5869e-02,  7.8915e-02,\n",
            "         -1.1280e-01,  6.3511e-02,  4.2866e-02,  6.8946e-02,  7.0102e-03,\n",
            "         -1.0567e-01,  4.3966e-02,  6.9271e-02,  1.2849e-01, -1.4944e-02,\n",
            "         -6.6897e-03,  8.2150e-02,  5.2601e-02,  1.6255e-01, -1.3434e-01,\n",
            "         -9.5460e-02, -1.5464e-01, -4.8818e-02, -1.7054e-01, -8.0549e-02,\n",
            "         -5.1115e-02,  1.3000e-02, -3.1886e-02,  1.1666e-01, -1.2617e-01,\n",
            "          9.4444e-02, -8.2004e-02, -5.6807e-02,  6.5037e-02, -8.4760e-02,\n",
            "         -1.6025e-02,  3.6536e-02, -9.1656e-02, -1.3128e-01,  7.1395e-02,\n",
            "          4.4847e-02,  2.9823e-02,  1.1129e-01,  2.1198e-02, -1.3662e-01,\n",
            "          2.1580e-02,  1.6184e-01, -7.4666e-02, -1.7764e-01, -7.9812e-02,\n",
            "         -1.8567e-01,  1.6297e-01, -4.4176e-02,  3.6010e-02, -1.0048e-01,\n",
            "         -3.5530e-02,  4.2371e-02,  1.0375e-01, -7.6285e-02, -7.7045e-02,\n",
            "          1.1521e-01,  2.4729e-02, -8.7472e-02,  1.4792e-01]], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([[ 0.0499,  0.0192,  0.2279,  0.0865,  0.0618, -0.1291,  0.0661,  0.0989,\n",
            "          0.0929,  0.0660,  0.0205, -0.1368,  0.1953,  0.0235,  0.0496,  0.0131,\n",
            "          0.0886,  0.0094,  0.0324, -0.0110,  0.0696,  0.0625,  0.0701, -0.1681,\n",
            "         -0.0317, -0.0403,  0.0340, -0.1299,  0.0518, -0.0470,  0.0616,  0.1248,\n",
            "         -0.0292, -0.1126,  0.0368, -0.1379, -0.1198, -0.1022,  0.0164, -0.0634,\n",
            "          0.0743, -0.0232,  0.0400, -0.1291, -0.0256,  0.0041, -0.0449,  0.0715,\n",
            "         -0.0778, -0.0068,  0.0601,  0.1044,  0.0083,  0.0264,  0.0769, -0.0075,\n",
            "         -0.0255, -0.1392, -0.2298,  0.0139,  0.1621, -0.0737, -0.0171,  0.1555],\n",
            "        [ 0.0477, -0.0510,  0.0290, -0.0125,  0.0728, -0.1146, -0.0693,  0.0058,\n",
            "          0.1505,  0.0633,  0.0934, -0.0668, -0.0263,  0.0170, -0.1128, -0.1472,\n",
            "         -0.1296,  0.0217, -0.0354, -0.1071, -0.0510, -0.0226, -0.0047,  0.1358,\n",
            "          0.0723, -0.0113,  0.0780,  0.1284,  0.1205, -0.1387,  0.0248,  0.0481,\n",
            "          0.0369, -0.0669, -0.1135, -0.0709,  0.0169, -0.1846,  0.0506,  0.2378,\n",
            "         -0.0613, -0.0677, -0.0519,  0.1105, -0.1259, -0.0086, -0.0619, -0.1186,\n",
            "          0.2021, -0.0054, -0.0869,  0.0811,  0.0566,  0.0132,  0.1339,  0.1152,\n",
            "         -0.0715,  0.0855, -0.0030,  0.0522,  0.0372,  0.1000,  0.0735, -0.1576],\n",
            "        [ 0.1450,  0.2866, -0.2321, -0.0158,  0.0571, -0.0182, -0.0730, -0.3024,\n",
            "         -0.0805,  0.0460,  0.0292, -0.1609, -0.0742, -0.0619,  0.0850,  0.0391,\n",
            "         -0.0813, -0.0916, -0.0522,  0.0087,  0.0182, -0.0430,  0.0868, -0.0506,\n",
            "         -0.1307, -0.0951,  0.1123, -0.0560,  0.0034, -0.0551, -0.0072,  0.1550,\n",
            "          0.0511,  0.0530,  0.1050, -0.0527,  0.0892, -0.0900, -0.0012,  0.0636,\n",
            "          0.0866, -0.1256,  0.0941, -0.0126,  0.0597, -0.0329,  0.0466,  0.2216,\n",
            "         -0.0341,  0.1254, -0.0473,  0.0629, -0.0131, -0.0877,  0.0004, -0.0577,\n",
            "          0.1567,  0.2136, -0.0009,  0.0845, -0.0671,  0.0944,  0.0893,  0.1920],\n",
            "        [ 0.0731, -0.0004,  0.0708,  0.0028, -0.0627, -0.0588,  0.2633,  0.0974,\n",
            "         -0.0754, -0.0310, -0.0890,  0.0851, -0.0563,  0.0208, -0.1579, -0.0582,\n",
            "          0.0844,  0.0029,  0.1043, -0.1068, -0.1304, -0.2555, -0.0341, -0.1484,\n",
            "          0.0281,  0.0212, -0.0054, -0.0417,  0.0057,  0.1324,  0.0227, -0.0371,\n",
            "         -0.0535,  0.0926,  0.0224,  0.0878,  0.0275,  0.0722, -0.0458,  0.0827,\n",
            "          0.0068,  0.1608,  0.1362,  0.0786, -0.0329, -0.0098,  0.0248, -0.1674,\n",
            "          0.0535, -0.0103,  0.0996,  0.0094,  0.0314, -0.1912, -0.0322,  0.0361,\n",
            "         -0.1645, -0.0758,  0.0233,  0.1964,  0.0845, -0.0421,  0.0716, -0.0716],\n",
            "        [-0.0704,  0.1133,  0.0393, -0.0527, -0.0057, -0.0118,  0.0314, -0.1487,\n",
            "         -0.0249,  0.1056,  0.1935, -0.0273, -0.1938, -0.0728, -0.0722, -0.1090,\n",
            "          0.0206,  0.0355, -0.0577,  0.0885,  0.0036,  0.1295,  0.1622,  0.1068,\n",
            "         -0.0660,  0.1517,  0.1136, -0.0020, -0.0865,  0.0065,  0.1628,  0.0254,\n",
            "          0.1535, -0.0862, -0.0711, -0.0219,  0.0286,  0.1153,  0.0537, -0.0065,\n",
            "          0.0792, -0.0595, -0.0452,  0.1004,  0.0778, -0.0172,  0.0427, -0.0849,\n",
            "          0.1173, -0.1664, -0.0400,  0.1021, -0.0903, -0.0891,  0.0881,  0.0252,\n",
            "         -0.0722, -0.1586, -0.1269,  0.0111,  0.0293,  0.0428,  0.0460, -0.0359]],\n",
            "       device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([[[[ 1.2680e-01,  1.3223e-02,  8.8561e-02],\n",
            "          [-2.1536e-01,  6.7797e-02,  5.5777e-02],\n",
            "          [ 1.3994e-01,  2.3411e-02,  8.7029e-02]],\n",
            "\n",
            "         [[-9.2546e-03,  9.1180e-02,  8.2252e-02],\n",
            "          [ 7.4659e-02,  1.9647e-02, -6.5078e-03],\n",
            "          [-1.9257e-04,  3.6556e-02, -3.6322e-02]],\n",
            "\n",
            "         [[ 1.7653e-01, -6.0661e-03, -4.7117e-02],\n",
            "          [ 5.5460e-02, -2.1261e-02,  8.0499e-02],\n",
            "          [ 1.3030e-01,  1.9077e-02, -1.6772e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.8195e-02,  4.0331e-02, -4.8389e-03],\n",
            "          [ 1.2816e-01,  1.0632e-02,  9.9238e-02],\n",
            "          [ 1.2377e-01, -6.8442e-02,  3.0545e-02]],\n",
            "\n",
            "         [[-2.2692e-02,  9.3451e-02,  2.1488e-02],\n",
            "          [ 1.0636e-02, -2.4031e-02,  9.8356e-02],\n",
            "          [-1.1448e-01, -1.6577e-02,  7.7104e-03]],\n",
            "\n",
            "         [[ 2.3359e-02, -1.3822e-02,  1.3315e-01],\n",
            "          [-8.7986e-02,  6.2248e-02,  1.3861e-01],\n",
            "          [ 1.9412e-01,  5.1377e-02,  2.7170e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.4287e-02,  5.6925e-03,  9.1792e-02],\n",
            "          [-7.6060e-02, -3.0730e-02, -6.7820e-02],\n",
            "          [ 6.1703e-02, -4.8764e-02, -6.5557e-02]],\n",
            "\n",
            "         [[-8.5171e-02, -6.0187e-02,  1.4352e-02],\n",
            "          [ 1.1299e-02, -3.9211e-02, -7.6573e-02],\n",
            "          [-1.0774e-01, -5.9617e-02, -1.2523e-01]],\n",
            "\n",
            "         [[ 9.0057e-02,  7.2412e-02,  6.9232e-02],\n",
            "          [-1.1575e-01,  3.3936e-02, -1.5244e-02],\n",
            "          [ 1.0064e-01,  3.3632e-02, -6.2750e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.7791e-03,  2.3959e-01, -4.2679e-02],\n",
            "          [-1.6124e-01, -1.5422e-02, -2.6432e-03],\n",
            "          [ 9.1861e-03,  6.5057e-03, -6.1095e-02]],\n",
            "\n",
            "         [[-8.9753e-02, -2.0058e-02, -9.3793e-04],\n",
            "          [ 1.8804e-02,  5.8942e-02, -6.1910e-02],\n",
            "          [-4.8257e-02,  7.1263e-03,  5.0959e-02]],\n",
            "\n",
            "         [[-6.9097e-02, -1.2470e-02, -2.7783e-02],\n",
            "          [ 1.0500e-01, -2.5777e-01, -4.8795e-02],\n",
            "          [-8.0533e-02, -1.7189e-02,  2.6493e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.0148e-01, -7.6065e-02,  1.5460e-02],\n",
            "          [ 3.0132e-02,  1.5184e-01,  2.0333e-01],\n",
            "          [-1.0697e-01, -3.4506e-02,  9.5291e-02]],\n",
            "\n",
            "         [[-5.7034e-02, -2.6604e-02,  1.0148e-01],\n",
            "          [-1.0755e-01,  5.5514e-02,  7.3855e-02],\n",
            "          [-5.3893e-02,  2.5406e-02,  7.7061e-02]],\n",
            "\n",
            "         [[ 2.7114e-02,  4.0913e-02, -6.8543e-02],\n",
            "          [-1.4822e-01,  1.7677e-01,  1.4472e-01],\n",
            "          [-1.8234e-01,  1.0256e-01, -3.9285e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3650e-01, -1.5249e-01, -2.1608e-02],\n",
            "          [ 2.5492e-02, -2.3684e-02, -7.7836e-02],\n",
            "          [ 8.5603e-02, -6.9836e-02, -1.1846e-01]],\n",
            "\n",
            "         [[ 1.3354e-01, -3.3336e-03, -1.0056e-01],\n",
            "          [ 4.1926e-02,  7.9546e-03, -1.0893e-01],\n",
            "          [ 1.5279e-02, -6.1831e-02, -6.9778e-02]],\n",
            "\n",
            "         [[ 7.7572e-02,  2.5028e-02,  2.1003e-02],\n",
            "          [ 1.8441e-01, -5.7349e-03,  2.6290e-02],\n",
            "          [ 4.7310e-02,  1.0507e-01,  2.4625e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.5871e-02, -1.3152e-01, -1.8754e-03],\n",
            "          [ 7.0683e-03, -1.8898e-02,  3.0742e-02],\n",
            "          [ 4.2568e-02, -9.5257e-02,  8.1466e-03]],\n",
            "\n",
            "         [[-2.7382e-02,  1.0564e-01, -3.0784e-02],\n",
            "          [-1.2422e-01,  1.2804e-01, -1.0801e-01],\n",
            "          [-1.7042e-02,  1.0551e-01,  1.3102e-01]],\n",
            "\n",
            "         [[-7.1906e-02,  7.5920e-02,  1.7863e-01],\n",
            "          [-1.9194e-01, -1.0244e-01, -2.1165e-01],\n",
            "          [-7.5471e-02, -9.7660e-02,  2.8688e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.4496e-02, -8.4308e-02, -2.0582e-03],\n",
            "          [ 5.1523e-02,  1.1843e-01,  4.2605e-02],\n",
            "          [-6.5018e-02, -1.8499e-02, -6.9472e-02]],\n",
            "\n",
            "         [[ 1.9375e-02,  1.1070e-02,  1.4524e-01],\n",
            "          [ 7.4113e-03, -2.6978e-02, -1.4940e-01],\n",
            "          [-4.8791e-02, -3.5700e-02,  2.2019e-02]],\n",
            "\n",
            "         [[ 7.8360e-03,  5.6888e-02, -1.9079e-01],\n",
            "          [-5.5178e-03, -8.2893e-02,  1.1525e-01],\n",
            "          [ 7.8301e-02, -4.2069e-02, -2.4793e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.5452e-02, -2.3319e-02,  2.3713e-02],\n",
            "          [-7.8974e-02,  3.3350e-02,  1.2982e-01],\n",
            "          [-1.8109e-01,  8.5958e-02, -5.3050e-02]],\n",
            "\n",
            "         [[ 2.8014e-01,  5.4151e-02,  4.7616e-02],\n",
            "          [ 6.4802e-02,  1.1824e-01,  2.1245e-02],\n",
            "          [ 4.4250e-02, -1.4869e-03,  1.3957e-01]],\n",
            "\n",
            "         [[ 5.5214e-02, -1.8772e-02,  1.2059e-01],\n",
            "          [ 1.3475e-01, -1.6807e-02,  3.3609e-02],\n",
            "          [ 4.9381e-02, -3.3762e-02,  2.0277e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.7419e-02,  9.1381e-03,  1.0935e-01],\n",
            "          [ 3.8192e-02, -2.7003e-02,  1.6864e-01],\n",
            "          [ 7.0807e-02, -1.3673e-01, -1.4529e-01]],\n",
            "\n",
            "         [[-1.1309e-01,  1.0741e-01,  5.2773e-02],\n",
            "          [ 5.0141e-02,  2.3840e-02, -7.3693e-02],\n",
            "          [-7.4515e-02,  2.0210e-01, -2.9800e-02]],\n",
            "\n",
            "         [[-7.1768e-02,  3.4626e-02, -3.0256e-02],\n",
            "          [-6.9707e-02,  1.9167e-01,  8.7141e-02],\n",
            "          [-3.6241e-03, -2.2553e-01, -2.0536e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8920e-02, -3.6425e-02,  1.2571e-01],\n",
            "          [ 9.7524e-02, -9.4898e-02, -9.0421e-02],\n",
            "          [ 1.6534e-01,  9.2617e-02, -1.6848e-01]],\n",
            "\n",
            "         [[ 2.1711e-02, -3.9771e-02, -1.1062e-02],\n",
            "          [ 3.2804e-02,  1.2148e-01,  3.7753e-02],\n",
            "          [-2.9922e-02,  1.9088e-01, -1.5400e-01]],\n",
            "\n",
            "         [[ 5.5733e-02,  4.5047e-02, -7.0586e-02],\n",
            "          [-2.5606e-02, -5.3330e-02, -7.3910e-02],\n",
            "          [-9.8712e-02,  7.2092e-02,  3.1179e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.4488e-02,  7.0952e-02,  1.2575e-02],\n",
            "          [ 7.1480e-02, -1.1049e-01,  7.5715e-02],\n",
            "          [-5.7153e-03, -1.7829e-01,  1.2532e-01]],\n",
            "\n",
            "         [[ 1.3631e-01,  1.8369e-01,  1.9286e-01],\n",
            "          [ 1.5999e-01, -4.4085e-02,  8.1459e-02],\n",
            "          [ 1.5254e-01, -1.4865e-01, -5.3117e-03]],\n",
            "\n",
            "         [[-2.3334e-02,  1.7020e-01,  1.0228e-01],\n",
            "          [ 9.8004e-02, -5.8168e-03,  1.2220e-01],\n",
            "          [-5.8629e-02, -1.3284e-02,  4.6439e-02]]]], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([-0.0103, -0.1613,  0.0441,  0.0428, -0.1097,  0.0955,  0.1899, -0.0504,\n",
            "        -0.0268,  0.1231,  0.0871, -0.0877, -0.0885,  0.2493, -0.0884, -0.0093,\n",
            "        -0.1115,  0.0378,  0.0945, -0.0730, -0.0210, -0.0667, -0.0195, -0.1033,\n",
            "        -0.0135,  0.0339, -0.0878,  0.0352, -0.0148, -0.0306, -0.0315, -0.0562,\n",
            "        -0.0127,  0.0759,  0.1058, -0.0418, -0.0708, -0.0146,  0.0090, -0.0950,\n",
            "        -0.0158,  0.1045,  0.0741,  0.1511,  0.0021, -0.2176, -0.0549, -0.1316,\n",
            "         0.1328,  0.0557,  0.0332, -0.0303,  0.0573,  0.0761,  0.1738, -0.2023,\n",
            "         0.0899,  0.0874, -0.0714,  0.2628, -0.1363, -0.1887,  0.0167, -0.1468],\n",
            "       device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([[-2.2978e-02,  1.9340e-01, -1.4868e-01,  1.5536e-01,  9.4023e-02,\n",
            "         -4.7330e-02, -1.0015e-02,  1.1846e-01,  6.9176e-02, -2.1641e-02,\n",
            "          1.1097e-01, -3.5053e-02,  9.4144e-02, -9.3024e-02,  1.5977e-01,\n",
            "          2.1617e-02, -1.0075e-01, -2.0621e-02, -2.9322e-03,  2.7158e-02,\n",
            "          5.0949e-02,  2.3190e-02,  7.1103e-02,  7.8138e-02,  6.4285e-02,\n",
            "         -3.1990e-03,  4.1123e-02, -5.2588e-02,  1.9420e-01, -9.3561e-02,\n",
            "         -3.4561e-02, -5.1439e-02,  9.3825e-02,  1.3592e-01, -8.5968e-02,\n",
            "          1.1240e-02, -5.3462e-02, -1.5923e-01,  5.2878e-02,  2.1067e-01,\n",
            "         -1.7246e-01, -7.3622e-02, -4.2732e-02,  3.5180e-02, -4.6779e-03,\n",
            "         -3.0179e-02,  1.3646e-01,  1.4169e-02, -9.5121e-03, -5.0624e-02,\n",
            "          3.1146e-02,  2.1203e-01, -1.7978e-02, -2.0914e-01, -9.9401e-02,\n",
            "          8.0320e-02,  1.3894e-01,  2.9262e-02, -9.4636e-03, -1.7814e-01,\n",
            "          5.3331e-02,  7.7171e-02,  2.2889e-02,  7.7229e-02],\n",
            "        [-6.9773e-02,  8.1531e-02,  9.3693e-02,  8.8093e-02, -1.7650e-01,\n",
            "         -4.3112e-02, -1.0818e-01,  7.9975e-02,  9.8067e-02, -1.6685e-01,\n",
            "         -4.8194e-03,  6.3730e-02,  2.3016e-02, -1.3690e-02,  1.1308e-01,\n",
            "         -1.0088e-01,  2.2157e-03,  1.2565e-01, -4.9533e-02, -6.1279e-02,\n",
            "         -4.6026e-03,  8.6981e-02,  1.8212e-01,  6.3841e-02,  7.4696e-02,\n",
            "         -9.5468e-02, -6.7576e-02, -1.3201e-01,  4.6660e-02, -3.6545e-02,\n",
            "          1.5194e-01, -1.7819e-02,  1.1939e-01,  7.1206e-02, -1.2754e-01,\n",
            "          3.2223e-02,  1.5409e-01, -7.0719e-02,  1.9011e-02, -3.9816e-02,\n",
            "         -4.3717e-02,  1.7137e-02,  2.1882e-02, -3.0540e-02, -1.3654e-01,\n",
            "         -1.5563e-01, -6.9461e-02, -1.0580e-01,  6.8586e-02, -4.6372e-02,\n",
            "         -4.3253e-02,  8.5737e-03, -4.6336e-02, -6.5325e-02,  6.8058e-02,\n",
            "         -8.6157e-03,  3.9848e-02, -2.4649e-01, -4.9661e-02,  7.1370e-02,\n",
            "         -1.1026e-01,  1.2677e-01, -2.8839e-02, -1.0329e-01],\n",
            "        [-1.6329e-01, -1.3684e-01, -1.9272e-02,  3.2076e-02,  9.2556e-02,\n",
            "         -1.8849e-01,  2.8414e-02, -4.6553e-02,  1.8113e-01,  3.7316e-02,\n",
            "         -8.0717e-02,  8.0989e-02,  2.2849e-02, -7.5396e-02, -4.4158e-02,\n",
            "         -2.9676e-03, -2.8904e-02,  3.7577e-02,  5.7330e-02,  4.6843e-02,\n",
            "          1.6153e-01, -1.1448e-01, -5.1429e-02, -3.4858e-03,  2.0566e-02,\n",
            "         -8.3599e-02, -8.5436e-02,  7.5315e-02,  1.4736e-02,  1.1512e-01,\n",
            "          3.0977e-02,  1.0234e-02, -5.6163e-02,  9.7468e-02,  7.1909e-02,\n",
            "         -8.1328e-02, -9.0638e-03,  1.8068e-01, -1.4962e-01, -3.3929e-02,\n",
            "         -1.4847e-01, -2.9879e-02,  7.2397e-02,  1.1682e-02, -1.9938e-01,\n",
            "          6.6984e-02, -7.7755e-02,  7.9137e-02,  1.5109e-01,  2.0790e-01,\n",
            "          2.1068e-01,  1.9728e-02, -6.1411e-02, -1.7413e-02,  7.1814e-02,\n",
            "          1.7799e-01,  1.9935e-02, -1.9015e-02,  2.9655e-02, -5.7641e-02,\n",
            "         -2.5900e-03, -1.4755e-01, -6.7615e-03, -1.3172e-01],\n",
            "        [-1.8500e-01,  4.0154e-03,  2.3789e-01,  6.4444e-03, -6.7586e-02,\n",
            "          3.7085e-02, -4.1989e-02, -1.0559e-01, -1.8855e-01,  1.1296e-01,\n",
            "         -1.1013e-01,  2.3866e-01,  4.1473e-02, -4.3891e-03, -2.1380e-03,\n",
            "         -5.5211e-02, -7.8573e-02, -8.8325e-02,  1.4792e-02,  4.9303e-02,\n",
            "         -2.3874e-03,  7.7033e-02,  7.6481e-02, -8.6137e-02,  1.2940e-01,\n",
            "         -3.0295e-02, -4.6904e-03,  3.7964e-02,  2.1495e-01,  1.4092e-01,\n",
            "         -8.9011e-03,  3.0127e-03, -4.2749e-02, -4.0784e-02,  1.3421e-01,\n",
            "         -1.7955e-02, -2.8465e-01, -4.1642e-02,  7.5084e-02,  1.4812e-01,\n",
            "         -3.1891e-02, -6.8640e-02,  1.2543e-02, -3.4223e-02, -1.2139e-01,\n",
            "          4.4503e-02, -8.7353e-03, -1.2457e-01,  8.3189e-02, -1.0250e-02,\n",
            "         -5.0897e-02,  1.8710e-02,  4.5575e-02,  1.0653e-01,  2.7494e-02,\n",
            "          1.4428e-02, -9.4095e-02, -9.3695e-02, -1.2842e-01, -3.7181e-02,\n",
            "          3.8909e-02,  1.6910e-02, -2.0941e-01,  2.9955e-02],\n",
            "        [ 9.8953e-02,  2.4018e-01,  4.6248e-02, -1.1278e-01,  2.2068e-01,\n",
            "          6.6822e-02, -1.1879e-02, -1.3749e-01, -2.9408e-02,  8.5235e-02,\n",
            "          4.2715e-02, -1.0364e-01, -5.7423e-02,  1.2691e-01, -5.2660e-02,\n",
            "         -2.0122e-01, -3.5548e-03, -8.9250e-02, -1.6194e-04, -6.9320e-02,\n",
            "          4.9155e-03, -3.5043e-02,  8.0589e-03, -4.4085e-02, -7.2390e-02,\n",
            "         -7.7548e-03, -1.3483e-01,  1.1280e-01,  1.2511e-01, -3.1031e-02,\n",
            "          1.2113e-01,  1.1912e-01,  5.2633e-02, -6.8769e-02,  3.3971e-02,\n",
            "         -1.2142e-01,  2.4988e-02, -1.8910e-01,  1.1110e-01,  1.1301e-01,\n",
            "          1.4697e-01, -2.0957e-01, -4.1312e-02,  1.2903e-01,  2.2358e-02,\n",
            "         -9.4877e-02, -1.0100e-01, -1.4184e-01, -6.8402e-02,  6.5383e-02,\n",
            "          7.8399e-02,  2.7159e-02, -2.1747e-01, -6.5552e-02, -1.8458e-01,\n",
            "          1.9166e-01,  1.3273e-01,  2.5195e-02,  1.1462e-01, -1.8410e-01,\n",
            "         -2.8973e-02,  8.0783e-02,  1.3319e-03,  1.5361e-01]], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([[ 0.1262,  0.0304,  0.0847,  0.0487,  0.1089, -0.0482, -0.0478,  0.0658,\n",
            "          0.1168, -0.1154, -0.0926,  0.0681,  0.1328,  0.0662,  0.1324,  0.0302,\n",
            "         -0.0490,  0.0259,  0.1407, -0.2921, -0.0190,  0.0252,  0.1085, -0.0987,\n",
            "         -0.0196, -0.0569,  0.0790, -0.0184, -0.0105, -0.1064,  0.1404, -0.0163,\n",
            "         -0.2242, -0.1018, -0.1693,  0.0352, -0.0470,  0.0344, -0.2054, -0.0899,\n",
            "          0.0798,  0.0414,  0.0377,  0.0460, -0.0903, -0.1596, -0.0254,  0.0278,\n",
            "         -0.0935,  0.1488, -0.0033, -0.1064,  0.0224,  0.2250, -0.0210, -0.2139,\n",
            "         -0.0851, -0.0771,  0.0394,  0.0455, -0.0950,  0.2309, -0.0475, -0.0529],\n",
            "        [-0.0744, -0.0501,  0.0684, -0.0779,  0.1046, -0.1086,  0.0074,  0.0012,\n",
            "          0.0719, -0.0024,  0.0364, -0.1431, -0.2571,  0.0282,  0.0794, -0.0784,\n",
            "          0.1469, -0.1786,  0.0379, -0.0091, -0.1226,  0.0708, -0.0078,  0.0112,\n",
            "          0.0838,  0.0385,  0.0061,  0.0186, -0.0196, -0.1638, -0.1466, -0.0456,\n",
            "          0.0482, -0.0542, -0.1046,  0.0099, -0.0838,  0.0034,  0.0908, -0.0856,\n",
            "         -0.0371, -0.1422,  0.0824,  0.0779, -0.1049, -0.2439,  0.0600, -0.1187,\n",
            "          0.1599, -0.0187,  0.1161,  0.0733,  0.0790,  0.2267,  0.1159,  0.0591,\n",
            "         -0.0093,  0.0972, -0.0803, -0.0780,  0.0450,  0.1240,  0.0071,  0.0426],\n",
            "        [ 0.1431,  0.1197, -0.0560, -0.0727,  0.0555,  0.1792,  0.0286,  0.0575,\n",
            "         -0.0813, -0.0106,  0.1370,  0.0604, -0.2004, -0.0809, -0.0816, -0.0127,\n",
            "          0.0452, -0.0552,  0.0228,  0.0192,  0.0217, -0.0533, -0.0038,  0.1293,\n",
            "          0.1312,  0.1027, -0.0551, -0.0277,  0.1583,  0.2025,  0.1811,  0.0754,\n",
            "          0.0053, -0.0893, -0.0928, -0.0271, -0.0383,  0.0673,  0.1008, -0.0430,\n",
            "          0.2122, -0.0830, -0.0978,  0.0051, -0.0652,  0.0150, -0.0735, -0.0296,\n",
            "         -0.0425, -0.0372,  0.0049,  0.0410, -0.0318, -0.1230, -0.0130,  0.0339,\n",
            "          0.0122, -0.0614,  0.0756,  0.0108,  0.0917, -0.1263,  0.0278, -0.0332],\n",
            "        [-0.0640,  0.0719,  0.0886,  0.0107,  0.0702, -0.0130, -0.0080,  0.0077,\n",
            "          0.1312,  0.0050, -0.0655,  0.0216,  0.0809,  0.0376,  0.0330, -0.0230,\n",
            "         -0.1030, -0.0174,  0.0652, -0.0086,  0.0301, -0.0492, -0.0077,  0.1346,\n",
            "         -0.1611,  0.1274,  0.0179, -0.1416,  0.0642, -0.0582, -0.1668, -0.0159,\n",
            "         -0.0767, -0.0078,  0.0050, -0.0930, -0.0966, -0.0409, -0.0085,  0.0309,\n",
            "          0.0169, -0.1657, -0.1841, -0.1152, -0.1042,  0.0482,  0.0520,  0.1099,\n",
            "         -0.0438,  0.0219,  0.0094,  0.0318,  0.0295, -0.0502, -0.1121,  0.1510,\n",
            "         -0.0728, -0.0441,  0.0528, -0.0711,  0.2407,  0.0018, -0.0086,  0.0020],\n",
            "        [-0.0218, -0.1735, -0.0577,  0.0279, -0.1546,  0.0450, -0.0021, -0.1633,\n",
            "         -0.0186, -0.2333,  0.0360, -0.1039, -0.1135,  0.0630, -0.0785, -0.0394,\n",
            "         -0.1406, -0.1169, -0.0192,  0.0927,  0.0412,  0.0926,  0.0202, -0.0325,\n",
            "          0.1771,  0.0025,  0.1128,  0.0460,  0.0739,  0.1406, -0.0086, -0.0734,\n",
            "          0.0828, -0.0083, -0.0642,  0.0431, -0.0542,  0.0697,  0.0255,  0.0282,\n",
            "          0.0625,  0.0971, -0.0366,  0.0935,  0.0072, -0.1269,  0.0396, -0.0293,\n",
            "          0.0129, -0.0155, -0.1102,  0.1235,  0.0569,  0.0155,  0.0388, -0.0560,\n",
            "          0.0830,  0.1012, -0.0688, -0.0299, -0.1526,  0.0259, -0.0791, -0.1757]],\n",
            "       device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([[[[-2.4234e-02, -2.2566e-01,  1.7090e-01],\n",
            "          [ 2.5462e-02, -7.1490e-02,  6.0599e-02],\n",
            "          [ 4.6991e-02,  2.3814e-01,  5.9635e-02]],\n",
            "\n",
            "         [[-3.2624e-02,  2.6839e-03, -8.7443e-02],\n",
            "          [-4.2126e-02, -1.5870e-02,  1.2922e-01],\n",
            "          [ 2.6082e-02,  7.6529e-03,  1.7205e-01]],\n",
            "\n",
            "         [[-4.1299e-02, -3.8572e-02, -6.0805e-02],\n",
            "          [ 1.6161e-01,  2.6236e-02, -7.1649e-02],\n",
            "          [ 9.2664e-02, -6.3705e-02, -1.3465e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4881e-01, -7.6199e-02,  1.4009e-01],\n",
            "          [-1.1405e-02,  4.9616e-02, -5.8930e-02],\n",
            "          [ 7.2132e-02,  1.2565e-01, -5.3756e-02]],\n",
            "\n",
            "         [[ 1.0333e-01, -4.8730e-02, -1.6157e-01],\n",
            "          [ 2.9075e-02,  3.4312e-02, -1.2053e-01],\n",
            "          [ 6.6277e-03,  6.2164e-03, -1.2175e-01]],\n",
            "\n",
            "         [[ 1.4558e-01,  3.2345e-02, -1.0972e-01],\n",
            "          [ 1.5822e-01, -1.2161e-01, -1.0891e-01],\n",
            "          [ 9.5638e-02, -9.5392e-03, -1.5229e-01]]],\n",
            "\n",
            "\n",
            "        [[[-4.3610e-02,  3.1655e-02, -9.3305e-03],\n",
            "          [ 2.2943e-02, -1.3882e-02, -3.8663e-02],\n",
            "          [-4.8948e-02, -1.2163e-02,  5.1641e-02]],\n",
            "\n",
            "         [[-5.6585e-02,  3.5923e-02, -2.7564e-02],\n",
            "          [-1.0740e-01,  5.4061e-03, -1.3822e-02],\n",
            "          [ 1.5052e-01, -1.6887e-01,  6.7989e-02]],\n",
            "\n",
            "         [[-8.0134e-03, -8.8501e-02, -2.0387e-01],\n",
            "          [-3.5489e-02,  1.2222e-01, -2.0430e-02],\n",
            "          [ 1.9593e-01,  6.2261e-02,  9.5253e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.9362e-02, -1.1177e-01,  5.5413e-03],\n",
            "          [ 4.6387e-02,  1.0102e-01, -6.9785e-02],\n",
            "          [-1.0673e-01,  3.4611e-02,  2.7367e-04]],\n",
            "\n",
            "         [[ 9.2689e-02,  9.0986e-02,  6.9435e-02],\n",
            "          [ 8.0388e-02,  2.8980e-04,  9.0450e-02],\n",
            "          [-1.0230e-01, -6.7985e-02, -1.6178e-02]],\n",
            "\n",
            "         [[ 7.7677e-02, -1.5490e-01,  3.0386e-02],\n",
            "          [ 1.1442e-01,  1.6694e-01, -6.9206e-02],\n",
            "          [-5.7540e-02, -1.6795e-01,  1.4544e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.7321e-02, -1.6080e-01, -3.0740e-02],\n",
            "          [ 7.5067e-03, -9.4732e-02,  1.3182e-03],\n",
            "          [-1.5809e-01,  3.1653e-02, -7.6474e-02]],\n",
            "\n",
            "         [[ 1.4996e-01,  6.2439e-02, -9.6891e-02],\n",
            "          [-4.2950e-02,  9.0342e-02,  1.3774e-01],\n",
            "          [ 4.4953e-03, -9.8285e-03, -8.8939e-02]],\n",
            "\n",
            "         [[-6.6680e-02, -5.4561e-02, -1.2428e-02],\n",
            "          [ 1.2268e-01, -8.6333e-02,  6.9562e-02],\n",
            "          [ 6.3616e-02, -1.4608e-01,  4.4652e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.3489e-05,  1.0218e-01,  1.4056e-02],\n",
            "          [-1.3660e-01, -4.5346e-03,  1.1877e-01],\n",
            "          [ 6.0325e-03,  8.4251e-02, -1.4459e-02]],\n",
            "\n",
            "         [[-1.2212e-01, -8.5763e-02, -7.2246e-02],\n",
            "          [-1.1292e-01,  5.3466e-02, -7.9095e-02],\n",
            "          [-1.0360e-01,  6.8811e-02, -1.0493e-01]],\n",
            "\n",
            "         [[-2.0467e-02, -8.4354e-02, -1.6279e-01],\n",
            "          [ 5.8333e-02,  1.6000e-01,  3.7151e-02],\n",
            "          [-7.7522e-02, -8.8884e-03,  1.4492e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-7.0464e-02,  9.4445e-02, -9.7512e-03],\n",
            "          [ 1.2228e-01,  2.0025e-01,  1.4618e-02],\n",
            "          [-1.7025e-01, -2.2377e-01,  3.3683e-02]],\n",
            "\n",
            "         [[ 7.6356e-02, -9.7647e-02,  2.6599e-03],\n",
            "          [ 9.1510e-02, -7.0146e-02, -4.7287e-02],\n",
            "          [ 1.2449e-01,  4.5599e-03, -1.2722e-01]],\n",
            "\n",
            "         [[-4.0023e-02, -6.7264e-02,  1.0952e-01],\n",
            "          [ 4.1487e-02,  6.9377e-02, -8.5399e-02],\n",
            "          [ 5.5748e-02,  4.2729e-02, -4.2305e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.0178e-02, -7.1775e-02, -1.4429e-01],\n",
            "          [-1.8826e-01, -7.0453e-02, -7.6998e-02],\n",
            "          [ 6.5718e-02, -1.3581e-02,  1.7568e-02]],\n",
            "\n",
            "         [[-1.5822e-01,  2.2706e-03,  6.9175e-02],\n",
            "          [-6.1259e-02,  1.8524e-01,  1.1129e-01],\n",
            "          [-4.2879e-02, -1.1196e-01,  1.4593e-01]],\n",
            "\n",
            "         [[-1.3059e-02, -1.3736e-01,  4.7039e-02],\n",
            "          [ 2.0423e-01, -1.4976e-01,  1.8825e-02],\n",
            "          [-1.7659e-01, -3.3647e-02, -8.4359e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.6284e-03,  4.5473e-02, -4.5381e-02],\n",
            "          [-1.2598e-01,  5.4626e-02, -1.0485e-01],\n",
            "          [-4.8350e-02, -4.6423e-02,  2.3367e-02]],\n",
            "\n",
            "         [[-8.4810e-02, -1.4090e-01,  1.3922e-01],\n",
            "          [-2.9874e-01, -6.0687e-02,  9.5135e-02],\n",
            "          [ 1.1075e-01,  1.0804e-01, -2.9466e-02]],\n",
            "\n",
            "         [[-1.2930e-03,  2.0044e-01, -2.5383e-02],\n",
            "          [ 6.6333e-03, -7.1960e-02, -9.1925e-04],\n",
            "          [ 1.2057e-01, -1.0942e-01,  1.5418e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1713e-01,  1.3223e-01,  6.1869e-02],\n",
            "          [ 9.6492e-02, -2.9788e-02,  3.4255e-02],\n",
            "          [-5.3193e-02,  1.2762e-02,  1.0871e-01]],\n",
            "\n",
            "         [[ 2.9005e-02, -6.5776e-02,  7.5820e-02],\n",
            "          [ 5.1071e-02, -1.0767e-01, -2.1695e-02],\n",
            "          [-2.3463e-01, -8.0559e-02, -5.2733e-02]],\n",
            "\n",
            "         [[-1.4113e-03,  1.0522e-03,  9.2894e-02],\n",
            "          [-1.0507e-02,  1.5931e-01, -6.3866e-02],\n",
            "          [-2.5888e-02,  4.2993e-02,  8.1903e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7381e-02,  2.8219e-02, -3.2541e-02],\n",
            "          [ 1.2828e-01, -9.1244e-02, -1.1066e-01],\n",
            "          [-9.7393e-03,  1.1291e-01,  1.3617e-01]],\n",
            "\n",
            "         [[-7.7722e-02,  4.6522e-02,  1.5324e-01],\n",
            "          [ 2.8023e-02, -4.7002e-02,  3.9884e-03],\n",
            "          [-1.2675e-02, -1.9344e-02, -2.6167e-03]],\n",
            "\n",
            "         [[-1.2167e-01, -1.3406e-01,  1.0866e-01],\n",
            "          [-8.5350e-02,  6.4028e-02, -5.4298e-02],\n",
            "          [ 6.6116e-02, -8.4295e-02,  1.0645e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.5465e-02,  1.3374e-01, -1.7294e-02],\n",
            "          [ 5.2365e-02,  1.6893e-01,  2.4718e-01],\n",
            "          [ 2.1805e-01, -2.5094e-02,  7.6706e-02]],\n",
            "\n",
            "         [[ 2.3072e-02, -7.3249e-02, -6.1433e-02],\n",
            "          [-1.5426e-01,  1.1318e-01,  3.6508e-02],\n",
            "          [-2.7711e-03, -7.8056e-02,  9.6925e-02]],\n",
            "\n",
            "         [[-1.8840e-01, -2.2702e-02,  5.5157e-02],\n",
            "          [-1.6730e-01, -1.1643e-01,  1.6355e-01],\n",
            "          [-1.9865e-01, -7.2890e-02,  5.2227e-02]]]], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([-0.1519,  0.0952,  0.0304, -0.0302,  0.0612,  0.0971,  0.0345,  0.1858,\n",
            "         0.0767,  0.0517, -0.0313,  0.2482,  0.1297, -0.1677, -0.1075, -0.0358,\n",
            "         0.0391, -0.0399,  0.0437, -0.1177,  0.0238,  0.2004,  0.0101,  0.1281,\n",
            "         0.0360, -0.0631, -0.0045,  0.1009,  0.0633, -0.1283,  0.0505,  0.0354,\n",
            "        -0.1755,  0.1003, -0.0413,  0.1007, -0.1314,  0.0031, -0.2170, -0.1068,\n",
            "        -0.0509,  0.1158, -0.0600, -0.0394,  0.0355, -0.0090, -0.1831,  0.1068,\n",
            "        -0.1032,  0.0322,  0.1320,  0.0303,  0.2004, -0.0346, -0.0154,  0.0178,\n",
            "         0.0007,  0.2098,  0.1234, -0.0314, -0.0287, -0.0246,  0.0258,  0.0061],\n",
            "       device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([[-1.8289e-01, -1.1757e-01, -2.8821e-02, -1.1347e-01,  7.1535e-02,\n",
            "         -7.6396e-02,  1.5928e-02, -1.3671e-01,  2.1809e-01, -5.5418e-02,\n",
            "         -3.4265e-03,  3.1585e-02,  2.1929e-02, -3.3835e-02,  1.7379e-01,\n",
            "         -9.2798e-02,  3.8340e-03,  1.4497e-01, -1.7992e-02, -4.6275e-02,\n",
            "          1.1872e-01,  1.3659e-01, -1.0015e-01, -1.4851e-01, -7.1347e-05,\n",
            "         -4.0334e-02, -5.7949e-02,  9.6463e-02,  1.0854e-01,  1.1844e-03,\n",
            "          1.0409e-01,  5.2626e-02,  4.9521e-03, -2.4454e-02, -1.7247e-01,\n",
            "         -5.4988e-02,  1.5178e-01, -9.5530e-02,  2.4496e-02, -4.3658e-02,\n",
            "         -4.8837e-02,  1.2343e-01,  1.5165e-01,  1.0391e-01, -1.6183e-01,\n",
            "         -4.0409e-02,  1.3479e-01,  7.6922e-02, -3.3264e-02,  2.7761e-01,\n",
            "          2.5876e-02, -3.0062e-02,  9.1801e-02,  8.4297e-02,  1.5179e-01,\n",
            "         -2.3259e-01, -9.0814e-02,  1.4575e-01,  1.3724e-01,  2.1586e-02,\n",
            "         -2.8061e-02, -2.3110e-01, -1.6136e-01,  1.3156e-02],\n",
            "        [ 1.0638e-01,  3.2172e-02, -7.5044e-02,  5.7596e-02, -6.9835e-02,\n",
            "         -5.5666e-02, -1.4711e-01, -4.4263e-02, -1.3608e-01,  4.8302e-03,\n",
            "         -5.1721e-02,  1.3066e-01, -3.1975e-02, -5.1868e-02,  1.1730e-01,\n",
            "         -3.9104e-02, -1.4911e-01,  1.8226e-01, -1.0200e-02,  3.4755e-02,\n",
            "         -2.6562e-02,  1.9639e-01, -7.0164e-02, -3.1651e-02, -7.4535e-02,\n",
            "          3.3865e-02,  2.0571e-01,  2.1031e-02, -1.1780e-01, -2.1755e-02,\n",
            "         -2.1303e-02,  6.8994e-03, -1.0004e-01, -3.5988e-02,  8.0998e-03,\n",
            "         -6.1619e-02, -5.2005e-02, -1.8688e-01, -1.0261e-01, -9.8714e-02,\n",
            "          1.4333e-01, -1.3064e-01, -8.4756e-02,  1.9791e-02,  1.9341e-01,\n",
            "         -9.5464e-02, -1.5690e-01,  6.7803e-02,  4.0272e-02, -3.7256e-02,\n",
            "          6.2756e-02,  2.9095e-02, -1.5062e-01,  7.5789e-02,  3.8339e-02,\n",
            "          3.4289e-02, -2.0524e-02, -1.2894e-02,  1.0990e-01, -1.0067e-01,\n",
            "         -5.8213e-02, -1.5134e-01,  2.6896e-01,  8.6820e-02],\n",
            "        [ 6.3068e-03, -5.5071e-03,  1.2848e-02,  2.5261e-01,  6.8591e-02,\n",
            "          4.4944e-02, -8.1759e-02,  1.3690e-01, -8.0418e-02, -5.5601e-02,\n",
            "          9.3056e-02,  1.4095e-01,  5.1051e-02,  4.7255e-02, -4.5880e-02,\n",
            "          4.8299e-02, -1.1498e-01, -1.2539e-01, -4.4617e-02,  8.5462e-02,\n",
            "         -9.8930e-02,  8.4265e-02, -3.3034e-02, -1.1637e-01,  5.4928e-02,\n",
            "         -5.6728e-02,  1.3867e-01, -3.8002e-02,  1.5309e-01,  4.9732e-03,\n",
            "          5.9652e-02,  3.3548e-02, -5.6458e-02, -1.1968e-01,  1.4255e-01,\n",
            "         -2.0665e-01, -8.7554e-02, -1.1687e-01,  4.1810e-03,  6.9031e-02,\n",
            "          2.1860e-01, -1.5095e-02,  1.3047e-01,  1.2265e-01, -3.1115e-02,\n",
            "         -3.3150e-02, -7.1685e-02, -2.9065e-01, -6.3398e-02, -3.4241e-02,\n",
            "          1.5107e-01,  2.0254e-01, -2.1564e-02,  6.5036e-02, -4.1794e-02,\n",
            "         -1.0006e-01,  6.6119e-03, -5.0589e-03,  1.2581e-03, -2.0101e-02,\n",
            "          8.2708e-03,  4.0845e-02, -6.4684e-02,  1.5079e-01],\n",
            "        [ 1.7206e-02,  7.6657e-02, -8.9731e-02,  7.0077e-02,  8.2574e-02,\n",
            "          1.2962e-01, -1.1082e-01, -1.7983e-03, -1.7235e-01,  1.3935e-02,\n",
            "          6.5814e-02,  8.5591e-03, -1.5236e-01,  6.2225e-02, -9.5952e-02,\n",
            "          5.0883e-02,  9.1026e-02,  1.8867e-02,  1.3722e-02,  1.4190e-02,\n",
            "          1.8044e-01,  6.0828e-02, -9.5591e-02,  4.9754e-02,  2.2064e-02,\n",
            "          2.2129e-01, -5.0121e-02, -1.2786e-01, -3.9585e-02, -1.4237e-01,\n",
            "          2.7603e-02, -5.7831e-02,  1.1215e-02,  2.2448e-01,  2.0200e-01,\n",
            "         -5.6999e-02, -2.4561e-01,  1.0968e-01, -1.8966e-01,  1.3993e-01,\n",
            "         -3.9659e-02, -3.8804e-02, -5.9602e-03, -4.6744e-02,  7.2734e-02,\n",
            "         -2.7972e-02, -1.5708e-01, -1.0566e-01, -8.2630e-02, -7.5937e-02,\n",
            "          3.3885e-02,  1.1365e-01,  7.6536e-02, -6.7413e-03, -5.1896e-02,\n",
            "         -7.2824e-02, -5.9399e-02, -1.4039e-01,  4.0627e-03, -4.4984e-01,\n",
            "          1.7061e-01, -1.8879e-01,  3.8051e-03,  2.5634e-03],\n",
            "        [ 3.2911e-02, -1.1859e-02,  1.0757e-01,  3.6742e-02,  1.1390e-01,\n",
            "         -1.0221e-02, -4.7648e-02, -1.1863e-01, -6.1793e-02, -7.7954e-02,\n",
            "          1.5185e-01,  4.7136e-02, -7.0609e-04, -1.0753e-01,  1.2485e-01,\n",
            "          4.2112e-02, -9.0603e-02, -6.7909e-02, -8.4598e-02, -6.3221e-02,\n",
            "         -1.1365e-02,  5.5926e-02,  1.0362e-01, -1.3107e-01, -1.9089e-02,\n",
            "          6.4991e-02, -5.1097e-02,  9.4267e-02, -2.1780e-01, -5.1774e-02,\n",
            "          1.2240e-01, -2.1228e-02,  4.6512e-02, -1.6699e-01,  1.1033e-01,\n",
            "         -6.6469e-02,  1.7232e-01,  1.1289e-01,  4.2889e-02,  4.9235e-02,\n",
            "          3.5930e-02, -9.1499e-02,  8.5147e-02,  1.8146e-02, -1.1307e-01,\n",
            "          1.1810e-01, -1.1866e-01,  7.6312e-02,  5.9811e-02,  1.7654e-01,\n",
            "         -4.8783e-02,  6.1983e-02, -1.7536e-01, -4.8692e-02, -2.1823e-01,\n",
            "         -6.2219e-02, -4.9095e-02, -1.2187e-02, -7.5651e-02,  3.1751e-02,\n",
            "         -7.4809e-02,  1.2014e-01,  6.6485e-02,  9.3526e-02]], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([[ 3.5186e-02,  8.7565e-02,  4.0972e-02, -1.2078e-01,  8.1530e-02,\n",
            "         -1.1147e-01, -7.8868e-02,  1.8730e-01,  4.4809e-03,  3.7696e-02,\n",
            "         -1.7821e-04,  1.1646e-01,  1.4685e-02, -7.5692e-02,  1.3232e-01,\n",
            "          4.8797e-02, -1.5775e-03, -1.3244e-01, -8.5958e-02, -3.4117e-02,\n",
            "         -2.0682e-02, -8.2059e-02, -8.7827e-02, -3.8934e-02,  5.0023e-02,\n",
            "         -2.8453e-02,  1.9044e-01, -1.4975e-01, -2.5768e-02,  1.1077e-02,\n",
            "         -2.9599e-02, -2.0017e-01,  2.1633e-01,  3.6372e-02,  5.1049e-02,\n",
            "          9.2830e-02,  1.3102e-02,  2.0601e-02, -9.2798e-03, -8.0380e-03,\n",
            "         -1.0351e-01,  1.2514e-01, -7.8872e-02, -8.9135e-02,  4.1732e-02,\n",
            "         -1.8188e-02,  1.3560e-01, -7.8524e-02,  2.7718e-02, -1.8232e-01,\n",
            "          1.1389e-02, -5.8458e-02,  2.4482e-01, -5.6781e-02,  1.2235e-01,\n",
            "          3.1741e-02, -6.2436e-02,  2.8957e-02, -9.3340e-02, -6.6068e-02,\n",
            "          1.1777e-01,  1.9890e-01, -9.6648e-02, -7.0001e-02],\n",
            "        [-1.1238e-01,  2.5250e-02, -7.8101e-02, -6.0590e-02, -4.1437e-02,\n",
            "         -7.8046e-02,  3.5839e-02,  4.4729e-02,  7.3859e-02,  2.0045e-02,\n",
            "         -1.4146e-02,  1.1776e-01, -6.9913e-02,  2.2856e-02, -2.4032e-01,\n",
            "         -1.7866e-01, -2.9729e-02, -3.4620e-02,  1.2974e-01,  8.5024e-02,\n",
            "          9.5151e-02,  4.4720e-02, -9.8570e-02,  1.2293e-01,  1.1014e-01,\n",
            "          8.4720e-02,  7.5298e-02,  1.6731e-01,  1.5703e-02,  9.0639e-02,\n",
            "         -4.3778e-02, -8.8247e-02, -1.1349e-01,  6.4485e-03, -1.6674e-01,\n",
            "          7.8661e-02, -1.3612e-01, -2.2968e-01,  5.0833e-02,  1.6305e-02,\n",
            "          1.4809e-02, -4.8455e-02, -9.2067e-02,  6.8845e-02,  1.6539e-01,\n",
            "         -1.0523e-01,  2.5614e-02,  1.0537e-01, -3.8143e-02, -3.7079e-02,\n",
            "          9.1133e-03,  8.0542e-02,  3.4814e-02,  1.1315e-01,  1.3464e-01,\n",
            "          1.7223e-01,  8.1463e-02,  6.3524e-02, -4.6893e-02,  7.3272e-03,\n",
            "         -6.0719e-02, -1.1833e-02,  4.3744e-02, -2.5026e-02],\n",
            "        [ 1.1885e-01, -1.0457e-02, -9.2189e-02,  8.4430e-02,  1.0153e-01,\n",
            "          3.4198e-04,  2.6214e-01,  3.2020e-02, -1.7445e-01,  5.9401e-03,\n",
            "         -1.8095e-01,  3.5708e-03, -1.7746e-02,  1.6736e-01, -3.6650e-02,\n",
            "         -1.8715e-02,  1.9519e-02, -8.0364e-02,  4.7462e-02,  7.4594e-02,\n",
            "         -9.7124e-02, -1.2303e-01,  1.0680e-01, -1.0114e-01, -9.2228e-02,\n",
            "          9.3050e-02,  1.3879e-01, -3.0073e-02,  1.3571e-01, -6.5730e-02,\n",
            "         -5.8325e-03, -1.6186e-01, -3.3859e-03,  1.1733e-01,  1.2742e-01,\n",
            "          6.5908e-02, -1.3571e-01,  1.5421e-01, -1.1466e-01, -5.3993e-03,\n",
            "         -1.1823e-02, -7.3196e-03, -1.8867e-02, -1.0218e-02, -1.0402e-01,\n",
            "          4.2626e-02,  2.3093e-02, -8.7665e-02, -1.5238e-01,  6.3216e-02,\n",
            "          4.3134e-02,  1.3836e-01, -2.7406e-02,  4.6250e-02,  6.4330e-02,\n",
            "          2.8686e-02,  1.0406e-01,  1.0335e-01,  6.1912e-02,  7.5206e-02,\n",
            "          8.9574e-02, -1.0460e-01, -8.3580e-02, -1.1506e-01],\n",
            "        [ 1.4840e-01, -5.6033e-02, -1.8245e-02, -6.6504e-02,  4.4681e-02,\n",
            "         -1.8810e-01, -1.0010e-01, -3.8315e-02,  8.2917e-02, -6.6827e-02,\n",
            "         -1.6921e-01, -4.6523e-02, -2.1939e-01,  1.1118e-01, -1.8796e-02,\n",
            "          4.7694e-02, -9.3673e-03, -5.1850e-02, -2.1784e-02, -1.1893e-02,\n",
            "          2.0560e-03, -1.2971e-01,  6.2687e-02, -2.1028e-02,  8.8278e-02,\n",
            "         -7.1923e-02, -6.5180e-02, -6.2804e-03, -1.1069e-01, -4.6959e-02,\n",
            "         -5.4230e-02, -1.1876e-01,  8.4475e-02,  2.3164e-01,  6.9238e-02,\n",
            "          1.3724e-01,  4.3562e-02,  9.5832e-02, -5.2865e-02,  3.1461e-02,\n",
            "          2.1073e-01,  2.0913e-01, -8.3036e-02, -7.3248e-02, -3.8687e-02,\n",
            "          5.5923e-02, -1.4985e-01,  4.5063e-02,  8.9808e-02, -4.0910e-02,\n",
            "          1.7104e-02, -8.2087e-02, -1.3020e-01,  8.9465e-03, -7.5361e-02,\n",
            "         -1.9190e-02, -9.3366e-04,  2.3103e-01, -1.7905e-01, -2.4743e-02,\n",
            "          1.1288e-01,  2.1874e-02, -8.8420e-02,  1.4604e-01],\n",
            "        [-3.6420e-02, -9.2115e-02,  1.2093e-01,  1.4036e-01, -7.3157e-02,\n",
            "          4.3233e-02, -9.5805e-02,  1.2672e-01,  1.9921e-01, -1.8127e-02,\n",
            "          1.3894e-01, -1.2431e-01, -2.5943e-02, -3.4895e-02, -5.2708e-03,\n",
            "         -7.3434e-02,  1.1691e-02,  4.0050e-02, -3.2755e-01,  4.2607e-02,\n",
            "         -7.5811e-03, -7.0218e-02, -2.2662e-01, -4.0700e-02,  8.1834e-02,\n",
            "          2.4769e-02, -6.0927e-02,  1.6437e-02, -1.7723e-02, -2.6548e-02,\n",
            "         -8.4274e-02, -3.3423e-02,  2.0968e-02, -1.0815e-01, -6.9072e-02,\n",
            "         -1.0415e-02, -1.3272e-01, -2.0111e-02, -1.1343e-01,  2.0150e-01,\n",
            "          1.4020e-01, -7.8836e-03, -8.0864e-02,  1.1416e-01,  8.4230e-02,\n",
            "         -6.7696e-02, -1.2707e-01,  6.7575e-02,  1.3342e-01,  8.2624e-02,\n",
            "          5.9814e-02,  2.3183e-02,  1.2563e-01,  1.3257e-01,  1.5234e-01,\n",
            "         -1.6083e-02, -1.2675e-01,  2.7208e-01,  1.4821e-01,  1.6834e-01,\n",
            "          7.1408e-03, -4.8355e-02, -5.3943e-02, -1.1109e-01]], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([[-0.0118, -0.0500,  0.0767, -0.1450, -0.0437, -0.0816,  0.0795, -0.0572,\n",
            "         -0.0665,  0.2153,  0.0824,  0.0928, -0.0486,  0.0395, -0.1212,  0.0005,\n",
            "         -0.1068,  0.0705,  0.1295, -0.0568, -0.0740,  0.1087, -0.0466, -0.0376,\n",
            "         -0.1329, -0.0701,  0.0859, -0.0332,  0.0219,  0.0777,  0.0467, -0.1286,\n",
            "          0.0878,  0.0463,  0.0254,  0.0104,  0.0500,  0.0089, -0.0260, -0.0308,\n",
            "         -0.0340,  0.0686,  0.0825,  0.0024, -0.0777,  0.0765, -0.0653,  0.1678,\n",
            "          0.1043, -0.0570, -0.2174,  0.0985,  0.0145,  0.0382,  0.1632, -0.0896,\n",
            "         -0.0637, -0.0821,  0.1015,  0.0339, -0.0449, -0.0878,  0.2544,  0.1420],\n",
            "        [-0.1797,  0.0953,  0.1651, -0.2205,  0.1576,  0.0067,  0.1882,  0.0191,\n",
            "         -0.0309,  0.0803,  0.1506,  0.0219, -0.0672, -0.1251,  0.0953,  0.0650,\n",
            "         -0.0515,  0.1056, -0.1780, -0.0888,  0.1467,  0.0923,  0.0807, -0.1314,\n",
            "         -0.1581,  0.0073,  0.0900, -0.0834,  0.0862,  0.0900, -0.0548, -0.0415,\n",
            "          0.1351, -0.1320,  0.0208,  0.0524, -0.0613, -0.0383, -0.2630,  0.0501,\n",
            "          0.1050,  0.0868, -0.0032,  0.0564,  0.1247,  0.1509, -0.0873,  0.0666,\n",
            "          0.1228, -0.0395, -0.0464,  0.0435,  0.0346,  0.0670,  0.0341,  0.0804,\n",
            "          0.0500, -0.1503, -0.0147,  0.1114, -0.3029, -0.0824,  0.2467, -0.0381],\n",
            "        [ 0.2046, -0.0468,  0.0061,  0.1312,  0.0519, -0.1458, -0.1162,  0.1124,\n",
            "         -0.1624,  0.1257, -0.0062,  0.0843,  0.0046, -0.0850,  0.0257, -0.0354,\n",
            "         -0.1895,  0.0082, -0.1467, -0.0570,  0.0882,  0.0417,  0.0129, -0.2207,\n",
            "         -0.0133,  0.0147,  0.0291, -0.1054,  0.0547,  0.0609, -0.0745, -0.0313,\n",
            "         -0.0445,  0.1302,  0.1239,  0.0933,  0.0513,  0.0741,  0.0736,  0.1630,\n",
            "          0.1282, -0.1602, -0.0809,  0.1180,  0.0651, -0.0087,  0.0084,  0.0756,\n",
            "          0.1503,  0.0833, -0.0727, -0.0239,  0.0465, -0.0215,  0.0083, -0.1276,\n",
            "         -0.0696,  0.1909,  0.0423,  0.0528,  0.0259, -0.0463, -0.0905,  0.0008],\n",
            "        [ 0.0274, -0.1310, -0.0791,  0.0071, -0.0654, -0.1172,  0.0735,  0.1157,\n",
            "         -0.0922, -0.1579,  0.1114, -0.0660, -0.0452, -0.0060, -0.1592, -0.0148,\n",
            "         -0.0912,  0.0169, -0.1277, -0.2800, -0.0894,  0.0179,  0.0673, -0.0409,\n",
            "         -0.0088, -0.0469,  0.1298,  0.0558, -0.1111,  0.0504, -0.0222,  0.0003,\n",
            "         -0.1130,  0.0279,  0.1517, -0.3127, -0.0164, -0.1702,  0.0114, -0.0575,\n",
            "          0.0251,  0.0274,  0.1237,  0.1033, -0.1421,  0.1661, -0.0144, -0.0457,\n",
            "         -0.0232,  0.0259,  0.0466,  0.0312,  0.0500,  0.1053, -0.0458, -0.0175,\n",
            "         -0.0283, -0.1238,  0.2251, -0.1406, -0.0145, -0.0755,  0.1112, -0.0311],\n",
            "        [ 0.0298,  0.1101,  0.1096,  0.0462, -0.2028,  0.0156,  0.0110,  0.1432,\n",
            "          0.0943,  0.0019, -0.0097, -0.0233,  0.0574,  0.1378, -0.0979, -0.0357,\n",
            "         -0.2089,  0.0601, -0.0390,  0.0927, -0.0214,  0.0645, -0.2897,  0.0216,\n",
            "          0.0164,  0.1591, -0.0222,  0.1308,  0.0650, -0.0517, -0.1923,  0.0276,\n",
            "         -0.1072, -0.0438,  0.0419, -0.0622, -0.1037, -0.0013, -0.0356,  0.1071,\n",
            "          0.1192,  0.0026, -0.0007,  0.0607, -0.1691, -0.2416,  0.0885,  0.0846,\n",
            "          0.1808,  0.0907,  0.0311, -0.0589, -0.0454,  0.0925,  0.0915, -0.1433,\n",
            "         -0.1535, -0.0049,  0.0525,  0.1501, -0.2076, -0.0572,  0.0603,  0.1105]],\n",
            "       device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([-0.0116,  0.2291, -0.0212,  0.0672,  0.0589], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([-0.0166,  0.1837,  0.0968, -0.1098, -0.0192,  0.0113], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([ 0.1042,  0.1051,  0.0988,  0.1091,  0.0661, -0.0450], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([ 0.0845,  0.1815, -0.2016, -0.0175,  0.0492, -0.0350], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([ 0.0763, -0.0453, -0.0376,  0.1434, -0.0363,  0.0749], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([-0.0259, -0.1164,  0.1801,  0.1823, -0.0011, -0.0633], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([-0.0139, -0.1339, -0.0636, -0.0773, -0.0967,  0.0552], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([ 0.0305,  0.0452,  0.1046, -0.0354,  0.1372, -0.0113], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([ 0.0532, -0.1741, -0.0399, -0.1537, -0.0664, -0.0689], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([ 0.0194,  0.0761, -0.0077, -0.1037,  0.0740,  0.0555], device='cuda:0') amount of noise :)\n",
            "the grinch added tensor([-0.0871, -0.1730,  0.0622, -0.0069, -0.1575,  0.0576], device='cuda:0') amount of noise :)\n",
            "attempting to find existing checkpoint\n",
            "Loading data into RAM\n",
            "Currently loading into memory the train set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1150/1150 [00:06<00:00, 182.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently loading into memory the val set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 50/50 [00:00<00:00, 129.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently loading into memory the test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 423/423 [00:02<00:00, 189.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data {'train': 23000, 'val': 1000, 'test': 8460}\n",
            "train_seed 875689, val_seed: 985773, at start time\n",
            "0 75000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/75000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of data torch.Size([8, 5, 5, 1, 28, 28]) torch.Size([8, 5, 1, 1, 28, 28]) torch.Size([8, 5, 5]) torch.Size([8, 5, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-87915e2e92a4>:132: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  and param.grad is not None\n",
            "training phase 0 -> loss: 1.2018, accuracy: 0.8500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 1/75000 [00:02<47:01:54,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 1.0820, accuracy: 0.8000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 2/75000 [00:03<30:43:10,  1.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.09025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 1.0389, accuracy: 0.7250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 3/75000 [00:04<25:20:37,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0857375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 1.0370, accuracy: 0.7500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 4/75000 [00:05<25:48:56,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.08145062499999998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 1.0575, accuracy: 0.7500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 5/75000 [00:06<21:59:31,  1.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.07737809374999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 1.0060, accuracy: 0.8250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 6/75000 [00:06<19:19:03,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.07350918906249998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 1.0187, accuracy: 0.7750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 7/75000 [00:07<17:34:00,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.06983372960937498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 1.0384, accuracy: 0.7750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 8/75000 [00:08<16:38:44,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.06634204312890622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 1.0273, accuracy: 0.8500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 9/75000 [00:08<15:49:16,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0630249409724609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 1.0261, accuracy: 0.6750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 10/75000 [00:09<15:27:53,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.05987369392383786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.9263, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 11/75000 [00:10<15:00:31,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.05688000922764597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.9762, accuracy: 0.7750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 12/75000 [00:10<14:48:12,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.05403600876626367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.9035, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 13/75000 [00:11<14:33:27,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.05133420832795048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.9390, accuracy: 0.8250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 14/75000 [00:12<14:21:34,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.04876749791155295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.8891, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 15/75000 [00:12<14:18:10,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.046329123015975304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 1.1188, accuracy: 0.7000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 16/75000 [00:13<14:11:13,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.04401266686517654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.8773, accuracy: 0.8250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 17/75000 [00:14<14:06:51,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.04181203352191771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.9264, accuracy: 0.8500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 18/75000 [00:14<14:07:26,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.039721431845821824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.7931, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 19/75000 [00:15<14:06:45,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.037735360253530734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.9390, accuracy: 0.8000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 20/75000 [00:16<15:34:55,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.035848592240854196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.8463, accuracy: 0.8000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 21/75000 [00:17<16:59:51,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.03405616262881148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.7072, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 22/75000 [00:18<18:18:20,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.03235335449737091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.8284, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 23/75000 [00:19<17:00:29,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.030735686772502362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.9804, accuracy: 0.6750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 24/75000 [00:19<16:05:36,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.029198902433877242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.8981, accuracy: 0.7500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 25/75000 [00:20<15:30:48,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.027738957312183378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.8728, accuracy: 0.8500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 26/75000 [00:21<15:08:54,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.026352009446574207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6619, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 27/75000 [00:21<14:45:31,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.025034408974245494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.8089, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 28/75000 [00:22<14:36:16,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.023782688525533217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.7965, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 29/75000 [00:23<14:33:41,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.022593554099256556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.7285, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 30/75000 [00:23<14:24:00,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.021463876394293726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.7427, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 31/75000 [00:24<14:25:27,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.020390682574579037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.7781, accuracy: 0.8500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 32/75000 [00:25<14:19:30,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.019371148445850084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.7290, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 33/75000 [00:25<14:12:40,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.01840259102355758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6483, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 34/75000 [00:26<14:17:16,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0174824614723797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.8343, accuracy: 0.8000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 35/75000 [00:27<14:13:43,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.016608338398760712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.7364, accuracy: 0.8250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 36/75000 [00:28<14:17:44,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.015777921478822676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.7644, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 37/75000 [00:28<14:47:56,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.014989025404881541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.7641, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 38/75000 [00:29<15:53:11,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.014239574134637464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.7700, accuracy: 0.8500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 39/75000 [00:30<17:42:20,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.01352759542790559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6762, accuracy: 0.8250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 40/75000 [00:31<18:22:24,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.012851215656510309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.8472, accuracy: 0.8000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 41/75000 [00:32<17:05:06,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.012208654873684792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.7740, accuracy: 0.8250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 42/75000 [00:33<16:09:34,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.011598222130000552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6998, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 43/75000 [00:33<15:37:52,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.011018311023500524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.7009, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 44/75000 [00:34<15:08:03,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.010467395472325497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6138, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 45/75000 [00:35<14:54:55,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.009944025698709221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4739, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 46/75000 [00:35<14:45:04,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00944682441377376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.7921, accuracy: 0.8500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 47/75000 [00:36<14:28:12,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00897448319308507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6066, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 48/75000 [00:37<14:24:00,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.008525759033430816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6527, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 49/75000 [00:37<14:19:10,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.008099471081759275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6332, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 50/75000 [00:38<14:11:28,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.007694497527671311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5497, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 51/75000 [00:39<14:10:19,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.007309772651287745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6840, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 52/75000 [00:39<14:19:25,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.006944284018723357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6755, accuracy: 0.8500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 53/75000 [00:40<14:13:57,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.006597069817787189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5701, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 54/75000 [00:41<14:14:10,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.006267216326897829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6133, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 55/75000 [00:42<15:05:46,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.005953855510552938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6873, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 56/75000 [00:42<16:16:44,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.005656162735025291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6154, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 57/75000 [00:44<18:04:04,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.005373354598274026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5742, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 58/75000 [00:44<18:35:39,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.005104686868360324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5643, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 59/75000 [00:45<17:11:56,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.004849452524942308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5741, accuracy: 0.8500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 60/75000 [00:46<16:13:49,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.004606979898695193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5404, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 61/75000 [00:47<15:39:14,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.004376630903760433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6192, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 62/75000 [00:47<15:08:27,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0041577993585724116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5674, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 63/75000 [00:48<14:48:24,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0039499093906437905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6133, accuracy: 0.8500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 64/75000 [00:49<14:40:03,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0037524139211116006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6217, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 65/75000 [00:49<14:42:45,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0035647932250560204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4553, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 66/75000 [00:50<14:35:51,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.003386553563803219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6256, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 67/75000 [00:51<14:26:53,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.003217225885613058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6917, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 68/75000 [00:51<14:45:11,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0030563645913324047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5490, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 69/75000 [00:52<14:33:05,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0029035463617657843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5716, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 70/75000 [00:53<14:27:38,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.002758369043677495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4928, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 71/75000 [00:53<14:29:59,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00262045059149362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5511, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 72/75000 [00:54<14:25:31,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.002489428061918939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4206, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 73/75000 [00:55<15:42:53,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.002364956658822992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.7021, accuracy: 0.8250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 74/75000 [00:56<16:48:56,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.002246708825881842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4535, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 75/75000 [00:57<18:02:50,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00213437338458775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5204, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 76/75000 [00:58<17:40:06,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0020276547153583622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5560, accuracy: 0.8250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 77/75000 [00:58<16:41:45,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.001926271979590444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4807, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 78/75000 [00:59<15:51:52,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0018299583806109217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4846, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 79/75000 [01:00<15:11:39,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0017384604615803755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5371, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 80/75000 [01:00<14:53:59,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0016515374385013568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5810, accuracy: 0.8250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 81/75000 [01:01<14:51:45,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0015689605665762888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5272, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 82/75000 [01:02<14:40:34,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0014905125382474742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4117, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 83/75000 [01:03<14:31:28,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0014159869113351004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5638, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 84/75000 [01:03<14:30:08,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0013451875657683454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4221, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 85/75000 [01:04<14:23:49,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.001277928187479928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5225, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 86/75000 [01:05<14:25:17,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0012140317781059316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3780, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 87/75000 [01:05<14:24:57,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.001153330189200635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5718, accuracy: 0.8500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 88/75000 [01:06<14:14:07,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0010956636797406032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6206, accuracy: 0.8250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 89/75000 [01:07<14:18:27,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.001040880495753573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4455, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 90/75000 [01:07<14:33:53,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0009888364709658944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3767, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 91/75000 [01:08<16:01:25,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0009393946474175996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5519, accuracy: 0.8500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 92/75000 [01:09<17:13:03,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0008924249150467197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.6120, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 93/75000 [01:10<18:17:36,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0008478036692943836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3604, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 94/75000 [01:11<17:02:40,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0008054134858296644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4979, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 95/75000 [01:12<17:02:37,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0007651428115381812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3991, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 96/75000 [01:12<16:14:03,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.000726885670961272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5382, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 97/75000 [01:13<15:38:48,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0006905413874132084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4347, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 98/75000 [01:14<15:13:31,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0006560143180425479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5276, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 99/75000 [01:15<15:04:30,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0006232136021404205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4935, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 100/75000 [01:15<14:43:28,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0005920529220333994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5283, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 101/75000 [01:16<16:18:38,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0005624502759317294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5270, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 102/75000 [01:17<17:31:41,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0005343277621351429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3750, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 103/75000 [01:18<18:12:24,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0005076113740283857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4272, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 104/75000 [01:19<16:59:07,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00048223080532696635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4102, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 105/75000 [01:19<16:04:13,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00045811926506061804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5110, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 106/75000 [01:20<15:45:22,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0004352133018075871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4484, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 107/75000 [01:21<16:47:55,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00041345263671720774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4924, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 108/75000 [01:22<17:36:17,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00039278000488134735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4890, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 109/75000 [01:23<18:38:08,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00037314100463728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5292, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 110/75000 [01:24<17:44:03,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.000354483954405416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4274, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 111/75000 [01:25<16:50:04,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00033675975668514516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4399, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 112/75000 [01:25<16:07:05,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0003199217688508879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3759, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 113/75000 [01:26<15:28:16,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00030392568040834347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3975, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 114/75000 [01:27<14:57:35,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0002887293963879263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3955, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 115/75000 [01:27<14:55:17,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00027429292656852995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3970, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 116/75000 [01:28<14:52:20,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00026057828024010345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3478, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 117/75000 [01:29<14:31:56,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00024754936622809826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4380, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 118/75000 [01:29<14:34:26,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00023517189791669334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3705, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 119/75000 [01:30<14:32:05,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00022341330302085867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4213, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 120/75000 [01:31<14:22:06,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00021224263786981574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4077, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 121/75000 [01:31<14:19:00,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00020163050597632494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.5312, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 122/75000 [01:32<14:16:30,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0001915489806775087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4307, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 123/75000 [01:33<14:19:41,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00018197153164363326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2962, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 124/75000 [01:34<14:56:13,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0001728729550614516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4339, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 125/75000 [01:34<16:05:31,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00016422930730837902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3535, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 126/75000 [01:35<17:32:32,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00015601784194296006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3909, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 127/75000 [01:36<18:09:46,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00014821694984581206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4592, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 128/75000 [01:37<16:59:39,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00014080610235352146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4873, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 129/75000 [01:38<16:17:49,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0001337657972358454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3969, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 130/75000 [01:38<15:45:43,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.0001270775073740531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3447, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 131/75000 [01:39<15:16:53,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00012072363200535044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3599, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 132/75000 [01:40<14:59:37,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00011468745040508291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3535, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 133/75000 [01:41<14:56:05,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00010895307788482875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3639, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 134/75000 [01:41<14:51:35,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 0.00010350542399058731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3235, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 135/75000 [01:42<14:46:37,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.833015279105794e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3780, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 136/75000 [01:43<14:48:11,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.341364515150504e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3844, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 137/75000 [01:43<14:35:06,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.874296289392978e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4254, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 138/75000 [01:44<14:30:58,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.430581474923329e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4126, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 139/75000 [01:45<14:25:52,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.009052401177162e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2664, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 140/75000 [01:45<14:16:58,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.608599781118304e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3573, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 141/75000 [01:46<14:29:52,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.228169792062389e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4079, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 142/75000 [01:47<15:42:15,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.866761302459269e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3636, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 143/75000 [01:48<16:50:26,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.523423237336306e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3012, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 144/75000 [01:49<18:09:16,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.19725207546949e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2950, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 145/75000 [01:50<17:37:37,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.8873894716960144e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4033, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 146/75000 [01:50<16:41:57,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.5930199981112136e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2653, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 147/75000 [01:51<16:15:44,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.3133689982056524e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3187, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 148/75000 [01:52<15:40:02,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.0477005482953695e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3454, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 149/75000 [01:53<15:07:48,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.7953155208806006e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3086, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 150/75000 [01:53<14:55:32,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.55554974483657e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3100, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 151/75000 [01:54<14:43:19,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.327772257594741e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3699, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 152/75000 [01:55<14:37:22,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.111383644715004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4301, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 153/75000 [01:55<14:32:25,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.9058144624792534e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2714, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 154/75000 [01:56<14:46:35,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.7105237393552906e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2529, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 155/75000 [01:57<14:34:05,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.524997552387526e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3209, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 156/75000 [01:57<14:27:16,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.34874767476815e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2320, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 157/75000 [01:58<14:23:14,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.1813102910297426e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3157, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 158/75000 [01:59<14:17:19,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.0222447764782554e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3305, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 159/75000 [02:00<14:43:30,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.8711325376543424e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2624, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 160/75000 [02:00<16:17:46,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.727575910771625e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2900, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 161/75000 [02:02<18:05:55,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.5911971152330435e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3747, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 162/75000 [02:03<19:01:58,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.461637259471391e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3661, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 163/75000 [02:03<17:38:10,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.3385553964978216e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4157, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 164/75000 [02:04<16:34:25,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.2216276266729303e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2121, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 165/75000 [02:05<16:00:58,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.1105462453392836e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3461, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 166/75000 [02:05<15:38:53,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.0050189330723194e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4099, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 167/75000 [02:06<15:07:46,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.9047679864187035e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3175, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 168/75000 [02:07<14:49:04,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.8095295870977683e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2629, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 169/75000 [02:07<14:49:30,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.71905310774288e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3570, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 170/75000 [02:08<14:36:34,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.6331004523557357e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2599, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 171/75000 [02:09<14:32:42,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.5514454297379488e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3198, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 172/75000 [02:09<14:24:29,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.4738731582510512e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2120, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 173/75000 [02:10<14:15:43,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.4001795003384986e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3047, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 174/75000 [02:11<14:13:53,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.3301705253215736e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3231, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 175/75000 [02:12<14:10:45,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.2636619990554949e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2087, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 176/75000 [02:12<14:04:38,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.2004788991027201e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2837, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 177/75000 [02:13<15:16:38,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.140454954147584e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1866, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 178/75000 [02:14<16:24:16,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.0834322064402047e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2396, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 179/75000 [02:15<17:47:30,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.0292605961181944e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2693, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 180/75000 [02:16<17:45:27,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.777975663122847e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3872, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 181/75000 [02:17<16:37:47,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.289076879966705e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3354, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 182/75000 [02:17<15:54:35,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.82462303596837e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4779, accuracy: 0.7750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 183/75000 [02:18<15:26:25,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.38339188416995e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2373, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 184/75000 [02:19<14:58:55,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.964222289961452e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4307, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 185/75000 [02:19<14:49:00,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.566011175463379e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2580, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 186/75000 [02:20<15:25:42,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.18771061669021e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2616, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 187/75000 [02:21<15:04:38,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.8283250858556995e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2853, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 188/75000 [02:21<14:54:44,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.4869088315629144e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2625, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 189/75000 [02:22<14:40:12,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.162563389984768e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3182, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 190/75000 [02:23<14:36:11,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.85443522048553e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1866, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 191/75000 [02:24<14:36:19,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.561713459461253e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3359, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 192/75000 [02:24<14:29:34,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.28362778648819e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2771, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 193/75000 [02:25<14:24:40,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.019446397163781e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2553, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 194/75000 [02:26<14:40:11,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.768474077305592e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3023, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 195/75000 [02:27<16:21:03,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.530050373440312e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1952, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 196/75000 [02:28<17:49:35,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.303547854768296e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2137, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 197/75000 [02:29<18:35:00,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.088370462029881e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2248, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 198/75000 [02:29<17:14:14,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.883951938928387e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2673, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 199/75000 [02:30<16:16:58,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.689754341981967e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3642, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 200/75000 [02:31<15:35:57,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.5052666248828686e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2448, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 201/75000 [02:31<15:19:45,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.330003293638725e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1776, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 202/75000 [02:32<15:00:16,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.1635031289567887e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2006, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 203/75000 [02:33<14:52:59,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.005327972508949e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3136, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 204/75000 [02:33<14:40:59,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.8550615738835014e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2280, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 205/75000 [02:34<14:33:13,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.712308495189326e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1386, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 206/75000 [02:35<14:25:34,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.57669307042986e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2463, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 207/75000 [02:35<14:33:55,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.447858416908367e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3035, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 208/75000 [02:36<14:20:14,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.3254654960629483e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2443, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 209/75000 [02:37<14:15:26,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.2091922212598007e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1795, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 210/75000 [02:38<14:35:28,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.0987326101968105e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2341, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 211/75000 [02:38<14:22:47,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.9937959796869698e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1859, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 212/75000 [02:39<15:22:24,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.8941061807026212e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1481, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 213/75000 [02:40<16:25:15,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.79940087166749e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1790, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 214/75000 [02:41<17:32:07,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.7094308280841156e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2739, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 215/75000 [02:42<17:39:27,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.6239592866799097e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1895, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 216/75000 [02:43<16:47:36,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.5427613223459142e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2268, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 217/75000 [02:43<16:03:47,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.4656232562286185e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1716, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 218/75000 [02:44<15:36:13,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.3923420934171876e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2231, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 219/75000 [02:45<15:00:55,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.3227249887463282e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1797, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 220/75000 [02:45<14:54:56,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.2565887393090117e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2139, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 221/75000 [02:46<14:43:35,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.193759302343561e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2438, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 222/75000 [02:47<14:29:40,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.134071337226383e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3400, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 223/75000 [02:47<14:26:22,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.0773677703650638e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2063, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 224/75000 [02:48<14:24:18,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.0234993818468106e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3399, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 225/75000 [02:49<14:26:26,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.7232441275447e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2114, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 226/75000 [02:49<14:20:26,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.237081921167466e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2370, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 227/75000 [02:50<14:22:51,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.775227825109092e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2269, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 228/75000 [02:51<14:18:08,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.336466433853637e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2595, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 229/75000 [02:51<14:13:40,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.919643112160955e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1237, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 230/75000 [02:52<16:02:52,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.523660956552907e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1638, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 231/75000 [02:53<17:08:28,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.14747790872526e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3117, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 232/75000 [02:54<18:33:57,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.790104013288997e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2731, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 233/75000 [02:55<17:30:00,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.450598812624547e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4010, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 234/75000 [02:56<16:22:42,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.128068871993319e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3992, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 235/75000 [02:57<15:55:15,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.821665428393653e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1930, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 236/75000 [02:57<15:23:56,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.530582156973969e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1893, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 237/75000 [02:58<15:03:56,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.254053049125271e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1690, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 238/75000 [02:59<14:43:53,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.991350396669007e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2216, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 239/75000 [02:59<14:23:59,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.741782876835556e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2922, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 240/75000 [03:00<14:28:41,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.504693732993778e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2228, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 241/75000 [03:01<14:18:07,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.2794590463440887e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1726, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 242/75000 [03:01<14:07:26,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.065486094026884e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2926, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 243/75000 [03:02<14:10:02,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.8622117893255396e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2460, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 244/75000 [03:03<14:18:37,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.6691011998592624e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3406, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 245/75000 [03:03<14:41:06,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.485646139866299e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2372, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 246/75000 [03:04<14:28:48,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.311363832872984e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2730, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 247/75000 [03:05<15:01:20,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.1457956412293345e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1893, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 248/75000 [03:06<16:13:23,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.9885058591678676e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1493, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 249/75000 [03:07<17:57:15,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.839080566209474e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2775, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 250/75000 [03:08<18:57:50,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.6971265378990003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2437, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 251/75000 [03:09<17:40:48,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.56227021100405e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2166, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 252/75000 [03:09<16:40:34,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.434156700453848e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2714, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 253/75000 [03:10<16:01:49,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.3124488654311553e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2119, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 254/75000 [03:11<15:35:03,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.1968264221595975e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1357, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 255/75000 [03:11<15:31:53,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.0869851010516177e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1563, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 256/75000 [03:12<15:14:59,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.9826358459990365e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1146, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 257/75000 [03:13<15:09:01,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.8835040536990848e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1963, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 258/75000 [03:14<15:00:03,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.7893288510141304e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2096, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 259/75000 [03:14<14:53:23,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.6998624084634237e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1568, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 260/75000 [03:15<14:47:57,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.6148692880402525e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2134, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 261/75000 [03:16<14:30:36,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.53412582363824e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2582, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 262/75000 [03:16<14:48:40,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.4574195324563278e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1791, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 263/75000 [03:17<14:37:35,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.3845485558335112e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3361, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 264/75000 [03:18<14:27:14,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.3153211280418356e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2146, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 265/75000 [03:19<15:48:38,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.2495550716397436e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1840, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 266/75000 [03:20<16:50:53,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.1870773180577564e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1934, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 267/75000 [03:21<18:38:15,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.1277234521548686e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2526, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 268/75000 [03:21<17:45:38,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.0713372795471251e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1601, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 269/75000 [03:22<16:38:38,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.0177704155697688e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2457, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 270/75000 [03:23<16:10:02,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.668818947912803e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1579, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 271/75000 [03:24<15:38:27,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.185378000517163e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1726, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 272/75000 [03:24<15:14:59,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.726109100491304e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2558, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 273/75000 [03:25<15:01:30,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.289803645466738e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2332, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 274/75000 [03:26<14:47:11,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.875313463193401e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2811, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 275/75000 [03:26<14:30:16,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.481547790033731e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2880, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 276/75000 [03:27<14:36:15,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.107470400532044e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1952, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 277/75000 [03:28<14:32:05,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.752096880505442e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2021, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 278/75000 [03:28<14:26:05,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.41449203648017e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1810, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 279/75000 [03:29<14:24:24,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.09376743465616e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1640, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 280/75000 [03:30<15:04:41,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.7890790629233524e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2580, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 281/75000 [03:31<15:07:15,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.4996251097771844e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1921, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 282/75000 [03:31<15:58:01,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.224643854288325e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2512, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 283/75000 [03:32<17:21:13,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.963411661573909e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1494, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 284/75000 [03:34<18:56:38,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.715241078495213e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1756, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 285/75000 [03:34<18:58:21,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.479479024570452e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2006, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 286/75000 [03:35<17:33:42,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.2555050733419295e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1775, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 287/75000 [03:36<16:34:56,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.042729819674833e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2419, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 288/75000 [03:37<16:02:02,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.840593328691091e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1958, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 289/75000 [03:37<15:35:22,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.648563662256537e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1701, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 290/75000 [03:38<15:20:04,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.4661354791437095e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1477, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 291/75000 [03:39<15:02:42,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.292828705186524e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2068, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 292/75000 [03:39<14:48:20,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.1281872699271974e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2322, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 293/75000 [03:40<14:39:04,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.9717779064308373e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2671, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 294/75000 [03:41<14:29:51,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.8231890111092953e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1619, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 295/75000 [03:41<14:24:31,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.6820295605538305e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1534, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 296/75000 [03:42<14:20:21,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.5479280825261387e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2468, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 297/75000 [03:43<14:19:22,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.4205316783998316e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1348, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 298/75000 [03:43<14:27:37,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.2995050944798398e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2062, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 299/75000 [03:44<14:33:36,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.1845298397558478e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2285, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 300/75000 [03:45<15:53:31,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.0753033477680553e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3143, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 301/75000 [03:46<16:49:16,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.9715381803796525e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1526, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 302/75000 [03:47<18:15:48,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.8729612713606698e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2040, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 303/75000 [03:48<17:17:57,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.779313207792636e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1239, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 304/75000 [03:49<16:36:18,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.6903475474030043e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1457, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 305/75000 [03:49<16:15:45,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.605830170032854e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3000, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 306/75000 [03:50<15:38:35,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.525538661531211e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2225, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 307/75000 [03:51<15:19:44,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.4492617284546504e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3475, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 308/75000 [03:51<15:04:23,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.3767986420319179e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2375, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 309/75000 [03:52<14:48:47,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.3079587099303219e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2068, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 310/75000 [03:53<14:44:30,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.2425607744338058e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2211, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 311/75000 [03:53<14:55:01,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.1804327357121154e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1397, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 312/75000 [03:54<14:42:43,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.1214110989265096e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1946, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 313/75000 [03:55<14:38:39,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.0653405439801841e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2526, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 314/75000 [03:56<14:35:29,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.0120735167811749e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2212, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 315/75000 [03:56<14:28:08,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.61469840942116e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1640, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 316/75000 [03:57<14:21:25,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.133963488950102e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1566, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 317/75000 [03:58<15:21:14,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.677265314502596e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1699, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 318/75000 [03:59<16:46:20,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.243402048777466e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2001, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 319/75000 [04:00<18:06:54,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.831231946338592e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1756, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 320/75000 [04:01<18:06:56,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.439670349021662e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1292, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 321/75000 [04:01<17:04:21,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.067686831570578e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1691, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 322/75000 [04:02<16:13:44,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.714302489992049e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1257, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 323/75000 [04:03<15:44:17,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.3785873654924456e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2482, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 324/75000 [04:03<15:14:57,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.059657997217823e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1737, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 325/75000 [04:04<15:05:15,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.756675097356932e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1923, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 326/75000 [04:05<14:48:27,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.468841342489085e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.0730, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 327/75000 [04:05<14:40:00,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.19539927536463e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1377, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 328/75000 [04:06<14:40:26,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.9356293115963985e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1183, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 329/75000 [04:07<14:40:51,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.688847846016579e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1609, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 330/75000 [04:08<14:32:42,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.45440545371575e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1236, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 331/75000 [04:08<14:33:00,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.231685181029962e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1644, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 332/75000 [04:09<14:24:53,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.020100921978463e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1275, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 333/75000 [04:10<14:13:47,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.81909587587954e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1969, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 334/75000 [04:10<14:16:37,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.6281410820855627e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1473, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 335/75000 [04:11<15:47:57,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.4467340279812844e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1708, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 336/75000 [04:12<16:56:59,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.27439732658222e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1735, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 337/75000 [04:13<18:00:06,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.110677460253109e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1602, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 338/75000 [04:14<17:19:39,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.9551435872404534e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1277, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 339/75000 [04:15<16:32:42,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.8073864078784307e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3412, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 340/75000 [04:15<15:56:10,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.6670170874845092e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1220, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 341/75000 [04:16<15:23:48,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.533666233110284e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1194, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 342/75000 [04:17<15:03:16,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.4069829214547697e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2058, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 343/75000 [04:17<14:53:16,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.2866337753820313e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1824, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 344/75000 [04:18<14:38:03,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.1723020866129295e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1597, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 345/75000 [04:19<14:33:00,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.063686982282283e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2056, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 346/75000 [04:19<14:28:11,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.9605026331681687e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1818, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 347/75000 [04:20<14:12:39,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.8624775015097601e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1913, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 348/75000 [04:21<14:05:10,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.769353626434272e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2734, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 349/75000 [04:21<14:05:58,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.6808859451125584e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2114, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 350/75000 [04:22<14:20:10,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.5968416478569305e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.0956, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 351/75000 [04:23<14:17:13,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.516999565464084e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1588, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 352/75000 [04:24<14:35:21,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.4411495871908797e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1375, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 353/75000 [04:25<15:58:39,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.3690921078313357e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3096, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 354/75000 [04:26<17:29:29,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.3006375024397688e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1871, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 355/75000 [04:27<18:33:28,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.2356056273177802e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1303, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 356/75000 [04:27<17:13:26,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.1738253459518912e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1497, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 357/75000 [04:28<16:22:48,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.1151340786542967e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1332, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 358/75000 [04:29<15:45:51,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.0593773747215819e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2773, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 359/75000 [04:29<15:12:32,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.0064085059855027e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2255, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 360/75000 [04:30<14:51:34,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.560880806862275e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1430, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 361/75000 [04:31<14:37:13,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.08283676651916e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1687, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 362/75000 [04:31<14:33:45,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.628694928193202e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1945, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 363/75000 [04:32<14:28:37,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.197260181783541e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2221, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 364/75000 [04:33<14:29:34,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.787397172694363e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1501, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 365/75000 [04:33<14:21:55,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.398027314059645e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2355, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 366/75000 [04:34<14:25:40,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.028125948356663e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2219, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 367/75000 [04:35<14:26:22,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.676719650938829e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2777, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 368/75000 [04:36<14:22:25,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.342883668391888e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2381, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 369/75000 [04:36<14:27:37,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.025739484972293e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3436, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 370/75000 [04:37<15:51:23,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.724452510723678e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2789, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 371/75000 [04:38<16:57:59,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.438229885187493e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2741, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 372/75000 [04:39<18:17:17,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.166318390928118e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4223, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 373/75000 [04:40<18:09:14,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.908002471381712e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2377, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 374/75000 [04:41<17:47:32,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.662602347812625e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3034, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   0%|          | 375/75000 [04:42<16:43:06,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.429472230421994e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2412, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 376/75000 [04:42<16:05:34,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.2079986189008943e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2031, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 377/75000 [04:43<15:38:01,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.997598687955849e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3348, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 378/75000 [04:44<15:08:49,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.7977187535580564e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2952, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 379/75000 [04:44<15:12:38,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.6078328158801534e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2230, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 380/75000 [04:45<14:54:28,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.4274411750861456e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3373, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 381/75000 [04:46<14:42:19,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.256069116331838e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2719, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 382/75000 [04:46<14:36:39,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.093265660515246e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1965, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 383/75000 [04:47<14:25:08,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.9386023774894836e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3561, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 384/75000 [04:48<14:28:02,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.7916722586150093e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1718, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 385/75000 [04:48<14:29:35,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.652088645684259e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3228, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 386/75000 [04:49<14:26:57,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.5194842134000456e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3202, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 387/75000 [04:50<14:55:48,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.393510002730043e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1484, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 388/75000 [04:51<16:11:17,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.273834502593541e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2526, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 389/75000 [04:52<17:36:09,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.1601427774638639e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.4069, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 390/75000 [04:53<18:19:13,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.0521356385906706e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2631, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 391/75000 [04:54<17:16:02,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.949528856661137e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1942, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 392/75000 [04:54<16:26:41,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.85205241382808e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1919, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 393/75000 [04:55<15:52:19,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.7594497931366759e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3134, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 394/75000 [04:56<15:29:24,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.671477303479842e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1537, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 395/75000 [04:56<15:02:12,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.5879034383058498e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2012, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 396/75000 [04:57<14:46:05,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.5085082663905573e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1343, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 397/75000 [04:58<14:48:34,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.4330828530710293e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1774, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 398/75000 [04:58<14:49:34,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.3614287104174777e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2619, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 399/75000 [04:59<14:49:18,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.2933572748966038e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2950, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 400/75000 [05:00<14:43:42,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.2286894111517737e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1822, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 401/75000 [05:01<14:27:06,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.167254940594185e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.0825, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 402/75000 [05:01<14:22:44,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.1088921935644756e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2851, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 403/75000 [05:02<14:24:05,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.0534475838862517e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3945, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 404/75000 [05:03<14:18:03,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.0007752046919391e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1508, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 405/75000 [05:03<15:34:54,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.507364444573421e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2247, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 406/75000 [05:04<16:49:53,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.03199622234475e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1605, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 407/75000 [05:05<18:10:59,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.580396411227512e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2066, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 408/75000 [05:06<17:53:18,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.151376590666135e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3119, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 409/75000 [05:07<16:55:15,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.743807761132829e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2153, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 410/75000 [05:08<16:20:29,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.356617373076187e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2189, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 411/75000 [05:08<15:44:39,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.988786504422378e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.0912, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 412/75000 [05:09<15:18:53,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.639347179201259e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2462, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 413/75000 [05:10<15:03:51,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.307379820241195e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2825, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 414/75000 [05:11<15:13:03,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.992010829229135e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1797, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 415/75000 [05:11<14:55:33,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.6924102877676776e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3120, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 416/75000 [05:12<14:39:15,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.407789773379293e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1082, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 417/75000 [05:13<14:30:38,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.1374002847103286e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2022, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 418/75000 [05:13<14:26:50,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.880530270474812e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2481, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 419/75000 [05:14<14:20:14,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.6365037569510706e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2712, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 420/75000 [05:15<14:18:54,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.4046785691035167e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2787, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 421/75000 [05:15<14:18:15,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.1844446406483405e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1813, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 422/75000 [05:16<14:49:42,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.975222408615923e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1751, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 423/75000 [05:17<15:58:36,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.776461288185127e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2336, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 424/75000 [05:18<17:15:58,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.58763822377587e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1969, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 425/75000 [05:19<18:21:06,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.408256312587077e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1083, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 426/75000 [05:20<17:04:03,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.237843496957723e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2788, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 427/75000 [05:20<16:12:48,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.075951322109837e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.0943, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 428/75000 [05:21<15:37:15,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.922153756004345e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1297, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 429/75000 [05:22<15:11:40,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.7760460682041273e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1493, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 430/75000 [05:22<14:59:08,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.6372437647939207e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2474, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 431/75000 [05:23<14:43:35,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.5053815765542246e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1146, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 432/75000 [05:24<14:38:29,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.3801124977265133e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3960, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 433/75000 [05:25<14:40:39,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.2611068728401876e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1525, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 434/75000 [05:25<14:41:09,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.1480515291981783e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2287, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 435/75000 [05:26<14:35:54,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.0406489527382693e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1429, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 436/75000 [05:27<14:34:55,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.9386165051013556e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1331, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 437/75000 [05:27<14:31:29,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.8416856798462876e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1829, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 438/75000 [05:28<14:30:51,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.749601395853973e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1918, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 439/75000 [05:29<14:27:12,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.6621213260612744e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2139, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 440/75000 [05:30<15:29:04,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.5790152597582105e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1089, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 441/75000 [05:31<16:59:20,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.5000644967703e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1884, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 442/75000 [05:32<18:11:28,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.4250612719317848e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1532, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 443/75000 [05:32<18:01:35,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.3538082083351955e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1534, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 444/75000 [05:33<16:55:14,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.2861177979184357e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1519, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 445/75000 [05:34<16:05:57,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.2218119080225138e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.0865, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 446/75000 [05:35<15:37:03,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.1607213126213881e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2005, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 447/75000 [05:35<15:21:58,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.1026852469903187e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1589, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 448/75000 [05:36<15:00:17,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.0475509846408028e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2122, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 449/75000 [05:37<14:57:02,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.951734354087626e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2676, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 450/75000 [05:37<14:56:40,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.454147636383244e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1235, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 451/75000 [05:38<14:57:48,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.98144025456408e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1883, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 452/75000 [05:39<14:45:37,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.532368241835877e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2985, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 453/75000 [05:40<14:49:37,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.105749829744083e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.0992, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 454/75000 [05:40<14:42:38,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.700462338256877e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.3811, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 455/75000 [05:41<14:34:40,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.315439221344033e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1319, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 456/75000 [05:42<14:28:18,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.949667260276831e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1239, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 457/75000 [05:42<14:51:15,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.602183897262989e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.0912, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 458/75000 [05:43<16:52:40,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.2720747023998394e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1555, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 459/75000 [05:45<18:40:09,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.958470967279847e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1179, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 460/75000 [05:45<19:04:08,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.660547418915855e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1053, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 461/75000 [05:46<17:28:08,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.3775200479700615e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1889, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 462/75000 [05:47<16:38:03,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.108644045571558e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1552, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 463/75000 [05:48<15:58:28,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.8532118432929804e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1586, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 464/75000 [05:48<15:33:39,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.610551251128331e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1881, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 465/75000 [05:49<16:04:10,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.380023688571914e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1429, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 466/75000 [05:50<15:40:16,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 4.161022504143318e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.0950, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 467/75000 [05:51<15:26:51,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.952971378936151e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1413, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 468/75000 [05:51<15:04:36,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.755322809989344e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1298, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 469/75000 [05:52<14:50:46,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.5675566694898764e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1882, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 470/75000 [05:53<14:39:27,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.3891788360153825e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1822, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 471/75000 [05:53<14:27:26,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.219719894214613e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1775, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 472/75000 [05:54<14:24:28,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 3.0587338995038823e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1353, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 473/75000 [05:55<14:19:46,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.9057972045286882e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.0998, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 474/75000 [05:55<14:12:46,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.7605073443022535e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1334, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 475/75000 [05:56<15:41:58,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.6224819770871405e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1731, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 476/75000 [05:57<17:08:38,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.4913578782327834e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1215, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 477/75000 [05:58<18:13:24,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.366789984321144e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1945, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 478/75000 [05:59<17:23:07,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.248450485105087e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1483, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 479/75000 [06:00<16:31:02,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.1360279608498322e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1605, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 480/75000 [06:00<15:53:21,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 2.0292265628073407e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1853, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 481/75000 [06:01<15:26:57,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.9277652346669735e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1045, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 482/75000 [06:02<15:00:45,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.8313769729336246e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1215, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 483/75000 [06:02<14:52:58,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.7398081242869432e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.0545, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 484/75000 [06:03<14:46:28,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.652817718072596e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1660, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 485/75000 [06:04<14:35:21,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.570176832168966e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1543, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 486/75000 [06:05<14:32:24,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.4916679905605177e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2737, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 487/75000 [06:05<14:48:29,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.4170845910324916e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2195, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 488/75000 [06:06<14:34:07,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.346230361480867e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1133, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 489/75000 [06:07<14:27:40,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.2789188434068236e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2795, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 490/75000 [06:07<14:20:19,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.2149729012364822e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1059, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 491/75000 [06:08<14:44:57,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.154224256174658e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1927, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 492/75000 [06:09<15:34:34,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.0965130433659251e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2156, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 493/75000 [06:10<16:35:08,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 1.0416873911976289e-12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1504, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 494/75000 [06:11<18:05:44,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.896030216377474e-13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.0821, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 495/75000 [06:12<17:58:57,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 9.4012287055586e-13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2404, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 496/75000 [06:12<16:54:35,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.931167270280669e-13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1805, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 497/75000 [06:13<16:06:45,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.484608906766635e-13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.0863, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 498/75000 [06:14<15:53:17,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 8.060378461428303e-13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.2273, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 499/75000 [06:15<15:33:06,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.657359538356887e-13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 0 -> loss: 0.1101, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|          | 500/75000 [06:15<15:21:11,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 7.274491561439042e-13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/75 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|         | 1/75 [00:00<00:35,  2.10it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1689, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   1%|         | 1/75 [00:00<00:35,  2.10it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1689, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   3%|         | 2/75 [00:00<00:25,  2.81it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2598, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   3%|         | 2/75 [00:00<00:25,  2.81it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2598, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   4%|         | 3/75 [00:00<00:21,  3.31it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1110, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   4%|         | 3/75 [00:00<00:21,  3.31it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1110, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   5%|         | 4/75 [00:01<00:20,  3.52it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2597, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   5%|         | 4/75 [00:01<00:20,  3.52it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2597, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   7%|         | 5/75 [00:01<00:18,  3.77it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0978, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   7%|         | 5/75 [00:01<00:18,  3.77it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0978, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   8%|         | 6/75 [00:01<00:18,  3.74it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1983, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   8%|         | 6/75 [00:01<00:18,  3.74it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1983, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   9%|         | 7/75 [00:01<00:17,  3.90it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2570, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :   9%|         | 7/75 [00:01<00:17,  3.90it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2570, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  11%|         | 8/75 [00:02<00:17,  3.90it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2930, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  11%|         | 8/75 [00:02<00:17,  3.90it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2930, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  12%|        | 9/75 [00:02<00:16,  3.91it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1359, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  12%|        | 9/75 [00:02<00:16,  3.91it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1359, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  13%|        | 10/75 [00:02<00:16,  3.86it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0891, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  13%|        | 10/75 [00:02<00:16,  3.86it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0891, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  15%|        | 11/75 [00:03<00:16,  3.95it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1876, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  15%|        | 11/75 [00:03<00:16,  3.95it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1876, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  16%|        | 12/75 [00:03<00:15,  3.95it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1704, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  16%|        | 12/75 [00:03<00:15,  3.95it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1704, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  17%|        | 13/75 [00:03<00:15,  3.95it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0696, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  17%|        | 13/75 [00:03<00:15,  3.95it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0696, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  19%|        | 14/75 [00:03<00:15,  3.84it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1247, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  19%|        | 14/75 [00:03<00:15,  3.84it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1247, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  20%|        | 15/75 [00:04<00:15,  3.96it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0842, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  20%|        | 15/75 [00:04<00:15,  3.96it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0842, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  21%|       | 16/75 [00:04<00:15,  3.90it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2760, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  21%|       | 16/75 [00:04<00:15,  3.90it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2760, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  23%|       | 17/75 [00:04<00:14,  3.93it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0554, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  23%|       | 17/75 [00:04<00:14,  3.93it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0554, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  24%|       | 18/75 [00:04<00:14,  3.80it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1078, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  24%|       | 18/75 [00:04<00:14,  3.80it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1078, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  25%|       | 19/75 [00:05<00:14,  3.91it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1095, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  25%|       | 19/75 [00:05<00:14,  3.91it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1095, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  27%|       | 20/75 [00:05<00:13,  3.95it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1546, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  27%|       | 20/75 [00:05<00:13,  3.95it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1546, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  28%|       | 21/75 [00:05<00:13,  4.01it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1471, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  28%|       | 21/75 [00:05<00:13,  4.01it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1471, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  29%|       | 22/75 [00:05<00:13,  3.96it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1747, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  29%|       | 22/75 [00:05<00:13,  3.96it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1747, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  31%|       | 23/75 [00:06<00:12,  4.04it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1213, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  31%|       | 23/75 [00:06<00:12,  4.04it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1213, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  32%|      | 24/75 [00:06<00:13,  3.72it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0390, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  32%|      | 24/75 [00:06<00:13,  3.72it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0390, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  33%|      | 25/75 [00:06<00:14,  3.49it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1821, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  33%|      | 25/75 [00:06<00:14,  3.49it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1821, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  35%|      | 26/75 [00:06<00:14,  3.45it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1116, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  35%|      | 26/75 [00:06<00:14,  3.45it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1116, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  36%|      | 27/75 [00:07<00:14,  3.31it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2153, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  36%|      | 27/75 [00:07<00:14,  3.31it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2153, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  37%|      | 28/75 [00:07<00:14,  3.27it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1070, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  37%|      | 28/75 [00:07<00:14,  3.27it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1070, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  39%|      | 29/75 [00:07<00:14,  3.21it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1345, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  39%|      | 29/75 [00:07<00:14,  3.21it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1345, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  40%|      | 30/75 [00:08<00:14,  3.07it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1375, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  40%|      | 30/75 [00:08<00:14,  3.07it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1375, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  41%|     | 31/75 [00:08<00:14,  2.97it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1002, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  41%|     | 31/75 [00:08<00:14,  2.97it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1002, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  43%|     | 32/75 [00:09<00:14,  2.95it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2040, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  43%|     | 32/75 [00:09<00:14,  2.95it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2040, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  44%|     | 33/75 [00:09<00:14,  2.96it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2167, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  44%|     | 33/75 [00:09<00:14,  2.96it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2167, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  45%|     | 34/75 [00:09<00:14,  2.92it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0628, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  45%|     | 34/75 [00:09<00:14,  2.92it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0628, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  47%|     | 35/75 [00:10<00:13,  3.00it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1099, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  47%|     | 35/75 [00:10<00:13,  3.00it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1099, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  48%|     | 36/75 [00:10<00:13,  2.97it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1887, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  48%|     | 36/75 [00:10<00:13,  2.97it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1887, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  49%|     | 37/75 [00:10<00:13,  2.87it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2023, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  49%|     | 37/75 [00:10<00:13,  2.87it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2023, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  51%|     | 38/75 [00:11<00:12,  3.04it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1896, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  51%|     | 38/75 [00:11<00:12,  3.04it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1896, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  52%|    | 39/75 [00:11<00:10,  3.28it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1617, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  52%|    | 39/75 [00:11<00:10,  3.28it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1617, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  53%|    | 40/75 [00:11<00:10,  3.41it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1562, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  53%|    | 40/75 [00:11<00:10,  3.41it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1562, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  55%|    | 41/75 [00:11<00:09,  3.47it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1213, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  55%|    | 41/75 [00:11<00:09,  3.47it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1213, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  56%|    | 42/75 [00:12<00:09,  3.63it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2455, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  56%|    | 42/75 [00:12<00:09,  3.63it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2455, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  57%|    | 43/75 [00:12<00:08,  3.79it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1853, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  57%|    | 43/75 [00:12<00:08,  3.79it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1853, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  59%|    | 44/75 [00:12<00:08,  3.84it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1900, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  59%|    | 44/75 [00:12<00:08,  3.84it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1900, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  60%|    | 45/75 [00:12<00:08,  3.71it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1216, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  60%|    | 45/75 [00:12<00:08,  3.71it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1216, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  61%|   | 46/75 [00:13<00:07,  3.82it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0774, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  61%|   | 46/75 [00:13<00:07,  3.82it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0774, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  63%|   | 47/75 [00:13<00:07,  3.83it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2193, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  63%|   | 47/75 [00:13<00:07,  3.83it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2193, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  64%|   | 48/75 [00:13<00:06,  3.94it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1896, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  64%|   | 48/75 [00:13<00:06,  3.94it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1896, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  65%|   | 49/75 [00:13<00:06,  3.80it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2405, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  65%|   | 49/75 [00:13<00:06,  3.80it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2405, accuracy: 0.8750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  67%|   | 50/75 [00:14<00:06,  3.88it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1658, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  67%|   | 50/75 [00:14<00:06,  3.88it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1658, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  68%|   | 51/75 [00:14<00:06,  3.90it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2132, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  68%|   | 51/75 [00:14<00:06,  3.90it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2132, accuracy: 0.9000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  69%|   | 52/75 [00:14<00:05,  3.87it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.3747, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  69%|   | 52/75 [00:14<00:05,  3.87it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.3747, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  71%|   | 53/75 [00:14<00:05,  3.81it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1100, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  71%|   | 53/75 [00:14<00:05,  3.81it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1100, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  72%|  | 54/75 [00:15<00:05,  3.86it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2463, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  72%|  | 54/75 [00:15<00:05,  3.86it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2463, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  73%|  | 55/75 [00:15<00:05,  3.95it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1880, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  73%|  | 55/75 [00:15<00:05,  3.95it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1880, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  75%|  | 56/75 [00:15<00:04,  3.91it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0702, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  75%|  | 56/75 [00:15<00:04,  3.91it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0702, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  76%|  | 57/75 [00:15<00:04,  3.90it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1093, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  76%|  | 57/75 [00:15<00:04,  3.90it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1093, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  77%|  | 58/75 [00:16<00:04,  3.98it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1002, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  77%|  | 58/75 [00:16<00:04,  3.98it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1002, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  79%|  | 59/75 [00:16<00:03,  4.03it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1456, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  79%|  | 59/75 [00:16<00:03,  4.03it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1456, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  80%|  | 60/75 [00:16<00:03,  4.02it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0722, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  80%|  | 60/75 [00:16<00:03,  4.02it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0722, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  81%| | 61/75 [00:16<00:03,  3.97it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0676, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  81%| | 61/75 [00:16<00:03,  3.97it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0676, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  83%| | 62/75 [00:17<00:03,  4.04it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1472, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  83%| | 62/75 [00:17<00:03,  4.04it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1472, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  84%| | 63/75 [00:17<00:02,  4.06it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2029, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  84%| | 63/75 [00:17<00:02,  4.06it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2029, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  85%| | 64/75 [00:17<00:02,  3.99it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1431, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  85%| | 64/75 [00:17<00:02,  3.99it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1431, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  87%| | 65/75 [00:17<00:02,  3.94it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1053, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  87%| | 65/75 [00:17<00:02,  3.94it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1053, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  88%| | 66/75 [00:18<00:02,  4.00it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0515, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  88%| | 66/75 [00:18<00:02,  4.00it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0515, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  89%| | 67/75 [00:18<00:01,  4.04it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2036, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  89%| | 67/75 [00:18<00:01,  4.04it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2036, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  91%| | 68/75 [00:18<00:01,  4.06it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0335, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  91%| | 68/75 [00:18<00:01,  4.06it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0335, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  92%|| 69/75 [00:18<00:01,  4.05it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0575, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  92%|| 69/75 [00:18<00:01,  4.05it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0575, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  93%|| 70/75 [00:19<00:01,  4.12it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1538, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  93%|| 70/75 [00:19<00:01,  4.12it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1538, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  95%|| 71/75 [00:19<00:00,  4.17it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1489, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  95%|| 71/75 [00:19<00:00,  4.17it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1489, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  96%|| 72/75 [00:19<00:00,  4.24it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0827, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  96%|| 72/75 [00:19<00:00,  4.24it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0827, accuracy: 1.0000, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  97%|| 73/75 [00:19<00:00,  4.13it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0988, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  97%|| 73/75 [00:19<00:00,  4.13it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.0988, accuracy: 0.9750, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  99%|| 74/75 [00:20<00:00,  4.14it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2303, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, :  99%|| 74/75 [00:20<00:00,  4.14it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.2303, accuracy: 0.9250, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, : 100%|| 75/75 [00:20<00:00,  4.21it/s]\u001b[A\n",
            "val_phase 0 -> loss: 0.1780, accuracy: 0.9500, loss_importance_vector_0: 0.2000, loss_importance_vector_1: 0.2000, loss_importance_vector_2: 0.2000, loss_importance_vector_3: 0.2000, loss_importance_vector_4: 0.2000, : 100%|| 75/75 [00:20<00:00,  3.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best validation accuracy 0.9570000036557516\n",
            "saved models to /content/HowToTrainYourMAMLPytorch/omniglot_5_8_0.1_64_20_2/saved_models\n",
            "epoch 1 -> train_loss_mean: 0.3299, train_loss_std: 0.2189, train_accuracy_mean: 0.9451, train_accuracy_std: 0.0540, train_loss_importance_vector_0_mean: 0.2000, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.2000, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.2000, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.2000, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.2000, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.1528, val_loss_std: 0.0667, val_accuracy_mean: 0.9570, val_accuracy_std: 0.0302, val_loss_importance_vector_0_mean: 0.2000, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.2000, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.2000, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.2000, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.2000, val_loss_importance_vector_4_std: 0.0000, \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 1 -> loss: 0.1050, accuracy: 1.0000, loss_importance_vector_0: 0.1800, loss_importance_vector_1: 0.1800, loss_importance_vector_2: 0.1800, loss_importance_vector_3: 0.1800, loss_importance_vector_4: 0.2800, :   1%|          | 501/75000 [06:37<142:46:38,  6.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.91076698336709e-13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 1 -> loss: 0.1511, accuracy: 0.9750, loss_importance_vector_0: 0.1800, loss_importance_vector_1: 0.1800, loss_importance_vector_2: 0.1800, loss_importance_vector_3: 0.1800, loss_importance_vector_4: 0.2800, :   1%|          | 502/75000 [06:37<105:45:01,  5.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.565228634198735e-13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 1 -> loss: 0.2488, accuracy: 0.9250, loss_importance_vector_0: 0.1800, loss_importance_vector_1: 0.1800, loss_importance_vector_2: 0.1800, loss_importance_vector_3: 0.1800, loss_importance_vector_4: 0.2800, :   1%|          | 503/75000 [06:39<80:31:58,  3.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 6.236967202488797e-13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 1 -> loss: 0.0638, accuracy: 1.0000, loss_importance_vector_0: 0.1800, loss_importance_vector_1: 0.1800, loss_importance_vector_2: 0.1800, loss_importance_vector_3: 0.1800, loss_importance_vector_4: 0.2800, :   1%|          | 504/75000 [06:40<62:30:24,  3.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noise size: 5.925118842364357e-13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training phase 1 -> loss: 0.1201, accuracy: 1.0000, loss_importance_vector_0: 0.1800, loss_importance_vector_1: 0.1800, loss_importance_vector_2: 0.1800, loss_importance_vector_3: 0.1800, loss_importance_vector_4: 0.2800, :   1%|          | 505/75000 [06:40<48:09:17,  2.33s/it]"
          ]
        }
      ],
      "source": [
        "# Combines the arguments, model, data and experiment builders to run an experiment\n",
        "\n",
        "# python train_maml_system.py --name_of_args_json_file experiment_config/ --gpu_to_use 1\n",
        "# import sys\n",
        "# # Simulate command line arguments\n",
        "# sys.argv = [  # Replace with the current file name\n",
        "#            '--name_of_args_json_file', 'content/omniglot_maml++-omniglot_5_8_0.1_64_5_2.json',\n",
        "#            '--gpu_to_use', '1',  # Dataset directory\n",
        "#           #  '--experiment_name', 'omniglot_experiment',  # Experiment name\n",
        "#           #  '--architecture_name', 'maml', # You'll likely need to provide an appropriate architecture name\n",
        "#            # ... add other necessary arguments\n",
        "#            ]\n",
        "\n",
        "# args, device = get_args()\n",
        "args, device = load_args_from_json(\"../omniglot_maml++-omniglot_5_8_0.1_64_20_2.json\")\n",
        "\n",
        "model = MAMLFewShotClassifier(args=args, device=device,\n",
        "                              im_shape=(2, args.image_channels,\n",
        "                                        args.image_height, args.image_width))\n",
        "# maybe_unzip_dataset(args=args)\n",
        "data = MetaLearningSystemDataLoader\n",
        "maml_system = ExperimentBuilder(model=model, data=data, args=args, device=device)\n",
        "maml_system.run_experiment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZIfE7aOQ2sj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "GTJUQiySnDQi"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}